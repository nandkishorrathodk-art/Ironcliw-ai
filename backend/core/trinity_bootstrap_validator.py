"""
Trinity Bootstrap Validator v100.0
===================================

Ultra-robust, async, parallel, intelligent pre-flight validation system.
Validates ALL prerequisites before JARVIS startup to prevent mysterious failures.

Advanced Features:
- Zero hardcoding (100% environment-driven)
- Parallel async validation with TaskGroup (Python 3.11+)
- Structural pattern matching for error classification
- Protocol-based extensibility
- Distributed tracing integration
- Self-healing suggestion engine
- Cross-repo validation (JARVIS, JARVIS Prime, Reactor Core)

Architecture:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 TrinityBootstrapValidator                        â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
    â”‚  â”‚ ValidationOrchestrator (async parallel execution)           â”‚â”‚
    â”‚  â”‚  â”œâ”€â”€ EnvironmentValidator                                   â”‚â”‚
    â”‚  â”‚  â”œâ”€â”€ FileSystemValidator                                    â”‚â”‚
    â”‚  â”‚  â”œâ”€â”€ NetworkValidator                                       â”‚â”‚
    â”‚  â”‚  â”œâ”€â”€ ProcessValidator                                       â”‚â”‚
    â”‚  â”‚  â”œâ”€â”€ ResourceValidator                                      â”‚â”‚
    â”‚  â”‚  â”œâ”€â”€ DependencyValidator                                    â”‚â”‚
    â”‚  â”‚  â”œâ”€â”€ ConfigurationValidator                                 â”‚â”‚
    â”‚  â”‚  â””â”€â”€ CrossRepoValidator                                     â”‚â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
    â”‚  â”‚ SelfHealingSuggestionEngine                                 â”‚â”‚
    â”‚  â”‚  â””â”€â”€ Generates actionable fix commands                      â”‚â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Author: JARVIS System
Version: 100.0.0
"""
from __future__ import annotations

import asyncio
import functools
import hashlib
import importlib
import json
import logging
import os
import platform
import socket
import subprocess
import sys
import time
import traceback
from abc import ABC, abstractmethod
from contextlib import asynccontextmanager, suppress
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum, auto
from pathlib import Path
from typing import (
    Any,
    AsyncIterator,
    Awaitable,
    Callable,
    ClassVar,
    Dict,
    Final,
    Generic,
    List,
    Literal,
    Optional,
    Protocol,
    Set,
    Tuple,
    Type,
    TypeVar,
    Union,
    runtime_checkable,
)

# =============================================================================
# Environment-Driven Configuration (Zero Hardcoding)
# =============================================================================

def _env_float(key: str, default: float) -> float:
    """Get float from environment with validation."""
    try:
        return float(os.getenv(key, str(default)))
    except ValueError:
        return default

def _env_int(key: str, default: int) -> int:
    """Get int from environment with validation."""
    try:
        return int(os.getenv(key, str(default)))
    except ValueError:
        return default

def _env_bool(key: str, default: bool) -> bool:
    """Get bool from environment."""
    val = os.getenv(key, str(default)).lower()
    return val in ("true", "1", "yes", "on")

def _env_list(key: str, default: List[str]) -> List[str]:
    """Get list from comma-separated environment variable."""
    val = os.getenv(key)
    if val:
        return [x.strip() for x in val.split(",") if x.strip()]
    return default

def _env_path(key: str, default: Optional[Path] = None) -> Optional[Path]:
    """Get Path from environment."""
    val = os.getenv(key)
    if val:
        return Path(val).expanduser().resolve()
    return default


# Configuration from environment (NO HARDCODING)
class ValidatorConfig:
    """Environment-driven validator configuration."""

    # Timeouts (all configurable)
    VALIDATION_TIMEOUT: Final[float] = _env_float("TRINITY_VALIDATION_TIMEOUT", 60.0)
    NETWORK_CHECK_TIMEOUT: Final[float] = _env_float("TRINITY_NETWORK_TIMEOUT", 5.0)
    PROCESS_CHECK_TIMEOUT: Final[float] = _env_float("TRINITY_PROCESS_TIMEOUT", 3.0)
    HEALTH_CHECK_TIMEOUT: Final[float] = _env_float("TRINITY_HEALTH_TIMEOUT", 5.0)

    # Resource thresholds
    MIN_MEMORY_GB: Final[float] = _env_float("TRINITY_MIN_MEMORY_GB", 2.0)
    MIN_DISK_GB: Final[float] = _env_float("TRINITY_MIN_DISK_GB", 1.0)
    MAX_CPU_PERCENT: Final[float] = _env_float("TRINITY_MAX_CPU_PERCENT", 95.0)

    # Paths
    JARVIS_HOME: Final[Path] = _env_path("JARVIS_HOME", Path.home() / ".jarvis")
    STATE_DIR: Final[Path] = _env_path("JARVIS_STATE_DIR", Path.home() / ".jarvis" / "state")
    LOGS_DIR: Final[Path] = _env_path("JARVIS_LOGS_DIR", Path.home() / ".jarvis" / "logs")

    # Cross-repo paths
    JARVIS_PRIME_PATH: Final[Optional[Path]] = _env_path("JARVIS_PRIME_PATH")
    REACTOR_CORE_PATH: Final[Optional[Path]] = _env_path("REACTOR_CORE_PATH")

    # Required ports (comma-separated)
    REQUIRED_PORTS: Final[List[int]] = [
        int(p) for p in _env_list("TRINITY_REQUIRED_PORTS", ["8010", "8000", "8090"])
    ]

    # Required packages
    REQUIRED_PACKAGES: Final[List[str]] = _env_list(
        "TRINITY_REQUIRED_PACKAGES",
        ["aiohttp", "fastapi", "uvicorn", "pydantic"]
    )

    # Optional packages (warnings only)
    OPTIONAL_PACKAGES: Final[List[str]] = _env_list(
        "TRINITY_OPTIONAL_PACKAGES",
        ["torch", "transformers", "speechbrain", "psutil"]
    )

    # Required environment variables
    REQUIRED_ENV_VARS: Final[List[str]] = _env_list(
        "TRINITY_REQUIRED_ENV_VARS",
        []  # Empty by default - user can add via env
    )

    # Parallel validation
    MAX_PARALLEL_CHECKS: Final[int] = _env_int("TRINITY_MAX_PARALLEL_CHECKS", 10)

    # Feature flags
    ENABLE_CROSS_REPO_VALIDATION: Final[bool] = _env_bool("TRINITY_CROSS_REPO_VALIDATION", True)
    ENABLE_NETWORK_VALIDATION: Final[bool] = _env_bool("TRINITY_NETWORK_VALIDATION", True)
    ENABLE_RESOURCE_VALIDATION: Final[bool] = _env_bool("TRINITY_RESOURCE_VALIDATION", True)
    STRICT_MODE: Final[bool] = _env_bool("TRINITY_STRICT_VALIDATION", False)


# =============================================================================
# Type Definitions & Protocols
# =============================================================================

T = TypeVar("T")
ValidatorT = TypeVar("ValidatorT", bound="BaseValidator")

class ValidationSeverity(Enum):
    """Severity levels for validation issues."""
    CRITICAL = auto()   # Blocks startup, must fix
    ERROR = auto()      # Blocks startup in strict mode
    WARNING = auto()    # May cause issues, continue
    INFO = auto()       # Informational only

    def __lt__(self, other: "ValidationSeverity") -> bool:
        return self.value < other.value


class ValidationCategory(Enum):
    """Categories of validation checks."""
    ENVIRONMENT = "environment"
    FILESYSTEM = "filesystem"
    NETWORK = "network"
    PROCESS = "process"
    RESOURCE = "resource"
    DEPENDENCY = "dependency"
    CONFIGURATION = "configuration"
    CROSS_REPO = "cross_repo"
    SECURITY = "security"


@runtime_checkable
class Validatable(Protocol):
    """Protocol for validatable objects."""
    async def validate(self, result: "ValidationResult") -> None:
        """Run validation and add issues to result."""
        ...


@dataclass(frozen=True)  # slots=True removed for Python 3.9 compatibility
class ValidationIssue:
    """Immutable validation issue with full context."""
    category: ValidationCategory
    severity: ValidationSeverity
    code: str  # Unique issue code for tracking
    message: str
    component: Optional[str] = None
    fix_suggestion: Optional[str] = None
    fix_command: Optional[str] = None  # Executable fix command
    metadata: Dict[str, Any] = field(default_factory=dict)
    timestamp: float = field(default_factory=time.time)
    traceback: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "category": self.category.value,
            "severity": self.severity.name,
            "code": self.code,
            "message": self.message,
            "component": self.component,
            "fix_suggestion": self.fix_suggestion,
            "fix_command": self.fix_command,
            "metadata": self.metadata,
            "timestamp": self.timestamp,
        }

    def __str__(self) -> str:
        icon = {
            ValidationSeverity.CRITICAL: "ðŸ”´",
            ValidationSeverity.ERROR: "âŒ",
            ValidationSeverity.WARNING: "âš ï¸",
            ValidationSeverity.INFO: "â„¹ï¸",
        }.get(self.severity, "â€¢")
        return f"{icon} [{self.code}] {self.message}"


@dataclass
class ValidationResult:
    """
    Comprehensive validation result with intelligent issue tracking.

    Features:
    - Automatic severity classification
    - Issue deduplication
    - Pass/fail determination
    - Serialization support
    """
    passed: bool = True
    issues: List[ValidationIssue] = field(default_factory=list)
    _issue_codes: Set[str] = field(default_factory=set, repr=False)
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None

    @property
    def duration_ms(self) -> float:
        """Get validation duration in milliseconds."""
        if self.end_time:
            return (self.end_time - self.start_time) * 1000
        return (time.time() - self.start_time) * 1000

    @property
    def critical_issues(self) -> List[ValidationIssue]:
        return [i for i in self.issues if i.severity == ValidationSeverity.CRITICAL]

    @property
    def errors(self) -> List[ValidationIssue]:
        return [i for i in self.issues if i.severity == ValidationSeverity.ERROR]

    @property
    def warnings(self) -> List[ValidationIssue]:
        return [i for i in self.issues if i.severity == ValidationSeverity.WARNING]

    @property
    def info_issues(self) -> List[ValidationIssue]:
        return [i for i in self.issues if i.severity == ValidationSeverity.INFO]

    def add_issue(
        self,
        category: ValidationCategory,
        severity: ValidationSeverity,
        code: str,
        message: str,
        component: Optional[str] = None,
        fix_suggestion: Optional[str] = None,
        fix_command: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None,
        include_traceback: bool = False,
    ) -> ValidationIssue:
        """Add a validation issue with deduplication."""
        # Deduplicate by code
        if code in self._issue_codes:
            return next(i for i in self.issues if i.code == code)

        issue = ValidationIssue(
            category=category,
            severity=severity,
            code=code,
            message=message,
            component=component,
            fix_suggestion=fix_suggestion,
            fix_command=fix_command,
            metadata=metadata or {},
            traceback=traceback.format_exc() if include_traceback else None,
        )

        self.issues.append(issue)
        self._issue_codes.add(code)

        # Update passed status based on severity
        if severity == ValidationSeverity.CRITICAL:
            self.passed = False
        elif severity == ValidationSeverity.ERROR and ValidatorConfig.STRICT_MODE:
            self.passed = False

        return issue

    def merge(self, other: "ValidationResult") -> None:
        """Merge another result into this one."""
        for issue in other.issues:
            if issue.code not in self._issue_codes:
                self.issues.append(issue)
                self._issue_codes.add(issue.code)
                if issue.severity == ValidationSeverity.CRITICAL:
                    self.passed = False
                elif issue.severity == ValidationSeverity.ERROR and ValidatorConfig.STRICT_MODE:
                    self.passed = False

    def finalize(self) -> "ValidationResult":
        """Finalize the result and set end time."""
        self.end_time = time.time()
        # Sort issues by severity (most severe first)
        self.issues.sort(key=lambda i: i.severity.value)
        return self

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "passed": self.passed,
            "duration_ms": self.duration_ms,
            "issue_count": len(self.issues),
            "critical_count": len(self.critical_issues),
            "error_count": len(self.errors),
            "warning_count": len(self.warnings),
            "issues": [i.to_dict() for i in self.issues],
        }

    def save(self, path: Optional[Path] = None) -> Path:
        """Save validation result to file."""
        if path is None:
            path = ValidatorConfig.STATE_DIR / "validation_results"
            path.mkdir(parents=True, exist_ok=True)
            path = path / f"validation_{int(time.time())}.json"

        path.write_text(json.dumps(self.to_dict(), indent=2))
        return path


# =============================================================================
# Base Validator with Advanced Patterns
# =============================================================================

class BaseValidator(ABC):
    """
    Abstract base validator with advanced async patterns.

    Features:
    - Automatic timeout protection
    - Error isolation (one validator failure doesn't crash others)
    - Parallel sub-checks within validator
    - Logging integration
    """

    category: ClassVar[ValidationCategory]
    logger: logging.Logger

    def __init__(self):
        self.logger = logging.getLogger(f"Validator.{self.__class__.__name__}")

    @abstractmethod
    async def _run_checks(self, result: ValidationResult) -> None:
        """Run validation checks. Override in subclasses."""
        ...

    async def validate(self, result: ValidationResult) -> None:
        """Run validation with timeout and error isolation."""
        try:
            # Python 3.9 compatible timeout (asyncio.timeout is 3.11+)
            await asyncio.wait_for(
                self._run_checks(result),
                timeout=ValidatorConfig.VALIDATION_TIMEOUT
            )
        except asyncio.TimeoutError:
            result.add_issue(
                category=self.category,
                severity=ValidationSeverity.ERROR,
                code=f"{self.category.value.upper()}_TIMEOUT",
                message=f"{self.__class__.__name__} timed out after {ValidatorConfig.VALIDATION_TIMEOUT}s",
                fix_suggestion="Increase TRINITY_VALIDATION_TIMEOUT or check system responsiveness",
            )
        except Exception as e:
            result.add_issue(
                category=self.category,
                severity=ValidationSeverity.ERROR,
                code=f"{self.category.value.upper()}_EXCEPTION",
                message=f"{self.__class__.__name__} failed: {e}",
                include_traceback=True,
            )

    async def _parallel_checks(
        self,
        checks: List[Callable[[], Awaitable[None]]],
        max_concurrent: int = 5,
    ) -> None:
        """Run multiple checks in parallel with concurrency limit."""
        semaphore = asyncio.Semaphore(max_concurrent)

        async def bounded_check(check: Callable[[], Awaitable[None]]) -> None:
            async with semaphore:
                await check()

        await asyncio.gather(*[bounded_check(c) for c in checks], return_exceptions=True)


# =============================================================================
# Environment Validator
# =============================================================================

class EnvironmentValidator(BaseValidator):
    """
    Validates environment variables with intelligent type inference.

    Features:
    - Automatic type validation (numeric, boolean, path)
    - Range validation for numeric values
    - Path existence validation
    - Secret detection (warns about exposed secrets)
    """

    category = ValidationCategory.ENVIRONMENT

    # Environment variable specifications (dynamically loaded)
    ENV_SPECS: ClassVar[Dict[str, Dict[str, Any]]] = {
        # Format: "VAR_NAME": {"type": "float|int|bool|path|str", "min": X, "max": Y, "required": bool}
        "JARVIS_PRIME_PORT": {"type": "int", "min": 1, "max": 65535},
        # v150.0: Increased max from 600.0 to 1200.0 (20 minutes) to allow for very large models
        "JARVIS_PRIME_STARTUP_TIMEOUT": {"type": "float", "min": 1.0, "max": 1200.0},
        "TRINITY_VALIDATION_TIMEOUT": {"type": "float", "min": 1.0, "max": 300.0},
        "JARVIS_PRIME_PATH": {"type": "path"},
        "REACTOR_CORE_PATH": {"type": "path"},
        "JARVIS_PRIME_ENABLED": {"type": "bool"},
        "REACTOR_CORE_ENABLED": {"type": "bool"},
    }

    # Secret patterns (warn if exposed in certain ways)
    SECRET_PATTERNS: ClassVar[List[str]] = [
        "API_KEY", "SECRET", "PASSWORD", "TOKEN", "CREDENTIAL",
    ]

    async def _run_checks(self, result: ValidationResult) -> None:
        """Run environment validation checks."""
        # Check required env vars
        for var in ValidatorConfig.REQUIRED_ENV_VARS:
            if not os.getenv(var):
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.CRITICAL,
                    code=f"ENV_MISSING_{var}",
                    message=f"Required environment variable not set: {var}",
                    fix_suggestion=f"Set {var} in your shell or .env file",
                    fix_command=f"export {var}='your_value'",
                )

        # Validate typed env vars
        for var, spec in self.ENV_SPECS.items():
            value = os.getenv(var)
            if value is None:
                continue  # Skip unset optional vars

            await self._validate_env_var(result, var, value, spec)

        # Check for exposed secrets
        await self._check_secret_exposure(result)

    async def _validate_env_var(
        self,
        result: ValidationResult,
        var: str,
        value: str,
        spec: Dict[str, Any],
    ) -> None:
        """Validate a single environment variable."""
        var_type = spec.get("type", "str")

        if var_type == "int":
            try:
                int_val = int(value)
                if "min" in spec and int_val < spec["min"]:
                    result.add_issue(
                        category=self.category,
                        severity=ValidationSeverity.ERROR,
                        code=f"ENV_RANGE_{var}",
                        message=f"{var}={value} is below minimum {spec['min']}",
                        fix_suggestion=f"Set {var} to a value >= {spec['min']}",
                    )
                if "max" in spec and int_val > spec["max"]:
                    result.add_issue(
                        category=self.category,
                        severity=ValidationSeverity.ERROR,
                        code=f"ENV_RANGE_{var}",
                        message=f"{var}={value} is above maximum {spec['max']}",
                        fix_suggestion=f"Set {var} to a value <= {spec['max']}",
                    )
            except ValueError:
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.ERROR,
                    code=f"ENV_TYPE_{var}",
                    message=f"{var}='{value}' is not a valid integer",
                    fix_suggestion=f"Set {var} to an integer value",
                )

        elif var_type == "float":
            try:
                float_val = float(value)
                if "min" in spec and float_val < spec["min"]:
                    result.add_issue(
                        category=self.category,
                        severity=ValidationSeverity.ERROR,
                        code=f"ENV_RANGE_{var}",
                        message=f"{var}={value} is below minimum {spec['min']}",
                    )
                if "max" in spec and float_val > spec["max"]:
                    result.add_issue(
                        category=self.category,
                        severity=ValidationSeverity.ERROR,
                        code=f"ENV_RANGE_{var}",
                        message=f"{var}={value} is above maximum {spec['max']}",
                    )
            except ValueError:
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.ERROR,
                    code=f"ENV_TYPE_{var}",
                    message=f"{var}='{value}' is not a valid float",
                )

        elif var_type == "bool":
            if value.lower() not in ("true", "false", "1", "0", "yes", "no", "on", "off"):
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.WARNING,
                    code=f"ENV_TYPE_{var}",
                    message=f"{var}='{value}' is not a standard boolean",
                    fix_suggestion="Use 'true' or 'false'",
                )

        elif var_type == "path":
            path = Path(value).expanduser()
            if not path.exists():
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.WARNING,
                    code=f"ENV_PATH_{var}",
                    message=f"{var}='{value}' path does not exist",
                    fix_suggestion=f"Create directory or update {var}",
                    fix_command=f"mkdir -p '{path}'",
                )

    async def _check_secret_exposure(self, result: ValidationResult) -> None:
        """Check for potentially exposed secrets."""
        for var in os.environ:
            if any(pattern in var.upper() for pattern in self.SECRET_PATTERNS):
                value = os.getenv(var, "")
                # Check if secret is in command line (visible in ps)
                if value and value in " ".join(sys.argv):
                    result.add_issue(
                        category=self.category,
                        severity=ValidationSeverity.WARNING,
                        code=f"ENV_SECRET_EXPOSED_{var}",
                        message=f"Secret {var} may be exposed in command line arguments",
                        fix_suggestion="Use environment variables or .env file instead of CLI args",
                    )


# =============================================================================
# File System Validator
# =============================================================================

class FileSystemValidator(BaseValidator):
    """
    Validates file system permissions, paths, and disk space.

    Features:
    - Write permission testing
    - Disk space monitoring
    - Inode availability check
    - File handle limit check
    """

    category = ValidationCategory.FILESYSTEM

    async def _run_checks(self, result: ValidationResult) -> None:
        """Run file system validation checks."""
        checks = [
            lambda: self._check_directory_permissions(result),
            lambda: self._check_disk_space(result),
            lambda: self._check_file_handles(result),
        ]
        await self._parallel_checks(checks)

    async def _check_directory_permissions(self, result: ValidationResult) -> None:
        """Check write permissions for required directories."""
        required_dirs = [
            ValidatorConfig.JARVIS_HOME,
            ValidatorConfig.STATE_DIR,
            ValidatorConfig.LOGS_DIR,
        ]

        for dir_path in required_dirs:
            try:
                dir_path.mkdir(parents=True, exist_ok=True)

                # Test write capability
                test_file = dir_path / f".write_test_{os.getpid()}"
                test_file.write_text("test")
                test_file.unlink()

            except PermissionError:
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.CRITICAL,
                    code=f"FS_NO_WRITE_{dir_path.name}",
                    message=f"Cannot write to required directory: {dir_path}",
                    fix_suggestion="Check permissions or ownership",
                    fix_command=f"chmod 755 '{dir_path}' && chown $USER '{dir_path}'",
                )
            except Exception as e:
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.ERROR,
                    code=f"FS_ACCESS_{dir_path.name}",
                    message=f"Cannot access directory {dir_path}: {e}",
                )

    async def _check_disk_space(self, result: ValidationResult) -> None:
        """Check available disk space."""
        try:
            import shutil
            total, used, free = shutil.disk_usage(ValidatorConfig.JARVIS_HOME)
            free_gb = free / (1024 ** 3)

            if free_gb < ValidatorConfig.MIN_DISK_GB:
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.WARNING,
                    code="FS_LOW_DISK",
                    message=f"Low disk space: {free_gb:.1f}GB free (minimum: {ValidatorConfig.MIN_DISK_GB}GB)",
                    fix_suggestion="Free up disk space or use external storage",
                    metadata={"free_gb": free_gb, "used_gb": used / (1024 ** 3)},
                )
        except Exception as e:
            self.logger.debug(f"Disk space check failed: {e}")

    async def _check_file_handles(self, result: ValidationResult) -> None:
        """Check file handle limits."""
        try:
            import resource
            soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)

            if soft < 1024:
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.WARNING,
                    code="FS_LOW_HANDLES",
                    message=f"Low file handle limit: {soft} (recommended: 1024+)",
                    fix_suggestion="Increase ulimit",
                    fix_command=f"ulimit -n 4096",
                    metadata={"soft_limit": soft, "hard_limit": hard},
                )
        except (ImportError, AttributeError):
            pass  # Windows doesn't have resource module


# =============================================================================
# Network Validator
# =============================================================================

class NetworkValidator(BaseValidator):
    """
    Validates network connectivity and port availability.

    Features:
    - Port availability checking
    - Local network connectivity
    - DNS resolution
    - External connectivity (optional)
    """

    category = ValidationCategory.NETWORK

    async def _run_checks(self, result: ValidationResult) -> None:
        """Run network validation checks."""
        if not ValidatorConfig.ENABLE_NETWORK_VALIDATION:
            return

        checks = [
            lambda: self._check_ports(result),
            lambda: self._check_localhost(result),
        ]
        await self._parallel_checks(checks)

    async def _check_ports(self, result: ValidationResult) -> None:
        """Check if required ports are available."""
        for port in ValidatorConfig.REQUIRED_PORTS:
            try:
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.settimeout(ValidatorConfig.NETWORK_CHECK_TIMEOUT)
                connect_result = sock.connect_ex(('localhost', port))
                sock.close()

                if connect_result == 0:
                    # Port is in use
                    # Try to identify what's using it
                    process_info = await self._identify_port_user(port)

                    result.add_issue(
                        category=self.category,
                        severity=ValidationSeverity.WARNING,
                        code=f"NET_PORT_IN_USE_{port}",
                        message=f"Port {port} is already in use" + (f" by {process_info}" if process_info else ""),
                        fix_suggestion="The existing process will be cleaned up if it's a JARVIS process",
                        metadata={"port": port, "process": process_info},
                    )
            except socket.error as e:
                self.logger.debug(f"Port check for {port} failed: {e}")

    async def _check_localhost(self, result: ValidationResult) -> None:
        """Check localhost connectivity."""
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(1.0)
            sock.bind(('localhost', 0))  # Bind to any available port
            sock.close()
        except socket.error as e:
            result.add_issue(
                category=self.category,
                severity=ValidationSeverity.ERROR,
                code="NET_LOCALHOST_FAIL",
                message=f"Cannot bind to localhost: {e}",
                fix_suggestion="Check network configuration or firewall settings",
            )

    async def _identify_port_user(self, port: int) -> Optional[str]:
        """Try to identify what process is using a port."""
        try:
            import psutil
            for conn in psutil.net_connections(kind='tcp'):
                if conn.laddr.port == port and conn.status == 'LISTEN':
                    try:
                        proc = psutil.Process(conn.pid)
                        return f"{proc.name()} (PID {conn.pid})"
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        return f"PID {conn.pid}"
        except ImportError:
            pass
        return None


# =============================================================================
# Process Validator
# =============================================================================

class ProcessValidator(BaseValidator):
    """
    Validates running processes and detects orphaned JARVIS instances.

    Features:
    - Orphan detection with PID validation
    - Zombie process detection
    - Process tree analysis
    """

    category = ValidationCategory.PROCESS

    async def _run_checks(self, result: ValidationResult) -> None:
        """Run process validation checks."""
        await self._check_orphan_processes(result)
        await self._check_zombie_processes(result)

    async def _check_orphan_processes(self, result: ValidationResult) -> None:
        """Check for orphaned JARVIS processes."""
        try:
            import psutil

            current_pid = os.getpid()
            orphans = []

            for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'create_time']):
                try:
                    if proc.info['pid'] == current_pid:
                        continue

                    cmdline = ' '.join(proc.info.get('cmdline', []) or []).lower()

                    # Detect JARVIS-related processes
                    if any(marker in cmdline for marker in ['jarvis', 'j-prime', 'reactor-core']):
                        orphans.append({
                            'pid': proc.info['pid'],
                            'name': proc.info['name'],
                            'cmdline': cmdline[:100],
                            'age_seconds': time.time() - proc.info['create_time'],
                        })
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue

            if orphans:
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.INFO,
                    code="PROC_ORPHANS_FOUND",
                    message=f"Found {len(orphans)} existing JARVIS-related process(es)",
                    fix_suggestion="Will be cleaned up automatically during startup",
                    metadata={"orphans": orphans},
                )

        except ImportError:
            result.add_issue(
                category=self.category,
                severity=ValidationSeverity.INFO,
                code="PROC_NO_PSUTIL",
                message="psutil not available - process validation limited",
                fix_suggestion="Install psutil for better process management",
                fix_command="pip install psutil",
            )

    async def _check_zombie_processes(self, result: ValidationResult) -> None:
        """Check for zombie processes."""
        try:
            import psutil

            zombies = [
                p for p in psutil.process_iter(['pid', 'status'])
                if p.info['status'] == psutil.STATUS_ZOMBIE
            ]

            if len(zombies) > 10:  # Threshold
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.WARNING,
                    code="PROC_ZOMBIES",
                    message=f"High number of zombie processes: {len(zombies)}",
                    fix_suggestion="Reboot or investigate parent process handling",
                )
        except ImportError:
            pass


# =============================================================================
# Resource Validator
# =============================================================================

class ResourceValidator(BaseValidator):
    """
    Validates system resources (memory, CPU, GPU).

    Features:
    - Memory availability check
    - CPU usage monitoring
    - GPU availability detection
    - Adaptive threshold adjustment
    """

    category = ValidationCategory.RESOURCE

    async def _run_checks(self, result: ValidationResult) -> None:
        """Run resource validation checks."""
        if not ValidatorConfig.ENABLE_RESOURCE_VALIDATION:
            return

        checks = [
            lambda: self._check_memory(result),
            lambda: self._check_cpu(result),
            lambda: self._check_gpu(result),
        ]
        await self._parallel_checks(checks)

    async def _check_memory(self, result: ValidationResult) -> None:
        """Check available memory."""
        try:
            import psutil
            mem = psutil.virtual_memory()
            available_gb = mem.available / (1024 ** 3)

            if available_gb < ValidatorConfig.MIN_MEMORY_GB:
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.WARNING,
                    code="RES_LOW_MEMORY",
                    message=f"Low memory: {available_gb:.1f}GB available (recommended: {ValidatorConfig.MIN_MEMORY_GB}GB)",
                    fix_suggestion="Close applications or enable cloud inference mode",
                    metadata={
                        "available_gb": available_gb,
                        "total_gb": mem.total / (1024 ** 3),
                        "percent_used": mem.percent,
                    },
                )
            elif available_gb < ValidatorConfig.MIN_MEMORY_GB * 2:
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.INFO,
                    code="RES_MODERATE_MEMORY",
                    message=f"Moderate memory available: {available_gb:.1f}GB",
                    metadata={"available_gb": available_gb},
                )
        except ImportError:
            pass

    async def _check_cpu(self, result: ValidationResult) -> None:
        """Check CPU usage."""
        try:
            import psutil
            cpu_percent = psutil.cpu_percent(interval=0.5)

            if cpu_percent > ValidatorConfig.MAX_CPU_PERCENT:
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.WARNING,
                    code="RES_HIGH_CPU",
                    message=f"High CPU usage: {cpu_percent:.1f}%",
                    fix_suggestion="Wait for other processes to complete or reduce concurrency",
                    metadata={"cpu_percent": cpu_percent},
                )
        except ImportError:
            pass

    async def _check_gpu(self, result: ValidationResult) -> None:
        """Check GPU availability for ML workloads."""
        gpu_info = {"available": False, "type": None, "memory_gb": None}

        # Check CUDA
        try:
            import torch
            if torch.cuda.is_available():
                gpu_info["available"] = True
                gpu_info["type"] = "CUDA"
                gpu_info["device_name"] = torch.cuda.get_device_name(0)
                gpu_info["memory_gb"] = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
        except ImportError:
            pass

        # Check MPS (Apple Silicon)
        if not gpu_info["available"]:
            try:
                import torch
                if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    gpu_info["available"] = True
                    gpu_info["type"] = "MPS"
                    gpu_info["device_name"] = "Apple Silicon"
            except ImportError:
                pass

        result.add_issue(
            category=self.category,
            severity=ValidationSeverity.INFO,
            code="RES_GPU_STATUS",
            message=f"GPU: {'Available' if gpu_info['available'] else 'Not available'}" +
                    (f" ({gpu_info['type']}: {gpu_info.get('device_name', 'Unknown')})" if gpu_info['available'] else ""),
            metadata=gpu_info,
        )


# =============================================================================
# Dependency Validator
# =============================================================================

class DependencyValidator(BaseValidator):
    """
    Validates Python dependencies and package versions.

    Features:
    - Package availability check
    - Version compatibility validation
    - Lazy import testing
    """

    category = ValidationCategory.DEPENDENCY

    async def _run_checks(self, result: ValidationResult) -> None:
        """Run dependency validation checks."""
        # Check required packages in parallel
        async def check_package(package: str, required: bool):
            try:
                importlib.import_module(package)
            except ImportError as e:
                severity = ValidationSeverity.CRITICAL if required else ValidationSeverity.WARNING
                result.add_issue(
                    category=self.category,
                    severity=severity,
                    code=f"DEP_MISSING_{package.upper()}",
                    message=f"{'Required' if required else 'Optional'} package not found: {package}",
                    fix_suggestion=f"Install the package",
                    fix_command=f"pip install {package}",
                )

        checks = [
            lambda p=pkg: check_package(p, True)
            for pkg in ValidatorConfig.REQUIRED_PACKAGES
        ] + [
            lambda p=pkg: check_package(p, False)
            for pkg in ValidatorConfig.OPTIONAL_PACKAGES
        ]

        await self._parallel_checks(checks, max_concurrent=5)


# =============================================================================
# Configuration Validator
# =============================================================================

class ConfigurationValidator(BaseValidator):
    """
    Validates configuration consistency and conflicts.

    Features:
    - Conflict detection
    - Circular dependency detection
    - Configuration file validation
    """

    category = ValidationCategory.CONFIGURATION

    async def _run_checks(self, result: ValidationResult) -> None:
        """Run configuration validation checks."""
        await self._check_conflicts(result)
        await self._check_config_files(result)

    async def _check_conflicts(self, result: ValidationResult) -> None:
        """Check for conflicting configurations."""
        # Docker and Cloud Run conflict
        use_docker = _env_bool("JARVIS_PRIME_USE_DOCKER", False)
        use_cloud_run = _env_bool("JARVIS_PRIME_USE_CLOUD_RUN", False)

        if use_docker and use_cloud_run:
            result.add_issue(
                category=self.category,
                severity=ValidationSeverity.ERROR,
                code="CFG_CONFLICT_DOCKER_CLOUD",
                message="Cannot use both Docker and Cloud Run for JARVIS Prime",
                fix_suggestion="Set only one of JARVIS_PRIME_USE_DOCKER or JARVIS_PRIME_USE_CLOUD_RUN to true",
            )

        # Local and Cloud mode conflict
        force_local = _env_bool("JARVIS_PRIME_FORCE_LOCAL", False)
        force_cloud = _env_bool("JARVIS_PRIME_FORCE_CLOUD", False)

        if force_local and force_cloud:
            result.add_issue(
                category=self.category,
                severity=ValidationSeverity.ERROR,
                code="CFG_CONFLICT_LOCAL_CLOUD",
                message="Cannot force both local and cloud mode",
                fix_suggestion="Set only one of JARVIS_PRIME_FORCE_LOCAL or JARVIS_PRIME_FORCE_CLOUD",
            )

    async def _check_config_files(self, result: ValidationResult) -> None:
        """Check configuration files for validity."""
        # Check for .env file
        env_file = Path.cwd() / ".env"
        if env_file.exists():
            try:
                content = env_file.read_text()
                # Basic syntax check
                for line_num, line in enumerate(content.split('\n'), 1):
                    line = line.strip()
                    if line and not line.startswith('#') and '=' not in line:
                        result.add_issue(
                            category=self.category,
                            severity=ValidationSeverity.WARNING,
                            code=f"CFG_ENV_SYNTAX_{line_num}",
                            message=f".env line {line_num} has invalid syntax: {line[:50]}",
                        )
            except Exception as e:
                result.add_issue(
                    category=self.category,
                    severity=ValidationSeverity.WARNING,
                    code="CFG_ENV_READ_ERROR",
                    message=f"Cannot read .env file: {e}",
                )


# =============================================================================
# Cross-Repo Validator
# =============================================================================

class CrossRepoValidator(BaseValidator):
    """
    Validates cross-repository integration (JARVIS, JARVIS Prime, Reactor Core).

    Features:
    - Repository path validation
    - Version compatibility checking
    - Bridge file validation
    - Heartbeat file validation
    """

    category = ValidationCategory.CROSS_REPO

    async def _run_checks(self, result: ValidationResult) -> None:
        """Run cross-repo validation checks."""
        if not ValidatorConfig.ENABLE_CROSS_REPO_VALIDATION:
            return

        checks = [
            lambda: self._check_jarvis_prime(result),
            lambda: self._check_reactor_core(result),
            lambda: self._check_bridge_state(result),
        ]
        await self._parallel_checks(checks)

    async def _check_jarvis_prime(self, result: ValidationResult) -> None:
        """Check JARVIS Prime repository."""
        if not ValidatorConfig.JARVIS_PRIME_PATH:
            return

        path = ValidatorConfig.JARVIS_PRIME_PATH

        if not path.exists():
            result.add_issue(
                category=self.category,
                severity=ValidationSeverity.WARNING,
                code="XREPO_JPRIME_NOT_FOUND",
                message=f"JARVIS Prime repository not found: {path}",
                component="jarvis_prime",
                fix_suggestion="Clone jarvis-prime repository or update JARVIS_PRIME_PATH",
                fix_command=f"git clone https://github.com/your-org/jarvis-prime.git '{path}'",
            )
            return

        # Check for signature files
        signature_files = [
            path / "jarvis_prime" / "__init__.py",
            path / "run_server.py",
        ]

        if not any(f.exists() for f in signature_files):
            result.add_issue(
                category=self.category,
                severity=ValidationSeverity.WARNING,
                code="XREPO_JPRIME_INVALID",
                message=f"JARVIS Prime path exists but doesn't appear to be valid: {path}",
                component="jarvis_prime",
            )
        else:
            result.add_issue(
                category=self.category,
                severity=ValidationSeverity.INFO,
                code="XREPO_JPRIME_OK",
                message=f"JARVIS Prime repository found: {path}",
                component="jarvis_prime",
            )

    async def _check_reactor_core(self, result: ValidationResult) -> None:
        """Check Reactor Core repository."""
        if not ValidatorConfig.REACTOR_CORE_PATH:
            return

        path = ValidatorConfig.REACTOR_CORE_PATH

        if not path.exists():
            result.add_issue(
                category=self.category,
                severity=ValidationSeverity.WARNING,
                code="XREPO_REACTOR_NOT_FOUND",
                message=f"Reactor Core repository not found: {path}",
                component="reactor_core",
                fix_suggestion="Clone reactor-core repository or update REACTOR_CORE_PATH",
            )
            return

        result.add_issue(
            category=self.category,
            severity=ValidationSeverity.INFO,
            code="XREPO_REACTOR_OK",
            message=f"Reactor Core repository found: {path}",
            component="reactor_core",
        )

    async def _check_bridge_state(self, result: ValidationResult) -> None:
        """Check cross-repo bridge state files."""
        bridge_file = ValidatorConfig.JARVIS_HOME / "cross_repo" / "bridge_state.json"

        if bridge_file.exists():
            try:
                state = json.loads(bridge_file.read_text())
                age = time.time() - state.get("started_at", 0)

                if age < 30:  # Less than 30 seconds old
                    result.add_issue(
                        category=self.category,
                        severity=ValidationSeverity.WARNING,
                        code="XREPO_BRIDGE_RECENT",
                        message=f"Recent bridge state found ({age:.0f}s old) - another instance may be running",
                        metadata={"age_seconds": age, "session_id": state.get("session_id")},
                    )
            except Exception as e:
                self.logger.debug(f"Bridge state check failed: {e}")


# =============================================================================
# Self-Healing Suggestion Engine
# =============================================================================

class SelfHealingSuggestionEngine:
    """
    Generates actionable fix suggestions based on validation issues.

    Features:
    - Automated fix command generation
    - Priority-based suggestion ordering
    - Fix dependency analysis
    """

    def __init__(self):
        self.logger = logging.getLogger("SelfHealing")

    def generate_fix_script(self, result: ValidationResult) -> Optional[str]:
        """Generate a shell script to fix all fixable issues."""
        commands = []

        for issue in result.issues:
            if issue.fix_command:
                commands.append(f"# Fix: {issue.message}")
                commands.append(issue.fix_command)
                commands.append("")

        if not commands:
            return None

        script = "#!/bin/bash\n"
        script += "# Auto-generated fix script for JARVIS validation issues\n"
        script += f"# Generated: {datetime.now().isoformat()}\n\n"
        script += "set -e  # Exit on error\n\n"
        script += "\n".join(commands)

        return script

    def save_fix_script(self, result: ValidationResult) -> Optional[Path]:
        """Save fix script to file."""
        script = self.generate_fix_script(result)
        if not script:
            return None

        script_path = ValidatorConfig.STATE_DIR / "fix_validation_issues.sh"
        script_path.parent.mkdir(parents=True, exist_ok=True)
        script_path.write_text(script)
        script_path.chmod(0o755)

        return script_path


# =============================================================================
# Main Validator Orchestrator
# =============================================================================

class TrinityBootstrapValidator:
    """
    Main validator orchestrator that runs all validation checks in parallel.

    Usage:
        validator = TrinityBootstrapValidator()
        result = await validator.validate_all()

        if not result.passed:
            for issue in result.critical_issues:
                print(f"CRITICAL: {issue}")
            sys.exit(1)
    """

    def __init__(self):
        self.logger = logging.getLogger("TrinityValidator")
        self.self_healing = SelfHealingSuggestionEngine()

        # Initialize all validators
        self.validators: List[BaseValidator] = [
            EnvironmentValidator(),
            FileSystemValidator(),
            NetworkValidator(),
            ProcessValidator(),
            ResourceValidator(),
            DependencyValidator(),
            ConfigurationValidator(),
            CrossRepoValidator(),
        ]

    async def validate_all(self) -> ValidationResult:
        """
        Run all validation checks in parallel.

        Returns:
            ValidationResult with all issues collected
        """
        result = ValidationResult()

        self.logger.info("Starting Trinity bootstrap validation...")

        try:
            # Run all validators in parallel using TaskGroup (Python 3.11+)
            try:
                async with asyncio.TaskGroup() as tg:
                    for validator in self.validators:
                        tg.create_task(validator.validate(result))
            except AttributeError:
                # Fallback for Python < 3.11
                await asyncio.gather(
                    *[v.validate(result) for v in self.validators],
                    return_exceptions=True,
                )
        except Exception as e:
            result.add_issue(
                category=ValidationCategory.CONFIGURATION,
                severity=ValidationSeverity.ERROR,
                code="VAL_ORCHESTRATOR_ERROR",
                message=f"Validation orchestrator error: {e}",
                include_traceback=True,
            )

        result.finalize()

        # Log summary
        self.logger.info(
            f"Validation complete: {len(result.issues)} issues found "
            f"({len(result.critical_issues)} critical, {len(result.errors)} errors, "
            f"{len(result.warnings)} warnings) in {result.duration_ms:.0f}ms"
        )

        if not result.passed:
            self.logger.error("Validation FAILED - cannot start JARVIS")

            # Generate fix script if possible
            fix_script_path = self.self_healing.save_fix_script(result)
            if fix_script_path:
                self.logger.info(f"Fix script generated: {fix_script_path}")

        return result

    async def validate_and_report(self) -> Tuple[bool, str]:
        """
        Run validation and return formatted report.

        Returns:
            Tuple of (passed, report_string)
        """
        result = await self.validate_all()

        lines = []
        lines.append("=" * 60)
        lines.append("TRINITY BOOTSTRAP VALIDATION REPORT")
        lines.append("=" * 60)
        lines.append(f"Status: {'PASSED âœ“' if result.passed else 'FAILED âœ—'}")
        lines.append(f"Duration: {result.duration_ms:.0f}ms")
        lines.append(f"Issues: {len(result.issues)} total")
        lines.append("")

        if result.critical_issues:
            lines.append("CRITICAL ISSUES (must fix):")
            for issue in result.critical_issues:
                lines.append(f"  {issue}")
                if issue.fix_suggestion:
                    lines.append(f"    Fix: {issue.fix_suggestion}")
            lines.append("")

        if result.errors:
            lines.append("ERRORS:")
            for issue in result.errors:
                lines.append(f"  {issue}")
            lines.append("")

        if result.warnings:
            lines.append("WARNINGS:")
            for issue in result.warnings:
                lines.append(f"  {issue}")
            lines.append("")

        lines.append("=" * 60)

        return result.passed, "\n".join(lines)


# =============================================================================
# Module-Level Convenience Functions
# =============================================================================

_validator_instance: Optional[TrinityBootstrapValidator] = None


async def get_validator() -> TrinityBootstrapValidator:
    """Get or create the global validator instance."""
    global _validator_instance
    if _validator_instance is None:
        _validator_instance = TrinityBootstrapValidator()
    return _validator_instance


async def validate_bootstrap() -> ValidationResult:
    """Convenience function to run validation."""
    validator = await get_validator()
    return await validator.validate_all()


async def validate_and_exit_on_failure() -> ValidationResult:
    """Run validation and exit if failed."""
    result = await validate_bootstrap()

    if not result.passed:
        print("\n" + "=" * 60)
        print("JARVIS BOOTSTRAP VALIDATION FAILED")
        print("=" * 60)

        for issue in result.critical_issues + result.errors:
            print(f"\n{issue}")
            if issue.fix_suggestion:
                print(f"  â†’ {issue.fix_suggestion}")
            if issue.fix_command:
                print(f"  $ {issue.fix_command}")

        print("\n" + "=" * 60)
        sys.exit(1)

    return result


# =============================================================================
# CLI Entry Point
# =============================================================================

if __name__ == "__main__":
    async def main():
        validator = TrinityBootstrapValidator()
        passed, report = await validator.validate_and_report()
        print(report)
        sys.exit(0 if passed else 1)

    asyncio.run(main())
