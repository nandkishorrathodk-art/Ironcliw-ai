"""
Memory-Aware Startup Manager
============================

Intelligent startup system that detects available RAM and automatically
activates hybrid cloud architecture when local resources are constrained.

Features:
- Detects available RAM at startup using macOS vm_stat
- Automatically activates cloud-first mode when RAM < threshold
- Spins up GCP Spot VM for heavy ML processing
- Configures hybrid router to offload ML to cloud
- Zero hardcoding - all thresholds configurable
- Async throughout for non-blocking operations

This solves the "Startup timeout - please check logs" issue caused by
trying to load heavy ML models (Whisper, SpeechBrain, ECAPA-TDNN) on
RAM-constrained systems.

Usage:
    from core.memory_aware_startup import MemoryAwareStartup

    startup_manager = MemoryAwareStartup()
    startup_mode = await startup_manager.determine_startup_mode()

    if startup_mode.use_cloud_ml:
        await startup_manager.activate_cloud_ml_backend()
"""

import asyncio
import logging
import os
import subprocess
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Dict, List, Optional, Tuple, Any

logger = logging.getLogger(__name__)


class StartupMode(Enum):
    """Startup mode based on available resources

    IMPORTANT: We eliminated LOCAL_MINIMAL mode because it caused "Processing..." hangs.

    The problem with LOCAL_MINIMAL (4-6GB):
    - It skipped preloading ML models to save RAM at startup
    - But when user said "unlock my screen", it tried to load them locally
    - This caused RAM spikes and the "Processing..." freeze

    The fix: If we can't run FULL LOCAL, go straight to CLOUD_FIRST.
    This way, GCP handles ML processing and local RAM stays stable.
    """
    LOCAL_FULL = "local_full"          # Full local ML loading (RAM >= 6GB free)
    CLOUD_FIRST = "cloud_first"        # Skip local ML, use GCP (< 6GB free) - INSTANT response!
    CLOUD_ONLY = "cloud_only"          # Critical RAM, all ML on cloud (< 2GB free)


@dataclass
class MemoryStatus:
    """Current memory status on the system"""
    total_gb: float
    used_gb: float
    free_gb: float
    available_gb: float  # Including reclaimable
    compressed_gb: float
    wired_gb: float
    page_outs: int
    memory_pressure: float  # 0-100%

    @property
    def is_under_pressure(self) -> bool:
        """Check if system is under memory pressure"""
        return self.memory_pressure > 70 or self.page_outs > 1000

    @property
    def is_critical(self) -> bool:
        """Check if memory is critically low"""
        return self.available_gb < 2.0 or self.memory_pressure > 85


@dataclass
class StartupDecision:
    """Decision about how to start the system"""
    mode: StartupMode
    use_cloud_ml: bool
    skip_local_whisper: bool
    skip_local_speechbrain: bool
    skip_local_ecapa: bool
    skip_component_warmup: bool
    skip_neural_mesh: bool
    gcp_vm_required: bool
    reason: str
    memory_status: MemoryStatus
    recommendations: List[str] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for logging/storage"""
        return {
            "mode": self.mode.value,
            "use_cloud_ml": self.use_cloud_ml,
            "skip_local_whisper": self.skip_local_whisper,
            "skip_local_speechbrain": self.skip_local_speechbrain,
            "skip_local_ecapa": self.skip_local_ecapa,
            "skip_component_warmup": self.skip_component_warmup,
            "skip_neural_mesh": self.skip_neural_mesh,
            "gcp_vm_required": self.gcp_vm_required,
            "reason": self.reason,
            "memory_free_gb": self.memory_status.free_gb,
            "memory_available_gb": self.memory_status.available_gb,
            "memory_pressure": self.memory_status.memory_pressure,
            "recommendations": self.recommendations,
        }


class MemoryAwareStartup:
    """
    Intelligent startup manager that adapts to available system resources.

    Automatically detects RAM constraints and activates cloud-first mode
    to prevent startup timeouts from heavy ML model loading.
    """

    # Default thresholds (can be overridden via env vars)
    # IMPORTANT: Cloud threshold now equals full local threshold - NO GAP!
    # This eliminates the "Processing..." hang caused by lazy local loading.
    DEFAULT_FULL_LOCAL_THRESHOLD_GB = 6.0   # Free RAM needed for full local ML
    DEFAULT_CLOUD_FIRST_THRESHOLD_GB = 6.0  # If < 6GB, go straight to cloud (was 4GB - caused hangs!)
    DEFAULT_CLOUD_ONLY_THRESHOLD_GB = 2.0   # Below this = critical cloud only mode

    # ML model memory requirements (approximate)
    ML_MODEL_MEMORY = {
        "whisper_base": 0.5,      # Whisper base model
        "whisper_small": 1.0,     # Whisper small model
        "whisper_medium": 2.0,    # Whisper medium model
        "speechbrain": 0.3,       # SpeechBrain base
        "ecapa_tdnn": 0.2,        # ECAPA-TDNN 192D
        "pytorch_base": 0.5,      # PyTorch runtime
        "transformers": 0.3,      # Transformers library
        "neural_mesh": 0.8,       # Neural mesh system
        "component_warmup": 0.5,  # Warmup overhead
    }

    def __init__(self):
        """Initialize the memory-aware startup manager

        ARCHITECTURE DECISION (v17.8.7):
        We eliminated the LOCAL_MINIMAL gap. Now it's binary:
        - RAM >= 6GB ‚Üí LOCAL_FULL (preload everything locally)
        - RAM < 6GB  ‚Üí CLOUD_FIRST (use GCP Spot VM for ML)
        - RAM < 2GB  ‚Üí CLOUD_ONLY (critical mode)

        This prevents the "Processing..." hang that occurred when
        LOCAL_MINIMAL mode deferred model loading until voice unlock.
        """
        # Load thresholds from environment
        self.full_local_threshold = float(
            os.getenv("JARVIS_FULL_LOCAL_RAM_GB", self.DEFAULT_FULL_LOCAL_THRESHOLD_GB)
        )
        # Cloud threshold now equals full local - NO GAP!
        self.cloud_first_threshold = float(
            os.getenv("JARVIS_CLOUD_FIRST_RAM_GB", self.DEFAULT_CLOUD_FIRST_THRESHOLD_GB)
        )
        self.cloud_only_threshold = float(
            os.getenv("JARVIS_CLOUD_ONLY_RAM_GB", self.DEFAULT_CLOUD_ONLY_THRESHOLD_GB)
        )

        # Cloud ML configuration
        self.gcp_project = os.getenv("GCP_PROJECT_ID", "jarvis-473803")
        self.gcp_zone = os.getenv("GCP_ZONE", "us-central1-a")
        self.gcp_vm_type = os.getenv("GCP_ML_VM_TYPE", "e2-highmem-4")

        # State
        self._gcp_vm_manager = None
        self._hybrid_router = None
        self._cloud_ml_active = False
        self._startup_decision: Optional[StartupDecision] = None

        logger.info(f"MemoryAwareStartup initialized (v17.8.7 - NO LOCAL_MINIMAL GAP)")
        logger.info(f"  Full local threshold: {self.full_local_threshold}GB")
        logger.info(f"  Cloud-first threshold: {self.cloud_first_threshold}GB (equals full local - no gap!)")
        logger.info(f"  Cloud-only threshold: {self.cloud_only_threshold}GB")

    async def get_memory_status(self) -> MemoryStatus:
        """
        Get current memory status (cross-platform: psutil on Windows/Linux, vm_stat on macOS).

        Returns:
            MemoryStatus: Current memory status
        """
        try:
            import sys as _sys
            import psutil as _psutil

            vm = _psutil.virtual_memory()
            total_gb = vm.total / (1024**3)
            available_gb = vm.available / (1024**3)
            used_gb = (vm.total - vm.available) / (1024**3)
            free_gb = vm.free / (1024**3)
            memory_pressure = vm.percent

            swap = _psutil.swap_memory()
            page_outs = getattr(swap, 'sout', 0)

            return MemoryStatus(
                total_gb=total_gb,
                used_gb=used_gb,
                free_gb=free_gb,
                available_gb=available_gb,
                compressed_gb=0.0,
                wired_gb=0.0,
                page_outs=page_outs,
                memory_pressure=memory_pressure,
            )

        except Exception as e:
            logger.error(f"Failed to get memory status: {e}")
            # Return conservative defaults
            return MemoryStatus(
                total_gb=16.0,
                used_gb=14.0,
                free_gb=2.0,
                available_gb=2.0,
                compressed_gb=2.0,
                wired_gb=2.0,
                page_outs=0,
                memory_pressure=87.5,
            )

    async def determine_startup_mode(self) -> StartupDecision:
        """
        Determine the optimal startup mode based on available resources.

        Returns:
            StartupDecision: Decision about how to start the system
        """
        memory = await self.get_memory_status()

        logger.info("=" * 60)
        logger.info("üß† MEMORY-AWARE STARTUP ANALYSIS")
        logger.info("=" * 60)
        logger.info(f"  Total RAM: {memory.total_gb:.1f} GB")
        logger.info(f"  Used: {memory.used_gb:.1f} GB ({memory.memory_pressure:.1f}%)")
        logger.info(f"  Free: {memory.free_gb:.1f} GB")
        logger.info(f"  Available (with reclaimable): {memory.available_gb:.1f} GB")
        logger.info(f"  Compressed: {memory.compressed_gb:.1f} GB")
        logger.info(f"  Page outs: {memory.page_outs}")
        logger.info("=" * 60)

        recommendations = []

        # Determine startup mode based on available RAM
        # v17.8.7: BINARY DECISION - No LOCAL_MINIMAL gap that caused "Processing..." hangs!
        if memory.available_gb >= self.full_local_threshold:
            # Plenty of RAM - full local mode (preload everything)
            decision = StartupDecision(
                mode=StartupMode.LOCAL_FULL,
                use_cloud_ml=False,
                skip_local_whisper=False,
                skip_local_speechbrain=False,
                skip_local_ecapa=False,
                skip_component_warmup=False,
                skip_neural_mesh=False,
                gcp_vm_required=False,
                reason=f"Sufficient RAM ({memory.available_gb:.1f}GB available >= {self.full_local_threshold}GB threshold)",
                memory_status=memory,
                recommendations=["Full local ML loading enabled - instant voice unlock!"],
            )
            logger.info(f"‚úÖ STARTUP MODE: LOCAL_FULL")
            logger.info(f"   Reason: {decision.reason}")
            logger.info(f"   Voice Unlock: Instant (models preloaded locally)")

        elif memory.available_gb >= self.cloud_only_threshold:
            # NOT ENOUGH RAM FOR LOCAL - GO STRAIGHT TO CLOUD!
            # This is the FIX for "Processing..." hang - we used to have LOCAL_MINIMAL here
            # which deferred loading, causing freezes when user said "unlock my screen"
            recommendations = [
                "üöÄ GCP Spot VM will handle ML processing (instant response!)",
                "üí∞ Cost: ~$0.029/hour for e2-highmem-4 Spot VM",
                "üõ°Ô∏è Your Mac RAM stays stable - no freezing!",
                "Close Chrome tabs if you want to switch to LOCAL_FULL",
            ]
            decision = StartupDecision(
                mode=StartupMode.CLOUD_FIRST,
                use_cloud_ml=True,
                skip_local_whisper=True,
                skip_local_speechbrain=True,
                skip_local_ecapa=True,
                skip_component_warmup=True,
                skip_neural_mesh=True,
                gcp_vm_required=True,
                reason=f"RAM below threshold ({memory.available_gb:.1f}GB < {self.full_local_threshold}GB) - using GCP for ML (prevents Processing... hang!)",
                memory_status=memory,
                recommendations=recommendations,
            )
            logger.info(f"‚òÅÔ∏è  STARTUP MODE: CLOUD_FIRST (v17.8.7 - No more Processing... hangs!)")
            logger.info(f"   Reason: {decision.reason}")
            logger.info(f"   Action: Spinning up GCP Spot VM for ML processing")
            logger.info(f"   Voice Unlock: Cloud-powered (instant, no local RAM spike)")
            logger.info(f"   Cost: ~$0.029/hour Spot VM (auto-terminates when idle)")

        else:
            # Critical RAM - cloud only mode (emergency)
            recommendations = [
                "‚ö†Ô∏è CRITICAL: Close applications immediately",
                "All ML processing will be on GCP",
                "Only essential local services will run",
                "Consider restarting your Mac to clear memory",
            ]
            decision = StartupDecision(
                mode=StartupMode.CLOUD_ONLY,
                use_cloud_ml=True,
                skip_local_whisper=True,
                skip_local_speechbrain=True,
                skip_local_ecapa=True,
                skip_component_warmup=True,
                skip_neural_mesh=True,
                gcp_vm_required=True,
                reason=f"CRITICAL RAM ({memory.available_gb:.1f}GB < {self.cloud_only_threshold}GB) - emergency cloud-only mode",
                memory_status=memory,
                recommendations=recommendations,
            )
            logger.warning(f"üî¥ STARTUP MODE: CLOUD_ONLY (CRITICAL)")
            logger.warning(f"   Reason: {decision.reason}")
            logger.warning(f"   Action: Emergency cloud-only mode - close apps to free RAM!")

        # Log recommendations
        if recommendations:
            logger.info("üìã Recommendations:")
            for rec in recommendations:
                logger.info(f"   ‚Ä¢ {rec}")

        self._startup_decision = decision
        return decision

    async def activate_cloud_ml_backend(self) -> Dict[str, Any]:
        """
        Activate GCP Spot VM for ML processing.

        Returns:
            Dict with activation status and VM details
        """
        logger.info("‚òÅÔ∏è  Activating GCP ML Backend...")

        try:
            # Import GCP VM manager
            from core.gcp_vm_manager import get_gcp_vm_manager, VMManagerConfig, VMInstance, VMState

            # Configure for ML workload
            # Note: VMManagerConfig uses valid fields from gcp_vm_manager.py
            config = VMManagerConfig(
                project_id=self.gcp_project,
                zone=self.gcp_zone,
                machine_type=self.gcp_vm_type,
                use_spot=True,
                spot_max_price=0.10,  # Max cost per hour
                idle_timeout_minutes=15,
            )

            # Get or create VM manager
            self._gcp_vm_manager = await get_gcp_vm_manager(config)
            await self._gcp_vm_manager.initialize()

            # Check if we should create VM
            memory = await self.get_memory_status()

            # Create a memory snapshot with the attributes expected by gcp_vm_manager
            # The should_create_vm expects memory_snapshot with gcp_shift_recommended
            import platform as platform_module
            
            class MemorySnapshot:
                def __init__(self, memory_status):
                    self.gcp_shift_recommended = memory_status.memory_pressure > 70 or memory_status.available_gb < 4.0
                    self.reasoning = f"Memory pressure: {memory_status.memory_pressure:.1f}%, Available: {memory_status.available_gb:.1f}GB"
                    self.memory_pressure = memory_status.memory_pressure
                    self.available_gb = memory_status.available_gb
                    self.used_gb = memory_status.total_gb - memory_status.available_gb
                    self.total_gb = memory_status.total_gb
                    self.usage_percent = memory_status.memory_pressure
                    # Add platform attribute expected by intelligent_gcp_optimizer
                    self.platform = platform_module.system().lower()
                    # macOS specific attributes
                    self.macos_pressure_level = "warning" if memory_status.memory_pressure > 70 else "normal"
                    self.macos_is_swapping = memory_status.memory_pressure > 75
                    self.macos_page_outs = 0
                    # Linux specific attributes (None on macOS)
                    self.linux_psi_some_avg10 = None
                    self.linux_psi_full_avg10 = None

            memory_snapshot = MemorySnapshot(memory)
            should_create, reason, confidence = await self._gcp_vm_manager.should_create_vm(
                memory_snapshot,
                trigger_reason=f"ML processing, voice recognition (pressure={memory.memory_pressure:.0f}%)"
            )

            if should_create:
                logger.info(f"   Creating GCP Spot VM: {reason}")

                # Create VM with ML components
                vm_result = await self._gcp_vm_manager.create_vm(
                    components=["whisper", "speechbrain", "ecapa_tdnn", "ml_models"],
                    trigger_reason=f"Memory-aware startup: {reason}",
                )

                # v132.1: VMInstance is a dataclass, not dict - check state for success
                if vm_result and vm_result.state == VMState.RUNNING:
                    self._cloud_ml_active = True
                    logger.info(f"‚úÖ GCP ML Backend activated!")
                    logger.info(f"   VM: {vm_result.instance_id}")
                    logger.info(f"   IP: {vm_result.ip_address}")
                    logger.info(f"   Cost: ${vm_result.cost_per_hour}/hr")

                    # Configure hybrid router to use GCP for ML
                    await self._configure_hybrid_routing(vm_result)

                    return {
                        "success": True,
                        "mode": "gcp_spot_vm",
                        "vm_id": vm_result.instance_id,
                        "ip": vm_result.ip_address,
                        "cost_per_hour": vm_result.cost_per_hour,
                    }
                else:
                    logger.warning(f"‚ö†Ô∏è  GCP VM creation failed: {vm_result}")
                    return {"success": False, "error": "VM creation failed"}
            else:
                logger.info(f"   GCP VM not needed: {reason}")
                return {"success": True, "mode": "local", "reason": reason}

        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è  GCP VM manager not available: {e}")
            return {"success": False, "error": f"Import error: {e}"}
        except Exception as e:
            logger.error(f"‚ùå Failed to activate GCP ML backend: {e}")
            return {"success": False, "error": str(e)}

    async def _configure_hybrid_routing(self, vm_instance: Any) -> None:
        """
        Configure hybrid router to send ML requests to GCP.

        Args:
            vm_instance: VMInstance dataclass with IP and details
        """
        try:
            from core.hybrid_router import get_hybrid_router

            self._hybrid_router = get_hybrid_router()

            # v132.1: VMInstance is a dataclass - use attribute access
            gcp_ip = vm_instance.ip_address if hasattr(vm_instance, 'ip_address') else None
            if gcp_ip:
                await self._hybrid_router.update_backend_url(
                    backend_name="gcp",
                    url=f"http://{gcp_ip}:8010",
                )

                # Set ML capabilities to route to GCP
                ml_capabilities = [
                    "ml_processing",
                    "whisper_transcription",
                    "speaker_verification",
                    "voice_embedding",
                    "nlp_analysis",
                    "heavy_computation",
                ]

                for capability in ml_capabilities:
                    await self._hybrid_router.set_capability_route(
                        capability=capability,
                        backend="gcp",
                        priority=1,  # High priority
                    )

                logger.info(f"   Hybrid router configured for GCP ML offloading")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Could not configure hybrid routing: {e}")

    async def get_ml_endpoint(self, operation: str) -> str:
        """
        Get the appropriate endpoint for an ML operation.

        Args:
            operation: ML operation type (whisper, speaker_verify, etc.)

        Returns:
            Endpoint URL (local or GCP)
        """
        if self._cloud_ml_active and self._gcp_vm_manager:
            # Get active VM
            active_vms = [
                vm for vm in self._gcp_vm_manager.vms.values()
                if vm.is_healthy
            ]

            if active_vms:
                vm = active_vms[0]
                return f"http://{vm.ip_address}:8010/api/ml/{operation}"

        # Fall back to local
        return f"http://localhost:8010/api/ml/{operation}"

    @property
    def is_cloud_ml_active(self) -> bool:
        """Check if cloud ML backend is active"""
        return self._cloud_ml_active

    @property
    def startup_decision(self) -> Optional[StartupDecision]:
        """Get the startup decision"""
        return self._startup_decision

    async def cleanup(self) -> None:
        """Cleanup resources on shutdown"""
        if self._gcp_vm_manager:
            logger.info("üßπ Cleaning up GCP ML backend...")
            await self._gcp_vm_manager.cleanup_all_vms(
                reason="JARVIS shutdown - memory-aware startup cleanup"
            )


# Global instance
_startup_manager: Optional[MemoryAwareStartup] = None


async def get_startup_manager() -> MemoryAwareStartup:
    """Get or create the global startup manager"""
    global _startup_manager
    if _startup_manager is None:
        _startup_manager = MemoryAwareStartup()
    return _startup_manager


async def determine_startup_mode() -> StartupDecision:
    """
    Convenience function to determine startup mode.

    Returns:
        StartupDecision: Decision about how to start the system
    """
    manager = await get_startup_manager()
    return await manager.determine_startup_mode()


async def activate_cloud_ml_if_needed(decision: StartupDecision) -> Dict[str, Any]:
    """
    Activate cloud ML backend if the startup decision requires it.

    Args:
        decision: Startup decision from determine_startup_mode()

    Returns:
        Dict with activation status
    """
    if decision.gcp_vm_required:
        manager = await get_startup_manager()
        return await manager.activate_cloud_ml_backend()
    return {"success": True, "mode": "local", "reason": "Cloud ML not required"}
