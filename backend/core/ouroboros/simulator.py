"""
The Simulator - Runtime Introspection Engine v1.0
==================================================

"God Mode" Pillar 3: Predictive Execution & Live Debugging

This module gives JARVIS the ability to SEE code execution in real-time,
predict failures before they happen, and understand runtime behavior
without actually running production code.

Key Differences from Static Analysis:
- The Oracle (GraphRAG): "This function CALLS that function" (static)
- The Watcher (LSP): "This symbol IS DEFINED here" (static)
- The Simulator: "This function WILL FAIL with input X because Y" (dynamic)

The Simulator enables:
- Predictive execution: Run code in sandbox to see what happens
- Variable tracing: Track all variable changes during execution
- Call graph recording: See actual execution path at runtime
- Exception prediction: Detect errors before they crash production
- Performance profiling: Find bottlenecks without guessing
- Memory tracking: Detect leaks and excessive allocation
- State machine analysis: Understand program state transitions

Architecture:
- RuntimeTracer: Uses sys.settrace for function/line tracing
- SandboxExecutor: Isolated execution environment using multiprocessing
- MemoryProfiler: Tracks allocations using tracemalloc
- CoverageAnalyzer: Measures code coverage during execution
- ExceptionPredictor: Analyzes code paths for potential failures
- StateRecorder: Records program state for replay/analysis

Integration Points:
- Ouroboros: Validates code changes by simulating execution
- Oracle: Enriches static graph with runtime call patterns
- Watcher: Validates LSP findings with actual runtime behavior

Author: Trinity System
Version: 1.0.0
"""

from __future__ import annotations

import ast
import asyncio
import builtins
import collections
import contextlib
import copy
import dis
import functools
import gc
import inspect
import io
import linecache
import logging
import multiprocessing
import os
import pickle
import queue
import signal
import sys
import tempfile
import threading
import time
import traceback
import tracemalloc
import types
import uuid
import weakref
from abc import ABC, abstractmethod
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, Future
from dataclasses import dataclass, field

# v95.12: Import multiprocessing cleanup tracker
try:
    from core.resilience.graceful_shutdown import register_executor_for_cleanup
    _HAS_MP_TRACKER = True
except ImportError:
    _HAS_MP_TRACKER = False
    def register_executor_for_cleanup(*args, **kwargs):
        pass  # No-op fallback
from datetime import datetime
from enum import Enum, auto
from pathlib import Path
from typing import (
    Any,
    Callable,
    Coroutine,
    Dict,
    Generator,
    Generic,
    Iterator,
    List,
    Optional,
    Set,
    Tuple,
    Type,
    TypeVar,
    Union,
)

logger = logging.getLogger("Ouroboros.Simulator")


# =============================================================================
# CONFIGURATION
# =============================================================================

class SimulatorConfig:
    """Configuration for The Simulator."""

    # Execution limits (safety constraints)
    MAX_EXECUTION_TIME = float(os.getenv("SIMULATOR_MAX_TIME", "30.0"))
    MAX_MEMORY_MB = int(os.getenv("SIMULATOR_MAX_MEMORY", "512"))
    MAX_CALL_DEPTH = int(os.getenv("SIMULATOR_MAX_DEPTH", "100"))
    MAX_ITERATIONS = int(os.getenv("SIMULATOR_MAX_ITERATIONS", "100000"))
    MAX_OUTPUT_SIZE = int(os.getenv("SIMULATOR_MAX_OUTPUT", "1048576"))  # 1MB

    # Tracing settings
    TRACE_CALLS = bool(os.getenv("SIMULATOR_TRACE_CALLS", "1"))
    TRACE_LINES = bool(os.getenv("SIMULATOR_TRACE_LINES", "0"))  # Expensive
    TRACE_RETURNS = bool(os.getenv("SIMULATOR_TRACE_RETURNS", "1"))
    TRACE_EXCEPTIONS = bool(os.getenv("SIMULATOR_TRACE_EXCEPTIONS", "1"))

    # Profiling settings
    ENABLE_MEMORY_PROFILING = bool(os.getenv("SIMULATOR_MEMORY_PROFILE", "1"))
    ENABLE_TIME_PROFILING = bool(os.getenv("SIMULATOR_TIME_PROFILE", "1"))
    PROFILE_SAMPLE_INTERVAL = float(os.getenv("SIMULATOR_SAMPLE_INTERVAL", "0.001"))

    # Sandbox settings
    SANDBOX_PROCESS_POOL_SIZE = int(os.getenv("SIMULATOR_POOL_SIZE", "2"))
    SANDBOX_ALLOWED_MODULES = frozenset([
        "math", "random", "itertools", "functools", "operator",
        "collections", "json", "re", "datetime", "time",
        "typing", "dataclasses", "enum", "pathlib",
        "copy", "pprint", "textwrap", "string",
    ])


# =============================================================================
# DATA TYPES
# =============================================================================

class ExecutionStatus(Enum):
    """Status of code execution."""
    PENDING = auto()
    RUNNING = auto()
    COMPLETED = auto()
    FAILED = auto()
    TIMEOUT = auto()
    MEMORY_EXCEEDED = auto()
    DEPTH_EXCEEDED = auto()
    ITERATION_EXCEEDED = auto()
    SECURITY_VIOLATION = auto()


@dataclass
class CallFrame:
    """Represents a function call frame during execution."""
    frame_id: str
    function_name: str
    module_name: str
    file_path: str
    line_number: int
    args: Dict[str, Any]
    locals: Dict[str, Any]
    timestamp: float
    call_depth: int
    parent_frame_id: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary (for serialization)."""
        return {
            "frame_id": self.frame_id,
            "function_name": self.function_name,
            "module_name": self.module_name,
            "file_path": self.file_path,
            "line_number": self.line_number,
            "args": self._safe_repr(self.args),
            "locals": self._safe_repr(self.locals),
            "timestamp": self.timestamp,
            "call_depth": self.call_depth,
            "parent_frame_id": self.parent_frame_id,
        }

    def _safe_repr(self, obj: Any, max_len: int = 100) -> Any:
        """Safely convert object to string representation."""
        if isinstance(obj, dict):
            return {k: self._safe_repr(v, max_len) for k, v in list(obj.items())[:20]}
        try:
            s = repr(obj)
            return s[:max_len] + "..." if len(s) > max_len else s
        except Exception:
            return f"<{type(obj).__name__}>"


@dataclass
class LineExecution:
    """Represents a single line execution."""
    file_path: str
    line_number: int
    code_line: str
    timestamp: float
    locals_snapshot: Dict[str, str]
    frame_id: str


@dataclass
class ExceptionEvent:
    """Represents an exception during execution."""
    exception_type: str
    exception_message: str
    traceback_lines: List[str]
    file_path: str
    line_number: int
    timestamp: float
    frame_id: str
    local_variables: Dict[str, str]


@dataclass
class MemorySnapshot:
    """Memory usage snapshot."""
    timestamp: float
    current_mb: float
    peak_mb: float
    allocation_count: int
    top_allocations: List[Tuple[str, int]]  # (traceback, size_bytes)


@dataclass
class ExecutionTrace:
    """Complete trace of a code execution."""
    trace_id: str
    start_time: float
    end_time: float
    status: ExecutionStatus
    calls: List[CallFrame]
    lines: List[LineExecution]
    exceptions: List[ExceptionEvent]
    memory_snapshots: List[MemorySnapshot]
    return_value: Optional[Any]
    stdout: str
    stderr: str
    total_calls: int
    total_lines: int
    max_depth: int
    coverage_percent: float

    def to_dict(self) -> Dict[str, Any]:
        """Convert trace to dictionary."""
        return {
            "trace_id": self.trace_id,
            "start_time": self.start_time,
            "end_time": self.end_time,
            "duration_ms": (self.end_time - self.start_time) * 1000,
            "status": self.status.name,
            "total_calls": self.total_calls,
            "total_lines": self.total_lines,
            "max_depth": self.max_depth,
            "coverage_percent": self.coverage_percent,
            "exceptions_count": len(self.exceptions),
            "stdout_length": len(self.stdout),
            "stderr_length": len(self.stderr),
        }


@dataclass
class PredictionResult:
    """Result of execution prediction."""
    will_succeed: bool
    confidence: float
    predicted_issues: List[Dict[str, Any]]
    execution_path: List[str]
    resource_estimate: Dict[str, float]
    recommendations: List[str]


# =============================================================================
# RUNTIME TRACER
# =============================================================================

class RuntimeTracer:
    """
    Low-level runtime tracer using sys.settrace.

    This is the foundation of The Simulator's observation capabilities.
    It hooks into Python's execution model to observe every:
    - Function call
    - Line execution
    - Return value
    - Exception raised

    Thread-safe and handles recursive tracing.
    """

    def __init__(
        self,
        trace_calls: bool = True,
        trace_lines: bool = False,
        trace_returns: bool = True,
        trace_exceptions: bool = True,
        max_depth: int = SimulatorConfig.MAX_CALL_DEPTH,
        max_iterations: int = SimulatorConfig.MAX_ITERATIONS,
    ):
        self._trace_calls = trace_calls
        self._trace_lines = trace_lines
        self._trace_returns = trace_returns
        self._trace_exceptions = trace_exceptions
        self._max_depth = max_depth
        self._max_iterations = max_iterations

        # Collected data
        self._calls: List[CallFrame] = []
        self._lines: List[LineExecution] = []
        self._exceptions: List[ExceptionEvent] = []
        self._returns: List[Tuple[str, Any, float]] = []  # (frame_id, value, time)

        # State tracking
        self._frame_stack: List[str] = []
        self._frame_map: Dict[int, str] = {}  # id(frame) -> frame_id
        self._current_depth = 0
        self._iteration_count = 0
        self._active = False
        self._lock = threading.Lock()

        # Files to trace (filter out standard library)
        self._trace_files: Set[str] = set()
        self._exclude_patterns = {
            "/lib/python",
            "/site-packages/",
            "<frozen",
            "<string>",
            "importlib",
        }

    def set_trace_files(self, files: List[str]) -> None:
        """Set which files to trace."""
        self._trace_files = {str(Path(f).resolve()) for f in files}

    def _should_trace_file(self, filename: str) -> bool:
        """Check if we should trace this file."""
        if not filename:
            return False

        # Check exclude patterns
        for pattern in self._exclude_patterns:
            if pattern in filename:
                return False

        # If trace_files is set, only trace those files
        if self._trace_files:
            try:
                resolved = str(Path(filename).resolve())
                return resolved in self._trace_files
            except Exception:
                return False

        return True

    def _trace_function(self, frame: types.FrameType, event: str, arg: Any) -> Optional[Callable]:
        """
        The trace function called by Python for each execution event.

        This is THE core of runtime introspection.
        """
        if not self._active:
            return None

        self._iteration_count += 1
        if self._iteration_count > self._max_iterations:
            raise RuntimeError(f"Iteration limit exceeded: {self._max_iterations}")

        filename = frame.f_code.co_filename
        if not self._should_trace_file(filename):
            return self._trace_function

        try:
            if event == "call" and self._trace_calls:
                self._handle_call(frame)
            elif event == "line" and self._trace_lines:
                self._handle_line(frame)
            elif event == "return" and self._trace_returns:
                self._handle_return(frame, arg)
            elif event == "exception" and self._trace_exceptions:
                self._handle_exception(frame, arg)
        except Exception as e:
            logger.warning(f"Tracer error on {event}: {e}")

        return self._trace_function

    def _handle_call(self, frame: types.FrameType) -> None:
        """Handle function call event."""
        self._current_depth += 1

        if self._current_depth > self._max_depth:
            raise RuntimeError(f"Call depth exceeded: {self._max_depth}")

        frame_id = f"frame_{uuid.uuid4().hex[:8]}"
        self._frame_map[id(frame)] = frame_id

        parent_id = None
        if self._frame_stack:
            parent_id = self._frame_stack[-1]
        self._frame_stack.append(frame_id)

        # Capture arguments
        args = {}
        try:
            arg_info = inspect.getargvalues(frame)
            for arg_name in arg_info.args:
                if arg_name in arg_info.locals:
                    args[arg_name] = self._safe_copy(arg_info.locals[arg_name])
        except Exception:
            pass

        # Capture locals snapshot
        locals_snapshot = {}
        try:
            for k, v in list(frame.f_locals.items())[:50]:
                locals_snapshot[k] = self._safe_copy(v)
        except Exception:
            pass

        call_frame = CallFrame(
            frame_id=frame_id,
            function_name=frame.f_code.co_name,
            module_name=frame.f_globals.get("__name__", "<unknown>"),
            file_path=frame.f_code.co_filename,
            line_number=frame.f_lineno,
            args=args,
            locals=locals_snapshot,
            timestamp=time.time(),
            call_depth=self._current_depth,
            parent_frame_id=parent_id,
        )

        with self._lock:
            self._calls.append(call_frame)

    def _handle_line(self, frame: types.FrameType) -> None:
        """Handle line execution event."""
        frame_id = self._frame_map.get(id(frame), "unknown")

        # Get the actual line of code
        code_line = ""
        try:
            code_line = linecache.getline(
                frame.f_code.co_filename,
                frame.f_lineno
            ).strip()
        except Exception:
            pass

        # Snapshot locals
        locals_snapshot = {}
        try:
            for k, v in list(frame.f_locals.items())[:20]:
                locals_snapshot[k] = repr(v)[:100]
        except Exception:
            pass

        line_exec = LineExecution(
            file_path=frame.f_code.co_filename,
            line_number=frame.f_lineno,
            code_line=code_line,
            timestamp=time.time(),
            locals_snapshot=locals_snapshot,
            frame_id=frame_id,
        )

        with self._lock:
            self._lines.append(line_exec)

    def _handle_return(self, frame: types.FrameType, return_value: Any) -> None:
        """Handle function return event."""
        frame_id = self._frame_map.get(id(frame), "unknown")

        if self._frame_stack and self._frame_stack[-1] == frame_id:
            self._frame_stack.pop()

        self._current_depth = max(0, self._current_depth - 1)

        with self._lock:
            self._returns.append((frame_id, self._safe_copy(return_value), time.time()))

    def _handle_exception(self, frame: types.FrameType, exc_info: Tuple) -> None:
        """Handle exception event."""
        exc_type, exc_value, exc_tb = exc_info
        frame_id = self._frame_map.get(id(frame), "unknown")

        # Format traceback
        tb_lines = []
        try:
            tb_lines = traceback.format_exception(exc_type, exc_value, exc_tb)
        except Exception:
            pass

        # Capture local variables at exception point
        locals_snapshot = {}
        try:
            for k, v in list(frame.f_locals.items())[:20]:
                locals_snapshot[k] = repr(v)[:100]
        except Exception:
            pass

        exc_event = ExceptionEvent(
            exception_type=exc_type.__name__ if exc_type else "Unknown",
            exception_message=str(exc_value) if exc_value else "",
            traceback_lines=tb_lines,
            file_path=frame.f_code.co_filename,
            line_number=frame.f_lineno,
            timestamp=time.time(),
            frame_id=frame_id,
            local_variables=locals_snapshot,
        )

        with self._lock:
            self._exceptions.append(exc_event)

    def _safe_copy(self, obj: Any) -> Any:
        """Safely copy an object for storage."""
        try:
            # Try deepcopy for simple objects
            if isinstance(obj, (int, float, str, bool, type(None))):
                return obj
            if isinstance(obj, (list, tuple, set, frozenset)):
                return type(obj)(self._safe_copy(x) for x in list(obj)[:100])
            if isinstance(obj, dict):
                return {k: self._safe_copy(v) for k, v in list(obj.items())[:50]}
            # For complex objects, just store repr
            return repr(obj)[:500]
        except Exception:
            return f"<{type(obj).__name__}>"

    def start(self) -> None:
        """Start tracing."""
        self._active = True
        self._calls.clear()
        self._lines.clear()
        self._exceptions.clear()
        self._returns.clear()
        self._frame_stack.clear()
        self._frame_map.clear()
        self._current_depth = 0
        self._iteration_count = 0
        sys.settrace(self._trace_function)

    def stop(self) -> None:
        """Stop tracing."""
        self._active = False
        sys.settrace(None)

    def get_results(self) -> Dict[str, Any]:
        """Get collected trace data."""
        return {
            "calls": self._calls.copy(),
            "lines": self._lines.copy(),
            "exceptions": self._exceptions.copy(),
            "returns": self._returns.copy(),
            "max_depth_reached": max((c.call_depth for c in self._calls), default=0),
            "total_iterations": self._iteration_count,
        }


# =============================================================================
# MEMORY PROFILER
# =============================================================================

class MemoryProfiler:
    """
    Memory profiler using tracemalloc.

    Tracks memory allocations during code execution to:
    - Detect memory leaks
    - Find excessive allocations
    - Identify memory-hungry code paths
    """

    def __init__(self, max_memory_mb: int = SimulatorConfig.MAX_MEMORY_MB):
        self._max_memory_mb = max_memory_mb
        self._snapshots: List[MemorySnapshot] = []
        self._active = False
        self._start_snapshot = None

    def start(self) -> None:
        """Start memory profiling."""
        tracemalloc.start()
        self._start_snapshot = tracemalloc.take_snapshot()
        self._snapshots.clear()
        self._active = True

    def stop(self) -> None:
        """Stop memory profiling."""
        self._active = False
        if tracemalloc.is_tracing():
            tracemalloc.stop()

    def take_snapshot(self) -> MemorySnapshot:
        """Take a memory snapshot."""
        if not tracemalloc.is_tracing():
            return MemorySnapshot(
                timestamp=time.time(),
                current_mb=0.0,
                peak_mb=0.0,
                allocation_count=0,
                top_allocations=[],
            )

        current, peak = tracemalloc.get_traced_memory()
        snapshot = tracemalloc.take_snapshot()

        # Get top allocations
        top_stats = snapshot.statistics("lineno")[:10]
        top_allocations = [
            (str(stat.traceback), stat.size)
            for stat in top_stats
        ]

        mem_snapshot = MemorySnapshot(
            timestamp=time.time(),
            current_mb=current / (1024 * 1024),
            peak_mb=peak / (1024 * 1024),
            allocation_count=len(top_stats),
            top_allocations=top_allocations,
        )

        self._snapshots.append(mem_snapshot)

        # Check memory limit
        if mem_snapshot.current_mb > self._max_memory_mb:
            raise MemoryError(f"Memory limit exceeded: {mem_snapshot.current_mb:.1f}MB > {self._max_memory_mb}MB")

        return mem_snapshot

    def get_snapshots(self) -> List[MemorySnapshot]:
        """Get all memory snapshots."""
        return self._snapshots.copy()


# =============================================================================
# SANDBOX EXECUTOR
# =============================================================================

class SandboxExecutor:
    """
    Isolated code execution sandbox.

    Runs code in a separate process with:
    - Time limits
    - Memory limits
    - Restricted builtins
    - Captured stdout/stderr
    - Full execution tracing
    """

    def __init__(
        self,
        max_time: float = SimulatorConfig.MAX_EXECUTION_TIME,
        max_memory_mb: int = SimulatorConfig.MAX_MEMORY_MB,
        allowed_modules: Optional[Set[str]] = None,
    ):
        self._max_time = max_time
        self._max_memory_mb = max_memory_mb
        self._allowed_modules = allowed_modules or SimulatorConfig.SANDBOX_ALLOWED_MODULES

    def _create_restricted_globals(self) -> Dict[str, Any]:
        """Create restricted global namespace for sandbox."""
        # Start with empty globals
        restricted = {
            "__builtins__": {},
            "__name__": "__sandbox__",
            "__doc__": None,
        }

        # Add safe builtins
        safe_builtins = [
            # Types
            "bool", "int", "float", "str", "bytes", "bytearray",
            "list", "tuple", "dict", "set", "frozenset",
            "type", "object", "None", "True", "False",
            # Functions
            "len", "range", "enumerate", "zip", "map", "filter",
            "sorted", "reversed", "min", "max", "sum", "abs",
            "all", "any", "isinstance", "issubclass", "hasattr",
            "getattr", "setattr", "delattr", "callable", "iter", "next",
            "repr", "str", "print", "format", "chr", "ord",
            "round", "pow", "divmod", "hash", "id", "hex", "oct", "bin",
            "slice", "property", "staticmethod", "classmethod",
            "super", "vars", "dir",
            # Exceptions
            "Exception", "BaseException", "ValueError", "TypeError",
            "KeyError", "IndexError", "AttributeError", "RuntimeError",
            "StopIteration", "AssertionError", "NotImplementedError",
        ]

        for name in safe_builtins:
            if hasattr(builtins, name):
                restricted["__builtins__"][name] = getattr(builtins, name)

        # Add safe __import__ for allowed modules
        def safe_import(name, globals=None, locals=None, fromlist=(), level=0):
            base_module = name.split(".")[0]
            if base_module in self._allowed_modules:
                return __import__(name, globals, locals, fromlist, level)
            raise ImportError(f"Import not allowed: {name}")

        restricted["__builtins__"]["__import__"] = safe_import

        return restricted

    def execute_code(
        self,
        code: str,
        filename: str = "<sandbox>",
        globals_dict: Optional[Dict[str, Any]] = None,
        trace: bool = True,
    ) -> ExecutionTrace:
        """
        Execute code in sandbox with full tracing.

        This is synchronous and meant to be called in a subprocess.
        """
        trace_id = f"trace_{uuid.uuid4().hex[:12]}"
        start_time = time.time()

        # Initialize collectors
        tracer = RuntimeTracer(
            trace_calls=SimulatorConfig.TRACE_CALLS,
            trace_lines=SimulatorConfig.TRACE_LINES,
            trace_returns=SimulatorConfig.TRACE_RETURNS,
            trace_exceptions=SimulatorConfig.TRACE_EXCEPTIONS,
        ) if trace else None

        memory_profiler = MemoryProfiler(self._max_memory_mb) if SimulatorConfig.ENABLE_MEMORY_PROFILING else None

        # Capture stdout/stderr
        stdout_capture = io.StringIO()
        stderr_capture = io.StringIO()

        status = ExecutionStatus.PENDING
        return_value = None
        exception_info = None

        try:
            # Compile code
            compiled = compile(code, filename, "exec")

            # Create execution namespace
            exec_globals = globals_dict or self._create_restricted_globals()

            # Start profilers
            if memory_profiler:
                memory_profiler.start()
            if tracer:
                tracer.set_trace_files([filename])
                tracer.start()

            status = ExecutionStatus.RUNNING

            # Execute with captured output
            with contextlib.redirect_stdout(stdout_capture):
                with contextlib.redirect_stderr(stderr_capture):
                    exec(compiled, exec_globals)

            status = ExecutionStatus.COMPLETED
            return_value = exec_globals.get("result", None)

        except MemoryError as e:
            status = ExecutionStatus.MEMORY_EXCEEDED
            exception_info = str(e)
        except RuntimeError as e:
            if "depth" in str(e).lower():
                status = ExecutionStatus.DEPTH_EXCEEDED
            elif "iteration" in str(e).lower():
                status = ExecutionStatus.ITERATION_EXCEEDED
            else:
                status = ExecutionStatus.FAILED
            exception_info = str(e)
        except Exception as e:
            status = ExecutionStatus.FAILED
            exception_info = f"{type(e).__name__}: {e}"
        finally:
            # Stop profilers
            if tracer:
                tracer.stop()
            if memory_profiler:
                memory_profiler.stop()

        end_time = time.time()

        # Collect results
        trace_results = tracer.get_results() if tracer else {
            "calls": [], "lines": [], "exceptions": [], "returns": [], "max_depth_reached": 0
        }

        # Add exception if execution failed
        if exception_info and status == ExecutionStatus.FAILED:
            trace_results["exceptions"].append(ExceptionEvent(
                exception_type=exception_info.split(":")[0] if ":" in exception_info else "Error",
                exception_message=exception_info,
                traceback_lines=traceback.format_exc().splitlines(),
                file_path=filename,
                line_number=0,
                timestamp=end_time,
                frame_id="main",
                local_variables={},
            ))

        return ExecutionTrace(
            trace_id=trace_id,
            start_time=start_time,
            end_time=end_time,
            status=status,
            calls=trace_results["calls"],
            lines=trace_results["lines"],
            exceptions=trace_results["exceptions"],
            memory_snapshots=memory_profiler.get_snapshots() if memory_profiler else [],
            return_value=return_value,
            stdout=stdout_capture.getvalue()[:SimulatorConfig.MAX_OUTPUT_SIZE],
            stderr=stderr_capture.getvalue()[:SimulatorConfig.MAX_OUTPUT_SIZE],
            total_calls=len(trace_results["calls"]),
            total_lines=len(trace_results["lines"]),
            max_depth=trace_results["max_depth_reached"],
            coverage_percent=0.0,  # Would need source analysis to calculate
        )


def _execute_in_process(args: Tuple[str, str, Optional[Dict], bool]) -> Dict[str, Any]:
    """
    Worker function for process pool execution.

    This runs in a separate process for isolation.
    """
    code, filename, globals_dict, trace = args

    executor = SandboxExecutor()
    result = executor.execute_code(code, filename, globals_dict, trace)

    # Convert to dict for pickling
    return {
        "trace_id": result.trace_id,
        "start_time": result.start_time,
        "end_time": result.end_time,
        "status": result.status.name,
        "calls": [c.to_dict() for c in result.calls],
        "exceptions": [
            {
                "type": e.exception_type,
                "message": e.exception_message,
                "file": e.file_path,
                "line": e.line_number,
                "locals": e.local_variables,
            }
            for e in result.exceptions
        ],
        "return_value": repr(result.return_value) if result.return_value else None,
        "stdout": result.stdout,
        "stderr": result.stderr,
        "total_calls": result.total_calls,
        "total_lines": result.total_lines,
        "max_depth": result.max_depth,
        "coverage_percent": result.coverage_percent,
    }


# =============================================================================
# THE SIMULATOR - MAIN CLASS
# =============================================================================

class TheSimulator:
    """
    The Simulator - Runtime Introspection Engine.

    "God Mode" Pillar 3: Predictive Execution & Live Debugging.

    This class provides:
    - Predictive execution: Run code in sandbox to see results
    - Variable tracing: Track all state changes
    - Exception prediction: Detect potential failures
    - Performance profiling: Find bottlenecks
    - Memory analysis: Detect leaks

    Thread-safe and async-compatible for integration with Ouroboros.
    """

    def __init__(self):
        self._executor = SandboxExecutor()
        self._process_pool: Optional[ProcessPoolExecutor] = None
        self._thread_pool: Optional[ThreadPoolExecutor] = None
        self._lock = asyncio.Lock()
        self._initialized = False

        # Cache for repeated executions
        self._execution_cache: Dict[str, ExecutionTrace] = {}
        self._cache_max_size = 100

        # Metrics
        self._metrics = {
            "total_executions": 0,
            "successful_executions": 0,
            "failed_executions": 0,
            "timeout_executions": 0,
            "total_execution_time": 0.0,
            "cache_hits": 0,
        }

    async def initialize(self) -> bool:
        """Initialize The Simulator."""
        async with self._lock:
            if self._initialized:
                return True

            try:
                # Create process pool for isolated execution
                self._process_pool = ProcessPoolExecutor(
                    max_workers=SimulatorConfig.SANDBOX_PROCESS_POOL_SIZE
                )
                self._thread_pool = ThreadPoolExecutor(max_workers=4)

                # v95.12: Register executors for cleanup
                register_executor_for_cleanup(self._process_pool, "simulator_process_pool", is_process_pool=True)
                register_executor_for_cleanup(self._thread_pool, "simulator_thread_pool")

                self._initialized = True
                logger.info("The Simulator initialized")
                return True
            except Exception as e:
                logger.error(f"Failed to initialize Simulator: {e}")
                return False

    async def shutdown(self) -> None:
        """v95.12: Shutdown The Simulator with proper cleanup."""
        async with self._lock:
            executor_shutdown_timeout = 5.0

            # Shutdown process pool (critical for semaphore cleanup)
            if self._process_pool:
                try:
                    await asyncio.wait_for(
                        asyncio.get_running_loop().run_in_executor(
                            None,
                            lambda: self._process_pool.shutdown(wait=True, cancel_futures=True)
                        ),
                        timeout=executor_shutdown_timeout
                    )
                except asyncio.TimeoutError:
                    self._process_pool.shutdown(wait=False, cancel_futures=True)
                except Exception:
                    pass
                self._process_pool = None

            # Shutdown thread pool
            if self._thread_pool:
                try:
                    await asyncio.wait_for(
                        asyncio.get_running_loop().run_in_executor(
                            None,
                            lambda: self._thread_pool.shutdown(wait=True, cancel_futures=True)
                        ),
                        timeout=executor_shutdown_timeout
                    )
                except asyncio.TimeoutError:
                    self._thread_pool.shutdown(wait=False, cancel_futures=True)
                except Exception:
                    pass
                self._thread_pool = None

            self._initialized = False
            logger.info("The Simulator shutdown")

    async def simulate_code(
        self,
        code: str,
        filename: str = "<simulation>",
        globals_dict: Optional[Dict[str, Any]] = None,
        trace: bool = True,
        use_cache: bool = True,
        timeout: Optional[float] = None,
    ) -> ExecutionTrace:
        """
        Simulate code execution with full tracing.

        Args:
            code: Python code to execute
            filename: Virtual filename for the code
            globals_dict: Global namespace (uses sandbox defaults if None)
            trace: Whether to enable detailed tracing
            use_cache: Whether to use execution cache
            timeout: Custom timeout (uses config default if None)

        Returns:
            ExecutionTrace with full execution details
        """
        if not self._initialized:
            await self.initialize()

        # Check cache
        if use_cache:
            cache_key = f"{hash(code)}_{hash(str(globals_dict))}_{trace}"
            if cache_key in self._execution_cache:
                self._metrics["cache_hits"] += 1
                return self._execution_cache[cache_key]

        self._metrics["total_executions"] += 1
        start_time = time.time()
        timeout = timeout or SimulatorConfig.MAX_EXECUTION_TIME

        try:
            # Run in process pool for isolation
            loop = asyncio.get_running_loop()
            future = self._process_pool.submit(
                _execute_in_process,
                (code, filename, globals_dict, trace)
            )

            # Wait with timeout
            result_dict = await asyncio.wait_for(
                loop.run_in_executor(None, future.result),
                timeout=timeout
            )

            # Convert back to ExecutionTrace
            status = ExecutionStatus[result_dict["status"]]
            trace_result = ExecutionTrace(
                trace_id=result_dict["trace_id"],
                start_time=result_dict["start_time"],
                end_time=result_dict["end_time"],
                status=status,
                calls=[],  # Would need to reconstruct from dicts
                lines=[],
                exceptions=[
                    ExceptionEvent(
                        exception_type=e["type"],
                        exception_message=e["message"],
                        traceback_lines=[],
                        file_path=e["file"],
                        line_number=e["line"],
                        timestamp=result_dict["end_time"],
                        frame_id="unknown",
                        local_variables=e["locals"],
                    )
                    for e in result_dict["exceptions"]
                ],
                memory_snapshots=[],
                return_value=result_dict["return_value"],
                stdout=result_dict["stdout"],
                stderr=result_dict["stderr"],
                total_calls=result_dict["total_calls"],
                total_lines=result_dict["total_lines"],
                max_depth=result_dict["max_depth"],
                coverage_percent=result_dict["coverage_percent"],
            )

            if status == ExecutionStatus.COMPLETED:
                self._metrics["successful_executions"] += 1
            else:
                self._metrics["failed_executions"] += 1

            # Update cache
            if use_cache and len(self._execution_cache) < self._cache_max_size:
                self._execution_cache[cache_key] = trace_result

            return trace_result

        except asyncio.TimeoutError:
            self._metrics["timeout_executions"] += 1
            return ExecutionTrace(
                trace_id=f"timeout_{uuid.uuid4().hex[:8]}",
                start_time=start_time,
                end_time=time.time(),
                status=ExecutionStatus.TIMEOUT,
                calls=[],
                lines=[],
                exceptions=[],
                memory_snapshots=[],
                return_value=None,
                stdout="",
                stderr=f"Execution timeout after {timeout}s",
                total_calls=0,
                total_lines=0,
                max_depth=0,
                coverage_percent=0.0,
            )
        except Exception as e:
            self._metrics["failed_executions"] += 1
            return ExecutionTrace(
                trace_id=f"error_{uuid.uuid4().hex[:8]}",
                start_time=start_time,
                end_time=time.time(),
                status=ExecutionStatus.FAILED,
                calls=[],
                lines=[],
                exceptions=[ExceptionEvent(
                    exception_type=type(e).__name__,
                    exception_message=str(e),
                    traceback_lines=traceback.format_exc().splitlines(),
                    file_path=filename,
                    line_number=0,
                    timestamp=time.time(),
                    frame_id="main",
                    local_variables={},
                )],
                memory_snapshots=[],
                return_value=None,
                stdout="",
                stderr=str(e),
                total_calls=0,
                total_lines=0,
                max_depth=0,
                coverage_percent=0.0,
            )
        finally:
            self._metrics["total_execution_time"] += time.time() - start_time

    async def predict_execution(
        self,
        code: str,
        test_inputs: Optional[List[Dict[str, Any]]] = None,
    ) -> PredictionResult:
        """
        Predict the outcome of code execution.

        Analyzes code statically and optionally runs with test inputs
        to predict potential issues.

        Args:
            code: Python code to analyze
            test_inputs: Optional list of input dictionaries to test

        Returns:
            PredictionResult with predictions and recommendations
        """
        issues: List[Dict[str, Any]] = []
        execution_path: List[str] = []
        recommendations: List[str] = []

        # Static analysis
        try:
            tree = ast.parse(code)

            # Check for dangerous patterns
            for node in ast.walk(tree):
                if isinstance(node, ast.While):
                    issues.append({
                        "type": "potential_infinite_loop",
                        "line": node.lineno,
                        "severity": "warning",
                        "message": "While loop detected - ensure termination condition",
                    })
                elif isinstance(node, ast.Call):
                    if isinstance(node.func, ast.Name):
                        if node.func.id in ("eval", "exec"):
                            issues.append({
                                "type": "security_risk",
                                "line": node.lineno,
                                "severity": "high",
                                "message": f"Dangerous function '{node.func.id}' detected",
                            })
                elif isinstance(node, ast.Import) or isinstance(node, ast.ImportFrom):
                    module = node.module if isinstance(node, ast.ImportFrom) else node.names[0].name
                    if module and module.split(".")[0] not in SimulatorConfig.SANDBOX_ALLOWED_MODULES:
                        issues.append({
                            "type": "restricted_import",
                            "line": node.lineno,
                            "severity": "info",
                            "message": f"Import '{module}' not in allowed modules",
                        })

        except SyntaxError as e:
            issues.append({
                "type": "syntax_error",
                "line": e.lineno,
                "severity": "error",
                "message": str(e),
            })
            return PredictionResult(
                will_succeed=False,
                confidence=1.0,
                predicted_issues=issues,
                execution_path=[],
                resource_estimate={},
                recommendations=["Fix syntax error before execution"],
            )

        # Test execution with inputs
        if test_inputs:
            for i, inputs in enumerate(test_inputs[:5]):  # Limit test runs
                globals_with_inputs = {"inputs": inputs}
                trace = await self.simulate_code(
                    code,
                    filename=f"<test_{i}>",
                    globals_dict=globals_with_inputs,
                    trace=False,
                    timeout=5.0,
                )

                if trace.status != ExecutionStatus.COMPLETED:
                    issues.append({
                        "type": "execution_failure",
                        "input_index": i,
                        "severity": "error",
                        "message": f"Failed with input {i}: {trace.status.name}",
                    })

        # Generate predictions
        has_errors = any(i["severity"] == "error" for i in issues)
        has_high_risks = any(i["severity"] == "high" for i in issues)

        will_succeed = not has_errors and not has_high_risks
        confidence = 0.9 if not issues else 0.5 if not has_errors else 0.2

        # Generate recommendations
        if has_errors:
            recommendations.append("Fix error-level issues before deployment")
        if any(i["type"] == "potential_infinite_loop" for i in issues):
            recommendations.append("Add explicit loop bounds or timeout handling")
        if any(i["type"] == "security_risk" for i in issues):
            recommendations.append("Remove or sandbox dangerous function calls")

        return PredictionResult(
            will_succeed=will_succeed,
            confidence=confidence,
            predicted_issues=issues,
            execution_path=execution_path,
            resource_estimate={
                "estimated_time_ms": 100.0,  # Would need more analysis
                "estimated_memory_mb": 10.0,
            },
            recommendations=recommendations,
        )

    async def validate_improvement(
        self,
        original_code: str,
        improved_code: str,
        test_cases: Optional[List[Dict[str, Any]]] = None,
    ) -> Dict[str, Any]:
        """
        Validate that improved code behaves correctly.

        Compares execution of original and improved code to ensure
        the improvement doesn't break functionality.

        Returns:
            Validation result with comparison details
        """
        result = {
            "valid": True,
            "original_trace": None,
            "improved_trace": None,
            "differences": [],
            "recommendations": [],
        }

        # Execute original
        original_trace = await self.simulate_code(
            original_code,
            filename="<original>",
            trace=True,
            timeout=10.0,
        )
        result["original_trace"] = original_trace.to_dict()

        # Execute improved
        improved_trace = await self.simulate_code(
            improved_code,
            filename="<improved>",
            trace=True,
            timeout=10.0,
        )
        result["improved_trace"] = improved_trace.to_dict()

        # Compare results
        if original_trace.status == ExecutionStatus.COMPLETED:
            if improved_trace.status != ExecutionStatus.COMPLETED:
                result["valid"] = False
                result["differences"].append({
                    "type": "status_change",
                    "original": "COMPLETED",
                    "improved": improved_trace.status.name,
                    "severity": "error",
                })

        # Check for new exceptions
        if len(improved_trace.exceptions) > len(original_trace.exceptions):
            result["differences"].append({
                "type": "new_exceptions",
                "count": len(improved_trace.exceptions) - len(original_trace.exceptions),
                "severity": "warning",
            })

        # Check output differences
        if original_trace.stdout != improved_trace.stdout:
            result["differences"].append({
                "type": "stdout_changed",
                "severity": "info",
            })

        return result

    def get_metrics(self) -> Dict[str, Any]:
        """Get Simulator metrics."""
        return dict(self._metrics)

    def get_status(self) -> Dict[str, Any]:
        """Get Simulator status."""
        return {
            "initialized": self._initialized,
            "metrics": self._metrics,
            "cache_size": len(self._execution_cache),
            "config": {
                "max_time": SimulatorConfig.MAX_EXECUTION_TIME,
                "max_memory_mb": SimulatorConfig.MAX_MEMORY_MB,
                "max_depth": SimulatorConfig.MAX_CALL_DEPTH,
                "pool_size": SimulatorConfig.SANDBOX_PROCESS_POOL_SIZE,
            },
        }


# =============================================================================
# OUROBOROS INTEGRATION
# =============================================================================

class OuroborosSimulatorIntegration:
    """
    Integration layer between The Simulator and Ouroboros.

    Provides:
    - Pre-validation of code changes through simulation
    - Execution comparison between original and improved code
    - Performance regression detection
    - Resource usage prediction
    """

    def __init__(self, simulator: Optional[TheSimulator] = None):
        self._simulator = simulator

    async def _get_simulator(self) -> TheSimulator:
        """Lazy-load simulator."""
        if self._simulator is None:
            self._simulator = get_simulator()
            await self._simulator.initialize()
        return self._simulator

    async def validate_code_change(
        self,
        original_code: str,
        improved_code: str,
        test_inputs: Optional[List[Dict[str, Any]]] = None,
    ) -> Dict[str, Any]:
        """
        Validate a code change by simulating execution.

        This is THE key integration point - before Ouroboros commits
        a change, it can simulate the change to catch runtime errors.
        """
        simulator = await self._get_simulator()

        # Predict issues with improved code
        prediction = await simulator.predict_execution(improved_code, test_inputs)

        if not prediction.will_succeed:
            return {
                "valid": False,
                "reason": "Prediction indicates failure",
                "predicted_issues": prediction.predicted_issues,
                "recommendations": prediction.recommendations,
            }

        # Validate behavior matches
        validation = await simulator.validate_improvement(
            original_code,
            improved_code,
            test_inputs,
        )

        return {
            "valid": validation["valid"],
            "prediction": {
                "will_succeed": prediction.will_succeed,
                "confidence": prediction.confidence,
                "issues": prediction.predicted_issues,
            },
            "validation": validation,
            "recommendations": prediction.recommendations,
        }

    async def get_execution_profile(
        self,
        code: str,
        inputs: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        Get execution profile for code.

        Useful for understanding performance characteristics
        before optimizing.
        """
        simulator = await self._get_simulator()

        globals_dict = {"inputs": inputs} if inputs else None
        trace = await simulator.simulate_code(
            code,
            globals_dict=globals_dict,
            trace=True,
        )

        return {
            "status": trace.status.name,
            "duration_ms": (trace.end_time - trace.start_time) * 1000,
            "total_calls": trace.total_calls,
            "max_depth": trace.max_depth,
            "exceptions": len(trace.exceptions),
            "memory_snapshots": len(trace.memory_snapshots),
        }


# =============================================================================
# GLOBAL INSTANCE
# =============================================================================

_simulator: Optional[TheSimulator] = None


def get_simulator() -> TheSimulator:
    """Get global Simulator instance."""
    global _simulator
    if _simulator is None:
        _simulator = TheSimulator()
    return _simulator


async def shutdown_simulator() -> None:
    """Shutdown global Simulator."""
    global _simulator
    if _simulator:
        await _simulator.shutdown()
        _simulator = None


# =============================================================================
# CLI FOR TESTING
# =============================================================================

async def main():
    """CLI for testing The Simulator."""
    import argparse

    parser = argparse.ArgumentParser(description="The Simulator - Runtime Introspection Engine")
    parser.add_argument("command", choices=["simulate", "predict", "status"])
    parser.add_argument("--code", "-c", help="Code to execute")
    parser.add_argument("--file", "-f", help="File to execute")

    args = parser.parse_args()

    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)s | %(name)s | %(message)s',
        datefmt='%H:%M:%S'
    )

    simulator = get_simulator()
    await simulator.initialize()

    try:
        if args.command == "status":
            status = simulator.get_status()
            print("\nSimulator Status:")
            for key, value in status.items():
                print(f"  {key}: {value}")

        elif args.command == "simulate":
            code = args.code
            if args.file:
                code = Path(args.file).read_text()

            if not code:
                print("Error: Provide --code or --file")
                return 1

            print(f"\nSimulating code execution...")
            trace = await simulator.simulate_code(code, trace=True)

            print(f"\nExecution Result:")
            print(f"  Status: {trace.status.name}")
            print(f"  Duration: {(trace.end_time - trace.start_time)*1000:.2f}ms")
            print(f"  Calls: {trace.total_calls}")
            print(f"  Max Depth: {trace.max_depth}")
            print(f"  Exceptions: {len(trace.exceptions)}")

            if trace.stdout:
                print(f"\nStdout:\n{trace.stdout[:500]}")
            if trace.stderr:
                print(f"\nStderr:\n{trace.stderr[:500]}")
            if trace.exceptions:
                print(f"\nExceptions:")
                for exc in trace.exceptions:
                    print(f"  - {exc.exception_type}: {exc.exception_message}")

        elif args.command == "predict":
            code = args.code
            if args.file:
                code = Path(args.file).read_text()

            if not code:
                print("Error: Provide --code or --file")
                return 1

            print(f"\nPredicting execution...")
            prediction = await simulator.predict_execution(code)

            print(f"\nPrediction Result:")
            print(f"  Will Succeed: {prediction.will_succeed}")
            print(f"  Confidence: {prediction.confidence:.1%}")

            if prediction.predicted_issues:
                print(f"\nPredicted Issues:")
                for issue in prediction.predicted_issues:
                    print(f"  [{issue['severity'].upper()}] Line {issue.get('line', '?')}: {issue['message']}")

            if prediction.recommendations:
                print(f"\nRecommendations:")
                for rec in prediction.recommendations:
                    print(f"  - {rec}")

    finally:
        await simulator.shutdown()

    return 0


if __name__ == "__main__":
    sys.exit(asyncio.run(main()))
