"""
Dynamic LangChain Tool Registry for Ironcliw

This module provides a sophisticated tool management system that:
- Auto-discovers tools from the codebase
- Dynamically wraps existing Ironcliw capabilities as LangChain tools
- Supports async tool execution
- Provides tool composition and chaining
- Integrates with the permission system

Features:
- Zero hardcoding - tools are discovered and registered dynamically
- Async-first design
- Tool capability matching
- Automatic schema generation
- Permission-aware execution
- Tool versioning and hot-reload support
"""

from __future__ import annotations

import asyncio
import base64
import binascii
import errno
import functools
import importlib
import inspect
import json
import logging
import os
import re
import shlex
import shutil
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum, auto
from pathlib import Path
from typing import (
    Any, Awaitable, Callable, Dict, Generic, List, Literal, Optional,
    Protocol, Sequence, Set, Tuple, Type, TypeVar, Union, get_type_hints
)
from uuid import uuid4

try:
    from langchain_core.tools import BaseTool, StructuredTool, tool
    from langchain_core.callbacks import CallbackManagerForToolRun, AsyncCallbackManagerForToolRun
    # Fix for pydantic v2 - use pydantic directly instead of compatibility shim
    from pydantic import BaseModel, Field
    LANGCHAIN_AVAILABLE = True
except ImportError:
    try:
        from langchain.tools import BaseTool, StructuredTool, tool
        from langchain.callbacks.manager import CallbackManagerForToolRun, AsyncCallbackManagerForToolRun
        from pydantic import BaseModel, Field
        LANGCHAIN_AVAILABLE = True
    except ImportError:
        LANGCHAIN_AVAILABLE = False
        BaseTool = object
        StructuredTool = None
        tool = lambda x: x
        BaseModel = object
        Field = lambda **kwargs: None

from pydantic import BaseModel as PydanticBaseModel, Field as PydanticField, validator

from backend.core.resilience.atomic_file_ops import get_atomic_file_ops
from backend.intelligence.web_research_service import get_web_research_service

logger = logging.getLogger(__name__)


# ============================================================================
# Enums and Constants
# ============================================================================

class ToolCategory(str, Enum):
    """Categories for organizing tools."""
    SYSTEM = "system"
    FILE_SYSTEM = "file_system"
    NETWORK = "network"
    COMMUNICATION = "communication"
    ANALYSIS = "analysis"
    AUTOMATION = "automation"
    MONITORING = "monitoring"
    SECURITY = "security"
    UI = "ui"
    INTEGRATION = "integration"
    UTILITY = "utility"


class ToolRiskLevel(str, Enum):
    """Risk levels for tools."""
    SAFE = "safe"           # Read-only, no side effects
    LOW = "low"             # Minor side effects, easily reversible
    MEDIUM = "medium"       # Noticeable side effects, reversible
    HIGH = "high"           # Significant side effects, hard to reverse
    CRITICAL = "critical"   # System-altering, may be irreversible


class ToolExecutionMode(str, Enum):
    """Execution modes for tools."""
    SYNC = "sync"
    ASYNC = "async"
    BOTH = "both"


# ============================================================================
# Data Classes
# ============================================================================

@dataclass
class ToolMetadata:
    """Metadata about a tool."""
    name: str
    description: str
    category: ToolCategory
    risk_level: ToolRiskLevel
    version: str = "1.0.0"
    author: str = "Ironcliw"
    tags: List[str] = field(default_factory=list)
    requires_permission: bool = True
    execution_mode: ToolExecutionMode = ToolExecutionMode.ASYNC
    timeout_seconds: float = 30.0
    retry_count: int = 3
    cooldown_seconds: float = 0.0
    dependencies: List[str] = field(default_factory=list)
    capabilities: List[str] = field(default_factory=list)
    examples: List[Dict[str, Any]] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.utcnow)
    updated_at: datetime = field(default_factory=datetime.utcnow)


@dataclass
class ToolExecutionRecord:
    """Record of a tool execution."""
    tool_name: str
    execution_id: str
    input_args: Dict[str, Any]
    output: Any
    success: bool
    error: Optional[str] = None
    duration_ms: float = 0
    timestamp: datetime = field(default_factory=datetime.utcnow)
    permission_status: str = "granted"


@dataclass
class ToolCapability:
    """Describes what a tool can do."""
    name: str
    description: str
    input_types: List[str]
    output_types: List[str]
    side_effects: List[str]


# ============================================================================
# Tool Schema Generation
# ============================================================================

class ToolSchemaGenerator:
    """Generates tool schemas from Python functions."""

    TYPE_MAPPING = {
        str: "string",
        int: "integer",
        float: "number",
        bool: "boolean",
        list: "array",
        dict: "object",
        type(None): "null"
    }

    @classmethod
    def generate_schema(cls, func: Callable) -> Dict[str, Any]:
        """Generate JSON schema from function signature."""
        sig = inspect.signature(func)
        hints = get_type_hints(func) if hasattr(func, '__annotations__') else {}
        doc = inspect.getdoc(func) or ""

        properties = {}
        required = []

        for name, param in sig.parameters.items():
            if name in ('self', 'cls', 'run_manager', 'callback_manager'):
                continue

            param_type = hints.get(name, Any)
            param_schema = cls._type_to_schema(param_type)

            # Extract description from docstring
            param_desc = cls._extract_param_description(doc, name)
            if param_desc:
                param_schema["description"] = param_desc

            properties[name] = param_schema

            # Check if required
            if param.default is inspect.Parameter.empty:
                required.append(name)

        return {
            "type": "object",
            "properties": properties,
            "required": required
        }

    @classmethod
    def _type_to_schema(cls, type_hint: Any) -> Dict[str, Any]:
        """Convert Python type hint to JSON schema."""
        # Handle basic types
        if type_hint in cls.TYPE_MAPPING:
            return {"type": cls.TYPE_MAPPING[type_hint]}

        # Handle Optional
        origin = getattr(type_hint, '__origin__', None)
        if origin is Union:
            args = type_hint.__args__
            if type(None) in args:
                # Optional type
                non_none = [a for a in args if a is not type(None)]
                if len(non_none) == 1:
                    schema = cls._type_to_schema(non_none[0])
                    schema["nullable"] = True
                    return schema

        # Handle List
        if origin is list:
            item_type = type_hint.__args__[0] if type_hint.__args__ else Any
            return {
                "type": "array",
                "items": cls._type_to_schema(item_type)
            }

        # Handle Dict
        if origin is dict:
            return {"type": "object"}

        # Handle Literal
        if origin is Literal:
            return {"enum": list(type_hint.__args__)}

        # Default
        return {"type": "string"}

    @classmethod
    def _extract_param_description(cls, docstring: str, param_name: str) -> Optional[str]:
        """Extract parameter description from docstring."""
        # Support multiple docstring formats
        patterns = [
            rf":param {param_name}:\s*(.+?)(?=\n|:param|:return|$)",  # Sphinx
            rf"{param_name}\s*:\s*(.+?)(?=\n\s*\w+\s*:|$)",  # Google
            rf"Args:\s*.*?{param_name}\s*(?:\([^)]+\))?\s*:\s*(.+?)(?=\n|$)"  # Google Args
        ]

        for pattern in patterns:
            match = re.search(pattern, docstring, re.DOTALL)
            if match:
                return match.group(1).strip()

        return None


# ============================================================================
# Base Tool Classes
# ============================================================================

class IroncliwTool(ABC):
    """
    Base class for Ironcliw tools.

    Provides common functionality for all tools including:
    - Async execution support
    - Permission checking
    - Execution tracking
    - Error handling
    """

    def __init__(
        self,
        metadata: ToolMetadata,
        permission_manager: Optional[Any] = None
    ):
        self.metadata = metadata
        self.permission_manager = permission_manager
        self.logger = logging.getLogger(f"{__name__}.{metadata.name}")
        self._execution_count = 0
        self._last_execution: Optional[datetime] = None
        self._execution_history: List[ToolExecutionRecord] = []

    @property
    def name(self) -> str:
        return self.metadata.name

    @property
    def description(self) -> str:
        return self.metadata.description

    @abstractmethod
    async def _execute(self, **kwargs) -> Any:
        """Execute the tool. Override in subclasses."""
        pass

    async def run(self, **kwargs) -> Any:
        """
        Run the tool with permission checking and tracking.

        Args:
            **kwargs: Tool arguments

        Returns:
            Tool output
        """
        execution_id = str(uuid4())
        start_time = time.time()

        # Check cooldown
        if self._last_execution and self.metadata.cooldown_seconds > 0:
            elapsed = (datetime.utcnow() - self._last_execution).total_seconds()
            if elapsed < self.metadata.cooldown_seconds:
                raise RuntimeError(
                    f"Tool on cooldown. Wait {self.metadata.cooldown_seconds - elapsed:.1f}s"
                )

        # Check permission
        permission_status = "granted"
        if self.metadata.requires_permission and self.permission_manager:
            has_permission = await self._check_permission(kwargs)
            if not has_permission:
                permission_status = "denied"
                record = ToolExecutionRecord(
                    tool_name=self.name,
                    execution_id=execution_id,
                    input_args=kwargs,
                    output=None,
                    success=False,
                    error="Permission denied",
                    permission_status=permission_status
                )
                self._execution_history.append(record)
                raise PermissionError(f"Permission denied for tool: {self.name}")

        try:
            # Execute with timeout
            result = await asyncio.wait_for(
                self._execute(**kwargs),
                timeout=self.metadata.timeout_seconds
            )

            duration_ms = (time.time() - start_time) * 1000
            self._execution_count += 1
            self._last_execution = datetime.utcnow()

            # Record execution
            record = ToolExecutionRecord(
                tool_name=self.name,
                execution_id=execution_id,
                input_args=kwargs,
                output=result,
                success=True,
                duration_ms=duration_ms,
                permission_status=permission_status
            )
            self._execution_history.append(record)

            return result

        except asyncio.TimeoutError:
            duration_ms = (time.time() - start_time) * 1000
            record = ToolExecutionRecord(
                tool_name=self.name,
                execution_id=execution_id,
                input_args=kwargs,
                output=None,
                success=False,
                error="Execution timed out",
                duration_ms=duration_ms,
                permission_status=permission_status
            )
            self._execution_history.append(record)
            raise

        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            record = ToolExecutionRecord(
                tool_name=self.name,
                execution_id=execution_id,
                input_args=kwargs,
                output=None,
                success=False,
                error=str(e),
                duration_ms=duration_ms,
                permission_status=permission_status
            )
            self._execution_history.append(record)
            raise

    async def _check_permission(self, kwargs: Dict[str, Any]) -> bool:
        """Check if tool execution is permitted."""
        if self.permission_manager is None:
            return True

        try:
            return await self.permission_manager.check_permission(
                action_type=f"tool:{self.name}",
                target=self.name,
                context=kwargs
            )
        except Exception as e:
            self.logger.warning(f"Permission check failed: {e}")
            return False

    def get_execution_stats(self) -> Dict[str, Any]:
        """Get execution statistics."""
        if not self._execution_history:
            return {
                "total_executions": 0,
                "success_rate": 0,
                "avg_duration_ms": 0
            }

        successful = [r for r in self._execution_history if r.success]
        durations = [r.duration_ms for r in self._execution_history]

        return {
            "total_executions": len(self._execution_history),
            "success_rate": len(successful) / len(self._execution_history),
            "avg_duration_ms": sum(durations) / len(durations) if durations else 0,
            "last_execution": self._last_execution.isoformat() if self._last_execution else None
        }

    def to_langchain_tool(self) -> Optional[BaseTool]:
        """Convert to LangChain BaseTool."""
        if not LANGCHAIN_AVAILABLE:
            return None

        return IroncliwLangChainTool(jarvis_tool=self)


class IroncliwLangChainTool(BaseTool):
    """LangChain wrapper for Ironcliw tools."""

    name: str = ""
    description: str = ""
    jarvis_tool: Any = None

    class Config:
        arbitrary_types_allowed = True

    def __init__(self, jarvis_tool: IroncliwTool, **kwargs):
        super().__init__(**kwargs)
        self.jarvis_tool = jarvis_tool
        self.name = jarvis_tool.name
        self.description = jarvis_tool.description

    def _run(
        self,
        *args,
        run_manager: Optional[CallbackManagerForToolRun] = None,
        **kwargs
    ) -> str:
        """Sync execution (wraps async)."""
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # Create new loop in thread
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(
                        asyncio.run, self.jarvis_tool.run(**kwargs)
                    )
                    result = future.result()
            else:
                result = loop.run_until_complete(self.jarvis_tool.run(**kwargs))
            return json.dumps(result) if not isinstance(result, str) else result
        except Exception as e:
            return f"Error: {str(e)}"

    async def _arun(
        self,
        *args,
        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,
        **kwargs
    ) -> str:
        """Async execution."""
        try:
            result = await self.jarvis_tool.run(**kwargs)
            return json.dumps(result) if not isinstance(result, str) else result
        except Exception as e:
            return f"Error: {str(e)}"


# ============================================================================
# Function-Based Tool Wrapper
# ============================================================================

class FunctionTool(IroncliwTool):
    """Tool created from a function."""

    def __init__(
        self,
        func: Callable,
        metadata: ToolMetadata,
        permission_manager: Optional[Any] = None
    ):
        super().__init__(metadata, permission_manager)
        self.func = func
        self.is_async = asyncio.iscoroutinefunction(func)
        self.schema = ToolSchemaGenerator.generate_schema(func)

    async def _execute(self, **kwargs) -> Any:
        """Execute the wrapped function."""
        if self.is_async:
            return await self.func(**kwargs)
        else:
            # Run sync function in thread pool
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(None, functools.partial(self.func, **kwargs))


# ============================================================================
# Neural Mesh Agent Tool (v239.0)
# ============================================================================

class NeuralMeshAgentTool(IroncliwTool):
    """Tool that delegates to a Neural Mesh agent's execute_task().

    Each mesh agent capability (e.g., "fetch_unread_emails") gets wrapped
    as a IroncliwTool so the agent runtime's THINK step can discover it
    and the ACT step can execute it via the standard tool.run() pipeline.
    """

    def __init__(
        self,
        agent,  # BaseNeuralMeshAgent (untyped to avoid circular import) — may be None for deferred mesh
        capability: str,
        category: ToolCategory = ToolCategory.INTEGRATION,
        risk_level: ToolRiskLevel = ToolRiskLevel.LOW,
        timeout_seconds: float = 30.0,
    ):
        # Null-guard: agent may be None when neural mesh init was deferred (e.g. memory pressure)
        if agent is not None:
            agent_name = getattr(agent, "agent_name", "unknown")
            agent_type = getattr(agent, "agent_type", "unknown")
        else:
            agent_name = "deferred"
            agent_type = "deferred"

        tool_name = f"mesh:{agent_name}:{capability}"
        metadata = ToolMetadata(
            name=tool_name,
            description=f"[Neural Mesh] {capability} via {agent_name}",
            category=category,
            risk_level=risk_level,
            requires_permission=False,
            timeout_seconds=timeout_seconds,
            capabilities=[capability],
            tags=["neural_mesh", agent_type, agent_name],
        )
        super().__init__(metadata)
        self._agent = agent
        self._capability = capability

    async def _execute(self, **kwargs) -> Any:
        """Delegate to the mesh agent's execute_task method."""
        if self._agent is None:
            return {"error": "Agent unavailable — neural mesh deferred", "deferred": True}
        payload = {"action": self._capability, **kwargs}
        return await self._agent.execute_task(payload)


# ============================================================================
# Tool Registry
# ============================================================================

class ToolRegistry:
    """
    Dynamic tool registry with auto-discovery.

    Features:
    - Register tools by name or decorator
    - Auto-discover tools from modules
    - Query tools by capability
    - Hot-reload support
    """

    _instance: Optional["ToolRegistry"] = None

    def __init__(self):
        self._tools: Dict[str, IroncliwTool] = {}
        self._categories: Dict[ToolCategory, Set[str]] = {cat: set() for cat in ToolCategory}
        self._capabilities: Dict[str, Set[str]] = {}  # capability -> tool names
        self._loaded_modules: Set[str] = set()
        self.logger = logging.getLogger(__name__)

    @classmethod
    def get_instance(cls) -> "ToolRegistry":
        """Get singleton instance."""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    def register(
        self,
        tool: IroncliwTool,
        replace: bool = False
    ) -> None:
        """
        Register a tool.

        Args:
            tool: Tool to register
            replace: Whether to replace existing tool with same name
        """
        if tool.name in self._tools and not replace:
            raise ValueError(f"Tool '{tool.name}' already registered")

        self._tools[tool.name] = tool
        self._categories[tool.metadata.category].add(tool.name)

        # Index capabilities
        for cap in tool.metadata.capabilities:
            if cap not in self._capabilities:
                self._capabilities[cap] = set()
            self._capabilities[cap].add(tool.name)

        self.logger.info(f"Registered tool: {tool.name}")

    def register_function(
        self,
        func: Callable,
        name: Optional[str] = None,
        description: Optional[str] = None,
        category: ToolCategory = ToolCategory.UTILITY,
        risk_level: ToolRiskLevel = ToolRiskLevel.LOW,
        **metadata_kwargs
    ) -> IroncliwTool:
        """
        Register a function as a tool.

        Args:
            func: Function to register
            name: Tool name (defaults to function name)
            description: Tool description (defaults to docstring)
            category: Tool category
            risk_level: Risk level
            **metadata_kwargs: Additional metadata

        Returns:
            Created tool
        """
        tool_name = name or func.__name__
        tool_desc = description or inspect.getdoc(func) or f"Tool: {tool_name}"

        metadata = ToolMetadata(
            name=tool_name,
            description=tool_desc,
            category=category,
            risk_level=risk_level,
            **metadata_kwargs
        )

        tool = FunctionTool(func=func, metadata=metadata)
        self.register(tool)
        return tool

    def unregister(self, name: str) -> bool:
        """Unregister a tool."""
        if name not in self._tools:
            return False

        tool = self._tools[name]
        del self._tools[name]

        # Clean up indices
        self._categories[tool.metadata.category].discard(name)
        for cap in tool.metadata.capabilities:
            if cap in self._capabilities:
                self._capabilities[cap].discard(name)

        self.logger.info(f"Unregistered tool: {name}")
        return True

    def get(self, name: str) -> Optional[IroncliwTool]:
        """Get a tool by name."""
        return self._tools.get(name)

    def get_all(self) -> List[IroncliwTool]:
        """Get all registered tools."""
        return list(self._tools.values())

    def get_by_category(self, category: ToolCategory) -> List[IroncliwTool]:
        """Get tools by category."""
        names = self._categories.get(category, set())
        return [self._tools[n] for n in names if n in self._tools]

    def get_by_capability(self, capability: str) -> List[IroncliwTool]:
        """Get tools by capability."""
        names = self._capabilities.get(capability, set())
        return [self._tools[n] for n in names if n in self._tools]

    def search(
        self,
        query: str,
        category: Optional[ToolCategory] = None,
        risk_level_max: Optional[ToolRiskLevel] = None
    ) -> List[IroncliwTool]:
        """
        Search for tools matching criteria.

        Args:
            query: Search query (matches name, description, tags)
            category: Filter by category
            risk_level_max: Maximum risk level

        Returns:
            Matching tools
        """
        results = []
        query_lower = query.lower()
        risk_order = list(ToolRiskLevel)

        for tool in self._tools.values():
            # Check category filter
            if category and tool.metadata.category != category:
                continue

            # Check risk level filter
            if risk_level_max:
                tool_risk_idx = risk_order.index(tool.metadata.risk_level)
                max_risk_idx = risk_order.index(risk_level_max)
                if tool_risk_idx > max_risk_idx:
                    continue

            # Check query match
            if query_lower in tool.name.lower():
                results.append(tool)
            elif query_lower in tool.description.lower():
                results.append(tool)
            elif any(query_lower in tag.lower() for tag in tool.metadata.tags):
                results.append(tool)

        return results

    def discover_from_module(self, module_path: str) -> int:
        """
        Discover and register tools from a module.

        Args:
            module_path: Python module path (e.g., 'backend.tools.file_tools')

        Returns:
            Number of tools discovered
        """
        if module_path in self._loaded_modules:
            self.logger.debug(f"Module already loaded: {module_path}")
            return 0

        try:
            module = importlib.import_module(module_path)
        except ImportError as e:
            self.logger.error(f"Failed to import module {module_path}: {e}")
            return 0

        count = 0

        # Look for decorated functions
        for name, obj in inspect.getmembers(module):
            if hasattr(obj, '_jarvis_tool_metadata'):
                metadata = obj._jarvis_tool_metadata
                tool = FunctionTool(func=obj, metadata=metadata)
                self.register(tool, replace=True)
                count += 1

            # Look for IroncliwTool subclasses
            elif (inspect.isclass(obj)
                  and issubclass(obj, IroncliwTool)
                  and obj is not IroncliwTool):
                try:
                    tool_instance = obj()
                    self.register(tool_instance, replace=True)
                    count += 1
                except Exception as e:
                    self.logger.warning(f"Failed to instantiate {name}: {e}")

        self._loaded_modules.add(module_path)
        self.logger.info(f"Discovered {count} tools from {module_path}")
        return count

    def discover_from_directory(
        self,
        directory: Path,
        pattern: str = "*.py",
        base_module: str = ""
    ) -> int:
        """
        Discover tools from all Python files in a directory.

        Args:
            directory: Directory to scan
            pattern: File pattern to match
            base_module: Base module path

        Returns:
            Total tools discovered
        """
        total = 0

        if not directory.exists():
            self.logger.warning(f"Directory not found: {directory}")
            return 0

        for path in directory.glob(pattern):
            if path.name.startswith('_'):
                continue

            # Build module path
            relative = path.relative_to(directory.parent)
            module_parts = list(relative.with_suffix('').parts)
            if base_module:
                module_path = f"{base_module}.{'.'.join(module_parts)}"
            else:
                module_path = '.'.join(module_parts)

            total += self.discover_from_module(module_path)

        return total

    def to_langchain_tools(self) -> List[BaseTool]:
        """Convert all tools to LangChain tools."""
        if not LANGCHAIN_AVAILABLE:
            return []

        return [
            tool.to_langchain_tool()
            for tool in self._tools.values()
            if tool.to_langchain_tool() is not None
        ]

    def get_tool_manifest(self) -> Dict[str, Any]:
        """Get complete tool manifest."""
        return {
            "total_tools": len(self._tools),
            "categories": {
                cat.value: len(names)
                for cat, names in self._categories.items()
            },
            "capabilities": list(self._capabilities.keys()),
            "tools": [
                {
                    "name": tool.name,
                    "description": tool.description,
                    "category": tool.metadata.category.value,
                    "risk_level": tool.metadata.risk_level.value,
                    "version": tool.metadata.version,
                    "capabilities": tool.metadata.capabilities,
                    "tags": tool.metadata.tags
                }
                for tool in self._tools.values()
            ]
        }


# ============================================================================
# Tool Decorator
# ============================================================================

def jarvis_tool(
    name: Optional[str] = None,
    description: Optional[str] = None,
    category: ToolCategory = ToolCategory.UTILITY,
    risk_level: ToolRiskLevel = ToolRiskLevel.LOW,
    requires_permission: bool = True,
    capabilities: Optional[List[str]] = None,
    tags: Optional[List[str]] = None,
    **kwargs
):
    """
    Decorator to mark a function as a Ironcliw tool.

    Usage:
        @jarvis_tool(
            name="search_files",
            description="Search for files matching a pattern",
            category=ToolCategory.FILE_SYSTEM,
            risk_level=ToolRiskLevel.SAFE,
            capabilities=["file_search", "pattern_matching"]
        )
        async def search_files(pattern: str, directory: str = ".") -> List[str]:
            '''Search for files matching the given pattern.'''
            ...
    """
    def decorator(func: Callable) -> Callable:
        tool_name = name or func.__name__
        tool_desc = description or inspect.getdoc(func) or f"Tool: {tool_name}"

        metadata = ToolMetadata(
            name=tool_name,
            description=tool_desc,
            category=category,
            risk_level=risk_level,
            requires_permission=requires_permission,
            capabilities=capabilities or [],
            tags=tags or [],
            **kwargs
        )

        func._jarvis_tool_metadata = metadata

        @functools.wraps(func)
        async def wrapper(*args, **kw):
            return await func(*args, **kw) if asyncio.iscoroutinefunction(func) else func(*args, **kw)

        wrapper._jarvis_tool_metadata = metadata
        return wrapper

    return decorator


# ============================================================================
# Built-in Tools
# ============================================================================

class WebResearchTool(IroncliwTool):
    """Tool for structured live web search and synthesis."""

    SUPPORTED_OPERATIONS: Tuple[str, ...] = (
        "search",
        "read_page",
        "research",
        "research_markdown",
        "health",
        "metrics",
        "shutdown",
    )

    OPERATION_ALIASES: Dict[str, str] = {
        "web_search": "search",
        "search_web": "search",
        "read": "read_page",
        "web_read": "read_page",
        "web_research": "research",
        "report": "research_markdown",
        "research_report": "research_markdown",
        "get_health": "health",
        "get_metrics": "metrics",
        "close": "shutdown",
        "stop": "shutdown",
    }

    def __init__(self, permission_manager: Optional[Any] = None):
        metadata = ToolMetadata(
            name="web_research",
            description=(
                "Search the live web, read pages, and synthesize structured reports "
                "with source attribution"
            ),
            category=ToolCategory.NETWORK,
            risk_level=ToolRiskLevel.LOW,
            requires_permission=False,
            timeout_seconds=90.0,
            capabilities=[
                "web_search",
                "internet_research",
                "source_reading",
                "report_synthesis",
            ],
            tags=["web", "research", "search", "current_information"],
        )
        super().__init__(metadata, permission_manager)
        self._service = get_web_research_service()

    async def _execute(
        self,
        operation: str = "research",
        query: Optional[str] = None,
        url: Optional[str] = None,
        max_results: Optional[int] = None,
        max_sources: Optional[int] = None,
        max_chars: Optional[int] = None,
        include_types: Optional[Any] = None,
        **kwargs
    ) -> Dict[str, Any]:
        await self._service.initialize()

        op = (operation or kwargs.get("action") or kwargs.get("op") or "").strip().lower()
        op = self.OPERATION_ALIASES.get(op, op)
        if op not in self.SUPPORTED_OPERATIONS:
            raise ValueError(
                f"Unsupported operation '{op}'. Supported operations: {', '.join(self.SUPPORTED_OPERATIONS)}"
            )

        normalized_types = self._parse_type_filter(include_types or kwargs.get("result_types"))

        if op == "search":
            query_text = (query or kwargs.get("topic") or "").strip()
            results = await self._service.search(
                query=query_text,
                max_results=max_results,
                include_types=normalized_types,
                use_cache=self._to_bool(kwargs.get("use_cache"), default=True),
            )
            return {
                "operation": op,
                "query": query_text,
                "count": len(results),
                "results": results,
            }

        if op == "read_page":
            target_url = (url or kwargs.get("target_url") or "").strip()
            result = await self._service.read_page(
                url=target_url,
                max_chars=max_chars,
            )
            return {
                "operation": op,
                "result": result,
            }

        if op == "research":
            query_text = (query or kwargs.get("topic") or "").strip()
            report = await self._service.research(
                query=query_text,
                max_results=max_results,
                max_sources=max_sources,
                include_types=normalized_types,
            )
            return {
                "operation": op,
                "query": query_text,
                "report": report,
            }

        if op == "research_markdown":
            query_text = (query or kwargs.get("topic") or "").strip()
            report = await self._service.research(
                query=query_text,
                max_results=max_results,
                max_sources=max_sources,
                include_types=normalized_types,
            )
            return {
                "operation": op,
                "query": query_text,
                "markdown": report.get("markdown_report", ""),
                "report": report,
            }

        if op == "health":
            return {"operation": op, "health": self._service.get_health()}

        if op == "metrics":
            return {"operation": op, "metrics": self._service.get_metrics()}

        if op == "shutdown":
            await self._service.shutdown()
            return {"operation": op, "status": "shutdown_complete"}

        raise RuntimeError(f"Unhandled operation: {op}")

    @staticmethod
    def _parse_type_filter(raw: Optional[Any]) -> Optional[List[str]]:
        if raw is None:
            return None
        if isinstance(raw, (list, tuple, set)):
            values = [str(item).strip() for item in raw if str(item).strip()]
            return values or None
        values = [token.strip() for token in str(raw).split(",") if token.strip()]
        return values or None

    @staticmethod
    def _to_bool(value: Any, default: bool) -> bool:
        if value is None:
            return default
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            lowered = value.strip().lower()
            if lowered in {"1", "true", "yes", "y", "on"}:
                return True
            if lowered in {"0", "false", "no", "n", "off"}:
                return False
        return bool(value)


@dataclass(frozen=True)
class ShellExecutionPolicy:
    """Resolved policy for shell command execution."""

    allowed_cwd_roots: Tuple[Path, ...]
    denied_cwd_roots: Tuple[Path, ...]
    auto_approve_tiers: Tuple[str, ...]
    allow_shell_features: bool
    max_timeout_seconds: float
    max_output_bytes: int

    def as_dict(self) -> Dict[str, Any]:
        return {
            "allowed_cwd_roots": [str(path) for path in self.allowed_cwd_roots],
            "denied_cwd_roots": [str(path) for path in self.denied_cwd_roots],
            "auto_approve_tiers": list(self.auto_approve_tiers),
            "allow_shell_features": self.allow_shell_features,
            "max_timeout_seconds": self.max_timeout_seconds,
            "max_output_bytes": self.max_output_bytes,
        }


class ShellCommandTool(IroncliwTool):
    """Secure shell execution with command-tier safety and explicit policy controls."""

    CWD_ALLOWLIST_ENV = "Ironcliw_SHELL_CWD_ALLOWLIST"
    CWD_DENYLIST_ENV = "Ironcliw_SHELL_CWD_DENYLIST"
    AUTO_APPROVE_TIERS_ENV = "Ironcliw_SHELL_AUTO_APPROVE_TIERS"
    MAX_TIMEOUT_ENV = "Ironcliw_SHELL_MAX_TIMEOUT_SECONDS"
    MAX_OUTPUT_ENV = "Ironcliw_SHELL_MAX_OUTPUT_BYTES"
    ALLOW_SHELL_FEATURES_ENV = "Ironcliw_SHELL_ALLOW_SHELL_FEATURES"
    REPO_ROOTS_ENV = "Ironcliw_REPO_ROOTS"
    ALLOW_ROOT_PATHS_ENV = "Ironcliw_SHELL_ALLOW_ROOT_PATHS"
    EMIT_EVENTS_ENV = "Ironcliw_SHELL_EMIT_SAFETY_EVENTS"

    REPO_ENV_KEYS: Tuple[str, ...] = (
        "Ironcliw_PATH",
        "Ironcliw_REPO_PATH",
        "Ironcliw_CORE_PATH",
        "Ironcliw_PRIME_PATH",
        "Ironcliw_PRIME_REPO_PATH",
        "REACTOR_CORE_PATH",
        "Ironcliw_REACTOR_PATH",
    )

    SUPPORTED_OPERATIONS: Tuple[str, ...] = (
        "execute",
        "classify",
        "get_policy",
        "get_metrics",
    )

    OPERATION_ALIASES: Dict[str, str] = {
        "run": "execute",
        "shell": "execute",
        "shell_execute": "execute",
        "check": "classify",
        "inspect": "classify",
        "policy": "get_policy",
        "metrics": "get_metrics",
    }

    COMPLEX_TOKENS: Set[str] = {"|", "||", "&&", ";", "`"}

    def __init__(self, permission_manager: Optional[Any] = None):
        metadata = ToolMetadata(
            name="shell_agent",
            description=(
                "Execute terminal commands through policy-driven safety controls "
                "(tier classification, confirmation gates, and cwd allowlists)"
            ),
            category=ToolCategory.SYSTEM,
            risk_level=ToolRiskLevel.HIGH,
            requires_permission=False,
            timeout_seconds=90.0,
            capabilities=[
                "shell_execution",
                "command_classification",
                "package_management",
                "git_operations",
                "system_administration",
            ],
            tags=["shell", "terminal", "command", "safety", "policy"],
        )
        super().__init__(metadata, permission_manager)

        self._policy_lock = asyncio.Lock()
        self._policy_signature: Optional[Tuple[str, ...]] = None
        self._policy = self._build_policy()
        self._policy_signature = self._compute_policy_signature()

        self._metrics: Dict[str, Any] = {
            "total_requests": 0,
            "executed": 0,
            "classification_only": 0,
            "blocked": 0,
            "confirmation_required": 0,
            "failed": 0,
            "timed_out": 0,
            "tier_counts": {},
            "last_command_ts": None,
        }

        self._classifier = None
        try:
            from backend.system_control.command_safety import get_command_classifier

            self._classifier = get_command_classifier()
        except Exception as exc:
            self.logger.warning("Shell safety classifier unavailable: %s", exc)

    async def _execute(
        self,
        operation: str = "execute",
        command: Optional[Union[str, Sequence[str]]] = None,
        argv: Optional[Sequence[str]] = None,
        cwd: Optional[str] = None,
        timeout: Optional[float] = None,
        approved: Optional[Any] = None,
        require_confirmation: bool = True,
        allow_destructive: bool = False,
        safe_mode: bool = True,
        dry_run: bool = False,
        emit_events: Optional[bool] = None,
        allow_shell_features: Optional[bool] = None,
        env: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        await self._refresh_policy_if_changed()
        self._metrics["total_requests"] += 1

        op = (operation or kwargs.get("action") or kwargs.get("op") or "").strip().lower()
        op = self.OPERATION_ALIASES.get(op, op)
        if op not in self.SUPPORTED_OPERATIONS:
            raise ValueError(
                f"Unsupported operation '{op}'. Supported operations: {', '.join(self.SUPPORTED_OPERATIONS)}"
            )

        if op == "get_policy":
            return {"operation": op, "policy": self._policy.as_dict()}

        if op == "get_metrics":
            return {"operation": op, "metrics": dict(self._metrics)}

        command_value = command if command is not None else kwargs.get("cmd")
        argv_value = argv if argv is not None else kwargs.get("args")
        command_text, cmd_tokens = self._parse_command(command_value, argv_value)

        classification = await self._classify_command(
            command_text,
            emit_events=self._to_bool(emit_events, default=self._env_bool(self.EMIT_EVENTS_ENV, True)),
        )
        tier = str(classification.get("tier", "yellow")).lower()
        self._metrics["tier_counts"][tier] = self._metrics["tier_counts"].get(tier, 0) + 1

        response_base = {
            "operation": op,
            "command": command_text,
            "argv": cmd_tokens,
            "classification": classification,
        }

        if op == "classify":
            self._metrics["classification_only"] += 1
            return response_base

        resolved_cwd = self._resolve_and_validate_cwd(cwd or kwargs.get("working_directory") or ".")
        response_base["cwd"] = str(resolved_cwd)

        allow_complex = (
            self._to_bool(allow_shell_features, default=self._policy.allow_shell_features)
            or self._to_bool(kwargs.get("allow_complex"), default=False)
        )
        if self._contains_complex_shell_tokens(command_text, cmd_tokens) and not allow_complex:
            self._metrics["blocked"] += 1
            return {
                **response_base,
                "success": False,
                "blocked": True,
                "error": (
                    "Complex shell syntax is disabled by policy. "
                    "Pass a simple command/argv or enable allow_shell_features explicitly."
                ),
            }

        explicit_approval = self._to_bool(approved, default=False)
        requires_confirmation = bool(classification.get("requires_confirmation", True))
        is_destructive = bool(classification.get("is_destructive", False))

        if safe_mode:
            if tier == "red" and (is_destructive or not allow_destructive):
                if not explicit_approval or not allow_destructive:
                    self._metrics["blocked"] += 1
                    return {
                        **response_base,
                        "success": False,
                        "blocked": True,
                        "error": (
                            "Red-tier/destructive command blocked. "
                            "Set allow_destructive=true and approved=true to proceed."
                        ),
                    }

            if requires_confirmation and require_confirmation:
                approved_by_policy = await self._is_approved_by_policy(
                    tier=tier,
                    command_text=command_text,
                    cwd=str(resolved_cwd),
                    classification=classification,
                    explicit_approval=explicit_approval,
                )
                if not approved_by_policy:
                    self._metrics["confirmation_required"] += 1
                    return {
                        **response_base,
                        "success": False,
                        "requires_confirmation": True,
                        "error": "Command requires explicit approval before execution.",
                    }

        if dry_run:
            return {
                **response_base,
                "success": True,
                "dry_run": True,
                "would_execute": True,
            }

        exec_timeout = self._clamp_timeout(timeout)
        result = await self._run_exec(
            cmd_tokens=cmd_tokens,
            cwd=resolved_cwd,
            timeout_seconds=exec_timeout,
            env_overrides=env if isinstance(env, dict) else None,
        )

        self._metrics["last_command_ts"] = time.time()
        if result["timed_out"]:
            self._metrics["timed_out"] += 1
        elif result["success"]:
            self._metrics["executed"] += 1
        else:
            self._metrics["failed"] += 1

        return {**response_base, **result}

    async def _is_approved_by_policy(
        self,
        tier: str,
        command_text: str,
        cwd: str,
        classification: Dict[str, Any],
        explicit_approval: bool,
    ) -> bool:
        if explicit_approval:
            return True

        if tier in self._policy.auto_approve_tiers:
            return True

        if self.permission_manager:
            try:
                return await self.permission_manager.check_permission(
                    action_type="tool:shell_agent",
                    target=command_text,
                    context={
                        "cwd": cwd,
                        "classification": classification,
                    },
                    require_explicit=True,
                )
            except TypeError:
                try:
                    return await self.permission_manager.check_permission(
                        action_type="tool:shell_agent",
                        target=command_text,
                        context={
                            "cwd": cwd,
                            "classification": classification,
                        },
                    )
                except Exception as exc:
                    self.logger.debug("Permission check failed: %s", exc)
                    return False
            except Exception as exc:
                self.logger.debug("Permission check failed: %s", exc)
                return False

        return False

    async def _classify_command(self, command: str, emit_events: bool) -> Dict[str, Any]:
        if self._classifier is None:
            return {
                "command": command,
                "tier": "yellow",
                "risk_categories": ["system_modification"],
                "requires_confirmation": True,
                "is_destructive": False,
                "confidence": 0.4,
                "reasoning": "Safety classifier unavailable; defaulting to caution.",
            }

        try:
            result = await self._classifier.classify_async(command, emit_events=emit_events)
            if hasattr(result, "to_dict"):
                return result.to_dict()
            if isinstance(result, dict):
                return result
        except Exception as exc:
            self.logger.warning("Command safety classification failed: %s", exc)

        return {
            "command": command,
            "tier": "yellow",
            "risk_categories": ["system_modification"],
            "requires_confirmation": True,
            "is_destructive": False,
            "confidence": 0.3,
            "reasoning": "Safety classifier failed; defaulting to caution.",
        }

    async def _run_exec(
        self,
        cmd_tokens: Sequence[str],
        cwd: Path,
        timeout_seconds: float,
        env_overrides: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        started = time.time()

        if not cmd_tokens:
            raise ValueError("Command arguments cannot be empty")

        executable = cmd_tokens[0]
        resolved_exec = executable if Path(executable).is_absolute() else shutil.which(executable)
        if not resolved_exec:
            return {
                "success": False,
                "returncode": -1,
                "stdout": "",
                "stderr": f"Executable not found: {executable}",
                "timed_out": False,
                "duration_ms": round((time.time() - started) * 1000.0, 2),
            }

        env_payload = None
        if env_overrides:
            env_payload = dict(os.environ)
            for key, value in env_overrides.items():
                if not isinstance(key, str) or not key:
                    continue
                env_payload[key] = str(value)

        process = await asyncio.create_subprocess_exec(
            *cmd_tokens,
            cwd=str(cwd),
            env=env_payload,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )

        timed_out = False
        try:
            stdout_raw, stderr_raw = await asyncio.wait_for(
                process.communicate(),
                timeout=timeout_seconds,
            )
        except asyncio.TimeoutError:
            timed_out = True
            process.kill()
            await process.wait()
            stdout_raw = b""
            stderr_raw = b"Command timed out"

        stdout_bytes = stdout_raw[: self._policy.max_output_bytes]
        stderr_bytes = stderr_raw[: self._policy.max_output_bytes]
        stdout_text = stdout_bytes.decode("utf-8", errors="replace")
        stderr_text = stderr_bytes.decode("utf-8", errors="replace")

        if len(stdout_raw) > self._policy.max_output_bytes:
            stdout_text += "\n[output truncated]"
        if len(stderr_raw) > self._policy.max_output_bytes:
            stderr_text += "\n[output truncated]"

        return {
            "success": (process.returncode == 0) and not timed_out,
            "returncode": process.returncode if process.returncode is not None else -1,
            "stdout": stdout_text,
            "stderr": stderr_text,
            "timed_out": timed_out,
            "duration_ms": round((time.time() - started) * 1000.0, 2),
            "timeout_seconds": timeout_seconds,
        }

    def _parse_command(
        self,
        command: Optional[Union[str, Sequence[str]]],
        argv: Optional[Sequence[str]],
    ) -> Tuple[str, List[str]]:
        if argv:
            tokens = [str(token) for token in argv if str(token)]
            command_text = " ".join(shlex.quote(token) for token in tokens)
            if not tokens:
                raise ValueError("argv cannot be empty")
            return command_text, tokens

        if isinstance(command, (list, tuple)):
            tokens = [str(token) for token in command if str(token)]
            command_text = " ".join(shlex.quote(token) for token in tokens)
            if not tokens:
                raise ValueError("command list cannot be empty")
            return command_text, tokens

        command_text = str(command or "").strip()
        if not command_text:
            raise ValueError("Missing required parameter: command or argv")

        if "\n" in command_text:
            raise ValueError("Multiline commands are not allowed")

        try:
            tokens = shlex.split(command_text)
        except ValueError as exc:
            raise ValueError(f"Invalid command syntax: {exc}") from exc
        if not tokens:
            raise ValueError("Command resolved to no executable tokens")
        return command_text, tokens

    def _contains_complex_shell_tokens(self, command_text: str, tokens: Sequence[str]) -> bool:
        if any(token in self.COMPLEX_TOKENS for token in tokens):
            return True
        return "$(" in command_text or "<<" in command_text or ">>" in command_text

    async def _refresh_policy_if_changed(self) -> None:
        signature = self._compute_policy_signature()
        if signature == self._policy_signature:
            return
        async with self._policy_lock:
            signature = self._compute_policy_signature()
            if signature == self._policy_signature:
                return
            self._policy = self._build_policy()
            self._policy_signature = signature

    def _build_policy(self) -> ShellExecutionPolicy:
        allowed_roots = self._canonicalize_paths(self._parse_env_paths(self.CWD_ALLOWLIST_ENV))
        denied_roots = self._canonicalize_paths(self._parse_env_paths(self.CWD_DENYLIST_ENV))

        if not allowed_roots:
            defaults: List[Path] = []
            defaults.extend(self._parse_env_paths(self.REPO_ROOTS_ENV))
            for key in self.REPO_ENV_KEYS:
                raw = os.getenv(key, "").strip()
                if raw:
                    defaults.append(Path(raw))
            defaults.append(Path.cwd())
            defaults.append(Path.home() / ".jarvis")
            allowed_roots = self._canonicalize_paths(defaults)

        if not allowed_roots:
            allowed_roots = (self._resolve_user_path(str(Path.cwd())),)

        auto_approve_raw = os.getenv(self.AUTO_APPROVE_TIERS_ENV, "green,yellow").strip()
        auto_approve_tiers = tuple(
            sorted(
                {
                    tier.strip().lower()
                    for tier in re.split(r"[,;\s]+", auto_approve_raw)
                    if tier.strip()
                }
            )
        )

        return ShellExecutionPolicy(
            allowed_cwd_roots=allowed_roots,
            denied_cwd_roots=denied_roots,
            auto_approve_tiers=auto_approve_tiers,
            allow_shell_features=self._env_bool(self.ALLOW_SHELL_FEATURES_ENV, False),
            max_timeout_seconds=self._env_float(self.MAX_TIMEOUT_ENV, 120.0, minimum=1.0),
            max_output_bytes=self._env_int(self.MAX_OUTPUT_ENV, 200_000, minimum=1_024),
        )

    def _resolve_and_validate_cwd(self, raw_cwd: str) -> Path:
        resolved = self._resolve_user_path(raw_cwd)

        if any(self._is_relative(resolved, denied) for denied in self._policy.denied_cwd_roots):
            raise PermissionError(f"Working directory explicitly denied by policy: {resolved}")

        if not any(self._is_relative(resolved, allowed) for allowed in self._policy.allowed_cwd_roots):
            raise PermissionError(f"Working directory not in allowed roots: {resolved}")

        if not resolved.exists():
            raise FileNotFoundError(f"Working directory does not exist: {resolved}")
        if not resolved.is_dir():
            raise NotADirectoryError(f"Working directory is not a directory: {resolved}")
        return resolved

    def _compute_policy_signature(self) -> Tuple[str, ...]:
        values = [
            os.getenv(self.CWD_ALLOWLIST_ENV, ""),
            os.getenv(self.CWD_DENYLIST_ENV, ""),
            os.getenv(self.AUTO_APPROVE_TIERS_ENV, ""),
            os.getenv(self.MAX_TIMEOUT_ENV, ""),
            os.getenv(self.MAX_OUTPUT_ENV, ""),
            os.getenv(self.ALLOW_SHELL_FEATURES_ENV, ""),
            os.getenv(self.REPO_ROOTS_ENV, ""),
            os.getenv(self.ALLOW_ROOT_PATHS_ENV, ""),
            os.getenv(self.EMIT_EVENTS_ENV, ""),
        ]
        values.extend(os.getenv(key, "") for key in self.REPO_ENV_KEYS)
        return tuple(values)

    def _canonicalize_paths(self, paths: Sequence[Path]) -> Tuple[Path, ...]:
        allow_root_paths = self._env_bool(self.ALLOW_ROOT_PATHS_ENV, False)
        normalized: List[Path] = []
        for path in paths:
            try:
                resolved = self._resolve_user_path(str(path))
                if not allow_root_paths and resolved == Path(resolved.anchor):
                    self.logger.warning("Skipping root path in shell policy for safety: %s", resolved)
                    continue
                normalized.append(resolved)
            except Exception:
                continue

        unique: List[Path] = []
        for path in sorted(set(normalized), key=lambda candidate: len(candidate.parts)):
            if any(self._is_relative(path, existing) for existing in unique):
                continue
            unique.append(path)
        return tuple(unique)

    def _parse_env_paths(self, env_key: str) -> List[Path]:
        raw = os.getenv(env_key, "").strip()
        if not raw:
            return []

        values: List[str] = []
        if raw.startswith("["):
            try:
                parsed = json.loads(raw)
                if isinstance(parsed, list):
                    values = [str(item).strip() for item in parsed if str(item).strip()]
            except Exception:
                values = []
        if not values:
            values = [item.strip() for item in re.split(r"[,;\n]+", raw) if item.strip()]

        return [Path(value).expanduser() for value in values]

    @staticmethod
    def _resolve_user_path(raw_path: str) -> Path:
        candidate = Path(raw_path).expanduser()
        if not candidate.is_absolute():
            candidate = Path.cwd() / candidate

        missing_parts: List[str] = []
        probe = candidate
        while not probe.exists():
            missing_parts.append(probe.name)
            parent = probe.parent
            if parent == probe:
                break
            probe = parent

        resolved_base = probe.resolve()
        for part in reversed(missing_parts):
            resolved_base = resolved_base / part
        return resolved_base

    @staticmethod
    def _is_relative(path: Path, root: Path) -> bool:
        try:
            path.relative_to(root)
            return True
        except ValueError:
            return False

    def _clamp_timeout(self, timeout: Optional[float]) -> float:
        if timeout is None:
            return self._policy.max_timeout_seconds
        try:
            value = float(timeout)
        except (TypeError, ValueError):
            return self._policy.max_timeout_seconds
        return max(1.0, min(value, self._policy.max_timeout_seconds))

    @staticmethod
    def _to_bool(value: Any, default: bool) -> bool:
        if value is None:
            return default
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            lowered = value.strip().lower()
            if lowered in {"1", "true", "yes", "y", "on"}:
                return True
            if lowered in {"0", "false", "no", "n", "off"}:
                return False
        return bool(value)

    @staticmethod
    def _env_bool(env_key: str, default: bool) -> bool:
        return ShellCommandTool._to_bool(os.getenv(env_key), default=default)

    @staticmethod
    def _env_int(env_key: str, default: int, minimum: int = 0) -> int:
        raw = os.getenv(env_key, "").strip()
        if not raw:
            return default
        try:
            return max(int(raw), minimum)
        except ValueError:
            return default

    @staticmethod
    def _env_float(env_key: str, default: float, minimum: float = 0.0) -> float:
        raw = os.getenv(env_key, "").strip()
        if not raw:
            return default
        try:
            return max(float(raw), minimum)
        except ValueError:
            return default


@dataclass(frozen=True)
class MediaControlPolicy:
    """Resolved policy for media control operations."""

    allowed_players: Tuple[str, ...]
    default_player: str
    allow_autostart: bool
    max_volume: int
    command_timeout_seconds: float

    def as_dict(self) -> Dict[str, Any]:
        return {
            "allowed_players": list(self.allowed_players),
            "default_player": self.default_player,
            "allow_autostart": self.allow_autostart,
            "max_volume": self.max_volume,
            "command_timeout_seconds": self.command_timeout_seconds,
        }


class MediaControlTool(IroncliwTool):
    """Native media playback control for Spotify and Apple Music via AppleScript."""

    ALLOWED_PLAYERS_ENV = "Ironcliw_MEDIA_ALLOWED_PLAYERS"
    DEFAULT_PLAYER_ENV = "Ironcliw_MEDIA_DEFAULT_PLAYER"
    ALLOW_AUTOSTART_ENV = "Ironcliw_MEDIA_ALLOW_AUTOSTART"
    MAX_VOLUME_ENV = "Ironcliw_MEDIA_MAX_VOLUME"
    COMMAND_TIMEOUT_ENV = "Ironcliw_MEDIA_COMMAND_TIMEOUT_SECONDS"

    SUPPORTED_PLAYERS: Tuple[str, ...] = ("spotify", "music")
    PLAYER_ALIASES: Dict[str, str] = {
        "spotify": "spotify",
        "apple_music": "music",
        "applemusic": "music",
        "itunes": "music",
        "music": "music",
    }

    SUPPORTED_OPERATIONS: Tuple[str, ...] = (
        "play",
        "pause",
        "toggle",
        "stop",
        "next",
        "previous",
        "set_volume",
        "get_status",
        "list_players",
        "get_policy",
        "get_metrics",
    )
    OPERATION_ALIASES: Dict[str, str] = {
        "resume": "play",
        "play_music": "play",
        "pause_music": "pause",
        "stop_music": "stop",
        "next_track": "next",
        "previous_track": "previous",
        "prev": "previous",
        "volume": "set_volume",
        "status": "get_status",
        "players": "list_players",
        "policy": "get_policy",
        "metrics": "get_metrics",
    }

    def __init__(self, permission_manager: Optional[Any] = None):
        metadata = ToolMetadata(
            name="media_control_agent",
            description=(
                "Control Spotify and Apple Music playback with policy-scoped operations "
                "(play, pause, skip, previous, stop, volume, status)."
            ),
            category=ToolCategory.COMMUNICATION,
            risk_level=ToolRiskLevel.LOW,
            requires_permission=False,
            timeout_seconds=20.0,
            capabilities=[
                "media_playback_control",
                "spotify_control",
                "apple_music_control",
            ],
            tags=["media", "music", "spotify", "apple_music", "applescript"],
        )
        super().__init__(metadata, permission_manager)

        self._policy_lock = asyncio.Lock()
        self._policy_signature: Optional[Tuple[str, ...]] = None
        self._policy = self._build_policy()
        self._policy_signature = self._compute_policy_signature()
        self._metrics: Dict[str, Any] = {
            "total_requests": 0,
            "successful": 0,
            "failed": 0,
            "operation_counts": {},
            "player_counts": {},
            "last_command_ts": None,
        }

    async def _execute(
        self,
        operation: str = "get_status",
        player: Optional[str] = None,
        playlist: Optional[str] = None,
        playlist_uri: Optional[str] = None,
        volume: Optional[int] = None,
        auto_start: Optional[Any] = None,
        **kwargs
    ) -> Dict[str, Any]:
        await self._refresh_policy_if_changed()
        self._metrics["total_requests"] += 1

        op = (operation or kwargs.get("action") or kwargs.get("op") or "").strip().lower()
        op = self.OPERATION_ALIASES.get(op, op)
        if op not in self.SUPPORTED_OPERATIONS:
            return {
                "success": False,
                "error": f"Unsupported operation '{op}'. Supported operations: {', '.join(self.SUPPORTED_OPERATIONS)}",
            }

        self._metrics["operation_counts"][op] = self._metrics["operation_counts"].get(op, 0) + 1

        if op == "get_policy":
            return {"operation": op, "policy": self._policy.as_dict(), "success": True}

        if op == "get_metrics":
            return {"operation": op, "metrics": dict(self._metrics), "success": True}

        if op == "list_players":
            statuses = await self._collect_player_status()
            return {"operation": op, "success": True, "players": statuses}

        requested_player = player or kwargs.get("target") or kwargs.get("app")
        target_player = self._normalize_player_name(requested_player)

        if op == "get_status":
            if target_player and target_player != "auto":
                if target_player not in self._policy.allowed_players:
                    return {
                        "operation": op,
                        "success": False,
                        "error": f"Player '{target_player}' not allowed by policy",
                    }
                status = await self._probe_player_status(target_player)
                return {"operation": op, "success": True, "player": target_player, "status": status}
            statuses = await self._collect_player_status()
            return {"operation": op, "success": True, "players": statuses}

        if op == "set_volume":
            raw_volume = volume if volume is not None else kwargs.get("value")
            if raw_volume is None:
                return {"operation": op, "success": False, "error": "Missing required parameter: volume"}
            try:
                clamped_volume = self._clamp_volume(int(raw_volume))
            except (TypeError, ValueError):
                return {"operation": op, "success": False, "error": "Volume must be an integer"}
        else:
            clamped_volume = None

        allow_autostart = self._to_bool(auto_start, default=self._policy.allow_autostart)
        resolved_player = await self._resolve_target_player(target_player, prefer_running=True)
        if not resolved_player:
            return {
                "operation": op,
                "success": False,
                "error": "No allowed media player available (Spotify/Music).",
            }

        if not allow_autostart and op in {"play", "pause", "toggle", "stop", "next", "previous", "set_volume"}:
            status = await self._probe_player_status(resolved_player)
            if not status.get("running", False):
                return {
                    "operation": op,
                    "success": False,
                    "player": resolved_player,
                    "error": f"{resolved_player} is not running and autostart is disabled by policy.",
                }

        try:
            result = await self._execute_player_operation(
                player=resolved_player,
                operation=op,
                playlist=playlist or kwargs.get("playlist_name"),
                playlist_uri=playlist_uri or kwargs.get("uri"),
                volume=clamped_volume,
                allow_autostart=allow_autostart,
            )
        except Exception as exc:
            self._metrics["failed"] += 1
            return {"operation": op, "success": False, "player": resolved_player, "error": str(exc)}

        self._metrics["successful"] += 1
        self._metrics["player_counts"][resolved_player] = self._metrics["player_counts"].get(resolved_player, 0) + 1
        self._metrics["last_command_ts"] = time.time()
        return result

    async def _resolve_target_player(self, player: Optional[str], prefer_running: bool) -> Optional[str]:
        normalized = self._normalize_player_name(player)
        if normalized and normalized != "auto":
            if normalized not in self._policy.allowed_players:
                return None
            return normalized

        statuses = await self._collect_player_status()
        if prefer_running:
            for candidate in self._policy.allowed_players:
                status = statuses.get(candidate, {})
                if status.get("running") and str(status.get("state", "")).lower() == "playing":
                    return candidate
            for candidate in self._policy.allowed_players:
                status = statuses.get(candidate, {})
                if status.get("running"):
                    return candidate

        default_player = self._normalize_player_name(self._policy.default_player)
        if default_player in self._policy.allowed_players:
            return default_player

        return self._policy.allowed_players[0] if self._policy.allowed_players else None

    async def _collect_player_status(self) -> Dict[str, Dict[str, Any]]:
        statuses: Dict[str, Dict[str, Any]] = {}
        for player in self._policy.allowed_players:
            statuses[player] = await self._probe_player_status(player)
        return statuses

    async def _probe_player_status(self, player: str) -> Dict[str, Any]:
        app_name = self._player_app_name(player)
        script = f'''
set runningFlag to false
tell application "System Events"
    set runningFlag to (name of processes) contains "{app_name}"
end tell
if runningFlag then
    tell application "{app_name}"
        set stateText to "unknown"
        try
            set stateText to (player state as text)
        end try
        set trackName to ""
        set artistName to ""
        set albumName to ""
        set volumeLevel to -1
        try
            set volumeLevel to sound volume
        end try
        try
            set trackName to name of current track
        end try
        try
            set artistName to artist of current track
        end try
        try
            set albumName to album of current track
        end try
        return "running=true|state=" & stateText & "|track=" & trackName & "|artist=" & artistName & "|album=" & albumName & "|volume=" & (volumeLevel as text)
    end tell
else
    return "running=false|state=stopped|track=|artist=|album=|volume="
end if
'''
        result = await self._run_applescript(script, timeout_seconds=self._policy.command_timeout_seconds)
        if not result["success"]:
            return {
                "running": False,
                "state": "unavailable",
                "error": result["error"],
            }
        parsed = self._parse_key_value_payload(result["stdout"])
        parsed["running"] = self._to_bool(parsed.get("running"), default=False)
        volume = str(parsed.get("volume", "")).strip()
        parsed["volume"] = int(volume) if volume.isdigit() else None
        return parsed

    async def _execute_player_operation(
        self,
        player: str,
        operation: str,
        playlist: Optional[str],
        playlist_uri: Optional[str],
        volume: Optional[int],
        allow_autostart: bool,
    ) -> Dict[str, Any]:
        app_name = self._player_app_name(player)
        operation = self.OPERATION_ALIASES.get(operation, operation)

        script = self._build_player_script(
            player=player,
            app_name=app_name,
            operation=operation,
            playlist=playlist,
            playlist_uri=playlist_uri,
            volume=volume,
            allow_autostart=allow_autostart,
        )
        result = await self._run_applescript(script, timeout_seconds=self._policy.command_timeout_seconds)
        if not result["success"]:
            return {
                "operation": operation,
                "success": False,
                "player": player,
                "error": result["error"],
            }

        status = await self._probe_player_status(player)
        return {
            "operation": operation,
            "success": True,
            "player": player,
            "status": status,
            "message": result["stdout"] or f"{operation} executed",
        }

    def _build_player_script(
        self,
        player: str,
        app_name: str,
        operation: str,
        playlist: Optional[str],
        playlist_uri: Optional[str],
        volume: Optional[int],
        allow_autostart: bool,
    ) -> str:
        playlist_name = self._escape_applescript_string(playlist or "")
        playlist_uri_resolved = self._normalize_spotify_playlist_uri(playlist_uri or playlist or "")
        playlist_uri_escaped = self._escape_applescript_string(playlist_uri_resolved)
        autostart_stmt = f'tell application "{app_name}" to activate' if allow_autostart else ""

        if operation == "play":
            if player == "spotify" and playlist_uri_resolved:
                return f'''
{autostart_stmt}
tell application "{app_name}"
    play track "{playlist_uri_escaped}"
end tell
return "ok"
'''
            if player == "spotify" and playlist and not playlist_uri_resolved:
                raise RuntimeError(
                    "Spotify playlist playback requires a URI/link (spotify:playlist:... or https://open.spotify.com/playlist/...)"
                )
            if player == "music" and playlist_name:
                return f'''
{autostart_stmt}
tell application "{app_name}"
    if exists playlist "{playlist_name}" then
        play playlist "{playlist_name}"
    else
        error "playlist-not-found"
    end if
end tell
return "ok"
'''
            return f'''
{autostart_stmt}
tell application "{app_name}"
    play
end tell
return "ok"
'''

        if operation == "pause":
            return f'''
tell application "{app_name}"
    pause
end tell
return "ok"
'''

        if operation == "toggle":
            return f'''
{autostart_stmt}
tell application "{app_name}"
    if (player state as text) is "playing" then
        pause
    else
        play
    end if
end tell
return "ok"
'''

        if operation == "stop":
            if player == "spotify":
                return f'''
tell application "{app_name}"
    pause
end tell
return "ok"
'''
            return f'''
tell application "{app_name}"
    stop
end tell
return "ok"
'''

        if operation == "next":
            return f'''
tell application "{app_name}"
    next track
end tell
return "ok"
'''

        if operation == "previous":
            return f'''
tell application "{app_name}"
    previous track
end tell
return "ok"
'''

        if operation == "set_volume":
            if volume is None:
                raise RuntimeError("Missing required volume for set_volume")
            return f'''
tell application "{app_name}"
    set sound volume to {volume}
end tell
return "ok"
'''

        raise RuntimeError(f"Unsupported media operation: {operation}")

    async def _run_applescript(self, script: str, timeout_seconds: float) -> Dict[str, Any]:
        import sys
        if sys.platform == "win32":
            return {
                "success": False,
                "stdout": "",
                "stderr": "AppleScript not available on Windows",
                "error": "AppleScript not available on Windows",
                "returncode": -1,
                "timed_out": False,
            }
        process = await asyncio.create_subprocess_exec(
            "osascript",
            "-e",
            script,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )

        timed_out = False
        try:
            stdout_raw, stderr_raw = await asyncio.wait_for(process.communicate(), timeout=timeout_seconds)
        except asyncio.TimeoutError:
            timed_out = True
            process.kill()
            await process.wait()
            stdout_raw = b""
            stderr_raw = b"AppleScript command timed out"

        stdout_text = (stdout_raw or b"").decode("utf-8", errors="replace").strip()
        stderr_text = (stderr_raw or b"").decode("utf-8", errors="replace").strip()
        success = bool(process.returncode == 0 and not timed_out)
        return {
            "success": success,
            "stdout": stdout_text,
            "stderr": stderr_text,
            "error": stderr_text or "AppleScript execution failed",
            "returncode": process.returncode if process.returncode is not None else -1,
            "timed_out": timed_out,
        }

    async def _refresh_policy_if_changed(self) -> None:
        signature = self._compute_policy_signature()
        if signature == self._policy_signature:
            return
        async with self._policy_lock:
            signature = self._compute_policy_signature()
            if signature == self._policy_signature:
                return
            self._policy = self._build_policy()
            self._policy_signature = signature

    def _build_policy(self) -> MediaControlPolicy:
        allowed_players_raw = os.getenv(self.ALLOWED_PLAYERS_ENV, "spotify,music")
        allowed_players = tuple(
            player
            for player in self._parse_player_list(allowed_players_raw)
            if player in self.SUPPORTED_PLAYERS
        )
        if not allowed_players:
            allowed_players = ("spotify", "music")

        default_player = self._normalize_player_name(
            os.getenv(self.DEFAULT_PLAYER_ENV, "auto").strip().lower()
        ) or "auto"
        if default_player not in (*allowed_players, "auto"):
            default_player = "auto"

        return MediaControlPolicy(
            allowed_players=allowed_players,
            default_player=default_player,
            allow_autostart=self._env_bool(self.ALLOW_AUTOSTART_ENV, True),
            max_volume=self._env_int(self.MAX_VOLUME_ENV, 90, minimum=10),
            command_timeout_seconds=self._env_float(self.COMMAND_TIMEOUT_ENV, 8.0, minimum=1.0),
        )

    def _compute_policy_signature(self) -> Tuple[str, ...]:
        return (
            os.getenv(self.ALLOWED_PLAYERS_ENV, ""),
            os.getenv(self.DEFAULT_PLAYER_ENV, ""),
            os.getenv(self.ALLOW_AUTOSTART_ENV, ""),
            os.getenv(self.MAX_VOLUME_ENV, ""),
            os.getenv(self.COMMAND_TIMEOUT_ENV, ""),
        )

    @classmethod
    def _normalize_player_name(cls, value: Optional[str]) -> Optional[str]:
        if value is None:
            return None
        normalized = str(value).strip().lower().replace(" ", "_")
        if not normalized:
            return None
        if normalized in {"auto", "any"}:
            return "auto"
        return cls.PLAYER_ALIASES.get(normalized, normalized)

    @staticmethod
    def _parse_player_list(raw: str) -> List[str]:
        return [
            item.strip().lower().replace(" ", "_")
            for item in re.split(r"[,;\s]+", raw or "")
            if item.strip()
        ]

    @staticmethod
    def _player_app_name(player: str) -> str:
        return "Spotify" if player == "spotify" else "Music"

    def _clamp_volume(self, volume: int) -> int:
        return max(0, min(volume, self._policy.max_volume))

    @staticmethod
    def _escape_applescript_string(value: str) -> str:
        return value.replace("\\", "\\\\").replace('"', '\\"')

    @staticmethod
    def _parse_key_value_payload(payload: str) -> Dict[str, Any]:
        result: Dict[str, Any] = {}
        for part in payload.split("|"):
            if "=" not in part:
                continue
            key, value = part.split("=", 1)
            result[key.strip()] = value.strip()
        return result

    @staticmethod
    def _normalize_spotify_playlist_uri(raw: str) -> str:
        candidate = (raw or "").strip()
        if not candidate:
            return ""
        if candidate.startswith("spotify:playlist:"):
            return candidate
        match = re.search(r"open\.spotify\.com/playlist/([a-zA-Z0-9]+)", candidate)
        if match:
            return f"spotify:playlist:{match.group(1)}"
        return ""

    @staticmethod
    def _to_bool(value: Any, default: bool) -> bool:
        if value is None:
            return default
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            lowered = value.strip().lower()
            if lowered in {"1", "true", "yes", "y", "on"}:
                return True
            if lowered in {"0", "false", "no", "n", "off"}:
                return False
        return bool(value)

    @staticmethod
    def _env_bool(env_key: str, default: bool) -> bool:
        return MediaControlTool._to_bool(os.getenv(env_key), default=default)

    @staticmethod
    def _env_int(env_key: str, default: int, minimum: int = 0) -> int:
        raw = os.getenv(env_key, "").strip()
        if not raw:
            return default
        try:
            return max(int(raw), minimum)
        except ValueError:
            return default

    @staticmethod
    def _env_float(env_key: str, default: float, minimum: float = 0.0) -> float:
        raw = os.getenv(env_key, "").strip()
        if not raw:
            return default
        try:
            return max(float(raw), minimum)
        except ValueError:
            return default


@dataclass(frozen=True)
class ImageGenerationPolicy:
    """Resolved policy for image generation operations."""

    output_root: Path
    default_provider: str
    openai_model: str
    sd_webui_url: str
    max_dimension: int
    max_prompt_chars: int
    timeout_seconds: float
    allowed_formats: Tuple[str, ...]

    def as_dict(self) -> Dict[str, Any]:
        return {
            "output_root": str(self.output_root),
            "default_provider": self.default_provider,
            "openai_model": self.openai_model,
            "sd_webui_url": self.sd_webui_url,
            "max_dimension": self.max_dimension,
            "max_prompt_chars": self.max_prompt_chars,
            "timeout_seconds": self.timeout_seconds,
            "allowed_formats": list(self.allowed_formats),
        }


class ImageGenerationTool(IroncliwTool):
    """Text-to-image generation with provider abstraction and output policy controls."""

    OUTPUT_DIR_ENV = "Ironcliw_IMAGE_OUTPUT_DIR"
    PROVIDER_ENV = "Ironcliw_IMAGE_PROVIDER"
    OPENAI_MODEL_ENV = "Ironcliw_IMAGE_OPENAI_MODEL"
    SD_WEBUI_URL_ENV = "Ironcliw_IMAGE_SD_WEBUI_URL"
    MAX_DIMENSION_ENV = "Ironcliw_IMAGE_MAX_DIMENSION"
    MAX_PROMPT_CHARS_ENV = "Ironcliw_IMAGE_MAX_PROMPT_CHARS"
    TIMEOUT_ENV = "Ironcliw_IMAGE_TIMEOUT_SECONDS"
    FORMATS_ENV = "Ironcliw_IMAGE_ALLOWED_FORMATS"

    SUPPORTED_PROVIDERS: Tuple[str, ...] = ("openai", "sd_webui")
    SUPPORTED_OPERATIONS: Tuple[str, ...] = ("generate", "get_policy", "get_metrics")
    OPERATION_ALIASES: Dict[str, str] = {
        "create": "generate",
        "create_image": "generate",
        "render": "generate",
        "policy": "get_policy",
        "metrics": "get_metrics",
    }

    def __init__(self, permission_manager: Optional[Any] = None):
        metadata = ToolMetadata(
            name="image_generation_agent",
            description=(
                "Generate images from prompts via configured providers (OpenAI or SD WebUI), "
                "with bounded dimensions and policy-scoped output directories."
            ),
            category=ToolCategory.ANALYSIS,
            risk_level=ToolRiskLevel.MEDIUM,
            requires_permission=False,
            timeout_seconds=120.0,
            capabilities=["image_generation", "text_to_image", "diagram_rendering"],
            tags=["image", "generation", "openai", "stable_diffusion"],
        )
        super().__init__(metadata, permission_manager)

        self._atomic_ops = get_atomic_file_ops()
        self._policy_lock = asyncio.Lock()
        self._policy_signature: Optional[Tuple[str, ...]] = None
        self._policy = self._build_policy()
        self._policy_signature = self._compute_policy_signature()
        self._metrics: Dict[str, Any] = {
            "total_requests": 0,
            "successful": 0,
            "failed": 0,
            "provider_counts": {},
            "last_generation_ts": None,
        }

    async def _execute(
        self,
        operation: str = "generate",
        prompt: Optional[str] = None,
        provider: Optional[str] = None,
        width: int = 1024,
        height: int = 1024,
        negative_prompt: Optional[str] = None,
        output_name: Optional[str] = None,
        image_format: Optional[str] = None,
        style: Optional[str] = None,
        quality: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        await self._refresh_policy_if_changed()
        self._metrics["total_requests"] += 1

        op = (operation or kwargs.get("action") or kwargs.get("op") or "").strip().lower()
        op = self.OPERATION_ALIASES.get(op, op)
        if op not in self.SUPPORTED_OPERATIONS:
            return {
                "success": False,
                "error": f"Unsupported operation '{op}'. Supported operations: {', '.join(self.SUPPORTED_OPERATIONS)}",
            }

        if op == "get_policy":
            return {"operation": op, "success": True, "policy": self._policy.as_dict()}

        if op == "get_metrics":
            return {"operation": op, "success": True, "metrics": dict(self._metrics)}

        prompt_text = str(prompt or kwargs.get("text") or kwargs.get("description") or "").strip()
        if not prompt_text:
            return {"operation": op, "success": False, "error": "Missing required parameter: prompt"}
        if len(prompt_text) > self._policy.max_prompt_chars:
            return {
                "operation": op,
                "success": False,
                "error": f"Prompt exceeds policy limit ({self._policy.max_prompt_chars} chars).",
            }

        resolved_provider = self._resolve_provider(provider)
        if not resolved_provider:
            return {
                "operation": op,
                "success": False,
                "error": "No image provider available. Configure OPENAI_API_KEY or Ironcliw_IMAGE_SD_WEBUI_URL.",
            }

        width_value = self._normalize_dimension(width)
        height_value = self._normalize_dimension(height)
        output_format = self._normalize_format(image_format or kwargs.get("format") or "png")
        output_path = self._build_output_path(output_name=output_name, image_format=output_format)

        try:
            if resolved_provider == "openai":
                generated = await self._generate_with_openai(
                    prompt=prompt_text,
                    width=width_value,
                    height=height_value,
                    quality=quality,
                    style=style,
                )
            elif resolved_provider == "sd_webui":
                generated = await self._generate_with_sd_webui(
                    prompt=prompt_text,
                    negative_prompt=negative_prompt or "",
                    width=width_value,
                    height=height_value,
                    steps=self._safe_int(kwargs.get("steps"), default=28, minimum=5, maximum=80),
                    cfg_scale=self._safe_float(kwargs.get("cfg_scale"), default=7.0, minimum=1.0, maximum=20.0),
                )
            else:
                return {
                    "operation": op,
                    "success": False,
                    "error": f"Unsupported provider: {resolved_provider}",
                }
        except Exception as exc:
            self._metrics["failed"] += 1
            return {
                "operation": op,
                "success": False,
                "provider": resolved_provider,
                "error": str(exc),
            }

        checksum = await self._atomic_ops.write_bytes(output_path, generated["bytes"], timeout=self._policy.timeout_seconds)
        self._metrics["successful"] += 1
        self._metrics["provider_counts"][resolved_provider] = self._metrics["provider_counts"].get(resolved_provider, 0) + 1
        self._metrics["last_generation_ts"] = time.time()

        return {
            "operation": op,
            "success": True,
            "provider": resolved_provider,
            "prompt": prompt_text,
            "path": str(output_path),
            "format": output_format,
            "width": width_value,
            "height": height_value,
            "bytes": len(generated["bytes"]),
            "checksum_sha256": checksum,
            "meta": generated.get("meta", {}),
        }

    async def _generate_with_openai(
        self,
        prompt: str,
        width: int,
        height: int,
        quality: Optional[str],
        style: Optional[str],
    ) -> Dict[str, Any]:
        api_key = os.getenv("OPENAI_API_KEY", "").strip()
        if not api_key:
            raise RuntimeError("OPENAI_API_KEY is not configured")

        try:
            from openai import AsyncOpenAI
        except Exception as exc:
            raise RuntimeError("openai package is not installed for OpenAI image generation") from exc

        client = AsyncOpenAI(api_key=api_key)
        request: Dict[str, Any] = {
            "model": self._policy.openai_model,
            "prompt": prompt,
            "size": f"{width}x{height}",
            "response_format": "b64_json",
            "n": 1,
        }
        if quality:
            request["quality"] = quality
        if style:
            request["style"] = style

        response = await asyncio.wait_for(client.images.generate(**request), timeout=self._policy.timeout_seconds)
        data_items = getattr(response, "data", None) or []
        if not data_items:
            raise RuntimeError("OpenAI images API returned no data")

        first = data_items[0]
        b64_payload = getattr(first, "b64_json", None)
        url_payload = getattr(first, "url", None)
        revised_prompt = getattr(first, "revised_prompt", None)

        if isinstance(first, dict):
            b64_payload = b64_payload or first.get("b64_json")
            url_payload = url_payload or first.get("url")
            revised_prompt = revised_prompt or first.get("revised_prompt")

        if b64_payload:
            try:
                image_bytes = base64.b64decode(b64_payload, validate=False)
            except (binascii.Error, ValueError) as exc:
                raise RuntimeError("OpenAI returned invalid base64 image payload") from exc
            return {"bytes": image_bytes, "meta": {"revised_prompt": revised_prompt}}

        if url_payload:
            image_bytes = await self._fetch_url_bytes(url_payload)
            return {"bytes": image_bytes, "meta": {"url": url_payload, "revised_prompt": revised_prompt}}

        raise RuntimeError("OpenAI images API response missing b64_json/url payload")

    async def _generate_with_sd_webui(
        self,
        prompt: str,
        negative_prompt: str,
        width: int,
        height: int,
        steps: int,
        cfg_scale: float,
    ) -> Dict[str, Any]:
        if not self._policy.sd_webui_url:
            raise RuntimeError("Ironcliw_IMAGE_SD_WEBUI_URL is not configured")

        try:
            import aiohttp
        except Exception as exc:
            raise RuntimeError("aiohttp is required for SD WebUI image generation") from exc

        payload = {
            "prompt": prompt,
            "negative_prompt": negative_prompt,
            "width": width,
            "height": height,
            "steps": steps,
            "cfg_scale": cfg_scale,
        }

        timeout = aiohttp.ClientTimeout(total=self._policy.timeout_seconds)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.post(self._policy.sd_webui_url, json=payload) as response:
                body = await response.text()
                if response.status >= 400:
                    raise RuntimeError(f"SD WebUI request failed ({response.status}): {body[:300]}")
                try:
                    data = json.loads(body)
                except json.JSONDecodeError as exc:
                    raise RuntimeError("SD WebUI returned non-JSON response") from exc

        images = data.get("images") if isinstance(data, dict) else None
        if not images:
            raise RuntimeError("SD WebUI response did not include image payload")

        image_payload = str(images[0]).strip()
        if image_payload.startswith("data:image/") and "," in image_payload:
            image_payload = image_payload.split(",", 1)[1]

        try:
            image_bytes = base64.b64decode(image_payload, validate=False)
        except (binascii.Error, ValueError) as exc:
            raise RuntimeError("SD WebUI returned invalid base64 payload") from exc

        return {"bytes": image_bytes, "meta": {"info": data.get("info"), "parameters": data.get("parameters")}}

    async def _fetch_url_bytes(self, url: str) -> bytes:
        try:
            import aiohttp
        except Exception as exc:
            raise RuntimeError("aiohttp is required to fetch image URLs") from exc

        timeout = aiohttp.ClientTimeout(total=self._policy.timeout_seconds)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(url) as response:
                if response.status >= 400:
                    body = await response.text()
                    raise RuntimeError(f"Image download failed ({response.status}): {body[:200]}")
                return await response.read()

    async def _refresh_policy_if_changed(self) -> None:
        signature = self._compute_policy_signature()
        if signature == self._policy_signature:
            return
        async with self._policy_lock:
            signature = self._compute_policy_signature()
            if signature == self._policy_signature:
                return
            self._policy = self._build_policy()
            self._policy_signature = signature

    def _build_policy(self) -> ImageGenerationPolicy:
        output_root_raw = os.getenv(
            self.OUTPUT_DIR_ENV,
            str(Path.home() / ".jarvis" / "generated_images"),
        ).strip()
        output_root = self._resolve_user_path(output_root_raw)

        provider = (os.getenv(self.PROVIDER_ENV, "auto").strip().lower() or "auto")
        if provider not in (*self.SUPPORTED_PROVIDERS, "auto"):
            provider = "auto"

        formats = self._parse_formats(os.getenv(self.FORMATS_ENV, "png,jpg,webp"))
        if not formats:
            formats = ("png",)

        return ImageGenerationPolicy(
            output_root=output_root,
            default_provider=provider,
            openai_model=os.getenv(self.OPENAI_MODEL_ENV, "gpt-image-1").strip() or "gpt-image-1",
            sd_webui_url=os.getenv(self.SD_WEBUI_URL_ENV, "").strip(),
            max_dimension=self._env_int(self.MAX_DIMENSION_ENV, 1536, minimum=256),
            max_prompt_chars=self._env_int(self.MAX_PROMPT_CHARS_ENV, 2000, minimum=64),
            timeout_seconds=self._env_float(self.TIMEOUT_ENV, 90.0, minimum=5.0),
            allowed_formats=formats,
        )

    def _compute_policy_signature(self) -> Tuple[str, ...]:
        return (
            os.getenv(self.OUTPUT_DIR_ENV, ""),
            os.getenv(self.PROVIDER_ENV, ""),
            os.getenv(self.OPENAI_MODEL_ENV, ""),
            os.getenv(self.SD_WEBUI_URL_ENV, ""),
            os.getenv(self.MAX_DIMENSION_ENV, ""),
            os.getenv(self.MAX_PROMPT_CHARS_ENV, ""),
            os.getenv(self.TIMEOUT_ENV, ""),
            os.getenv(self.FORMATS_ENV, ""),
            os.getenv("OPENAI_API_KEY", ""),
        )

    def _resolve_provider(self, provider: Optional[str]) -> Optional[str]:
        requested = str(provider or "").strip().lower()
        if requested and requested != "auto":
            if requested not in self.SUPPORTED_PROVIDERS:
                return None
            if requested == "openai" and not self._openai_available():
                return None
            if requested == "sd_webui" and not self._sd_webui_available():
                return None
            return requested

        default_provider = self._policy.default_provider
        if default_provider == "openai" and self._openai_available():
            return "openai"
        if default_provider == "sd_webui" and self._sd_webui_available():
            return "sd_webui"

        if self._openai_available():
            return "openai"
        if self._sd_webui_available():
            return "sd_webui"
        return None

    def _openai_available(self) -> bool:
        return bool(os.getenv("OPENAI_API_KEY", "").strip())

    def _sd_webui_available(self) -> bool:
        return bool(self._policy.sd_webui_url)

    def _normalize_dimension(self, value: Any) -> int:
        try:
            parsed = int(value)
        except (TypeError, ValueError):
            parsed = 1024
        bounded = max(256, min(parsed, self._policy.max_dimension))
        # Keep dimensions model-friendly.
        return (bounded // 64) * 64

    def _normalize_format(self, image_format: str) -> str:
        fmt = str(image_format or "").strip().lower().replace(".", "")
        if fmt == "jpeg":
            fmt = "jpg"
        if fmt not in self._policy.allowed_formats:
            return self._policy.allowed_formats[0]
        return fmt

    def _build_output_path(self, output_name: Optional[str], image_format: str) -> Path:
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        safe_name = self._sanitize_output_name(output_name or f"jarvis_image_{timestamp}")
        if not safe_name.endswith(f".{image_format}"):
            safe_name = f"{safe_name}.{image_format}"

        output_root = self._policy.output_root
        output_path = (output_root / safe_name).resolve()

        try:
            output_path.relative_to(output_root.resolve())
        except ValueError as exc:
            raise PermissionError(f"Output path escapes allowed image directory: {output_path}") from exc

        return output_path

    @staticmethod
    def _sanitize_output_name(raw_name: str) -> str:
        name = re.sub(r"[^a-zA-Z0-9._-]+", "_", str(raw_name).strip())
        name = name.strip("._")
        return name or f"jarvis_image_{uuid4().hex[:10]}"

    @staticmethod
    def _parse_formats(raw: str) -> Tuple[str, ...]:
        formats = []
        for token in re.split(r"[,;\s]+", raw or ""):
            fmt = token.strip().lower().replace(".", "")
            if fmt == "jpeg":
                fmt = "jpg"
            if fmt in {"png", "jpg", "webp"} and fmt not in formats:
                formats.append(fmt)
        return tuple(formats)

    @staticmethod
    def _resolve_user_path(raw_path: str) -> Path:
        candidate = Path(raw_path).expanduser()
        if not candidate.is_absolute():
            candidate = Path.cwd() / candidate

        missing_parts: List[str] = []
        probe = candidate
        while not probe.exists():
            missing_parts.append(probe.name)
            parent = probe.parent
            if parent == probe:
                break
            probe = parent

        resolved_base = probe.resolve()
        for part in reversed(missing_parts):
            resolved_base = resolved_base / part
        return resolved_base

    @staticmethod
    def _safe_int(value: Any, default: int, minimum: int, maximum: int) -> int:
        try:
            parsed = int(value)
        except (TypeError, ValueError):
            parsed = default
        return max(minimum, min(parsed, maximum))

    @staticmethod
    def _safe_float(value: Any, default: float, minimum: float, maximum: float) -> float:
        try:
            parsed = float(value)
        except (TypeError, ValueError):
            parsed = default
        return max(minimum, min(parsed, maximum))

    @staticmethod
    def _env_int(env_key: str, default: int, minimum: int = 0) -> int:
        raw = os.getenv(env_key, "").strip()
        if not raw:
            return default
        try:
            return max(int(raw), minimum)
        except ValueError:
            return default

    @staticmethod
    def _env_float(env_key: str, default: float, minimum: float = 0.0) -> float:
        raw = os.getenv(env_key, "").strip()
        if not raw:
            return default
        try:
            return max(float(raw), minimum)
        except ValueError:
            return default


@dataclass(frozen=True)
class FileSystemAccessPolicy:
    """Resolved filesystem access policy for the file-system tool."""

    read_roots: Tuple[Path, ...]
    write_roots: Tuple[Path, ...]
    deny_roots: Tuple[Path, ...]

    def as_dict(self) -> Dict[str, List[str]]:
        return {
            "read_roots": [str(path) for path in self.read_roots],
            "write_roots": [str(path) for path in self.write_roots],
            "deny_roots": [str(path) for path in self.deny_roots],
        }


class FileSystemAgentTool(IroncliwTool):
    """Secure, policy-driven file system operations with allowlist enforcement."""

    READ_ALLOWLIST_ENV = "Ironcliw_FS_READ_ALLOWLIST"
    WRITE_ALLOWLIST_ENV = "Ironcliw_FS_WRITE_ALLOWLIST"
    DENYLIST_ENV = "Ironcliw_FS_DENYLIST"
    REPO_ROOTS_ENV = "Ironcliw_REPO_ROOTS"
    MAX_READ_BYTES_ENV = "Ironcliw_FS_MAX_READ_BYTES"
    MAX_LIST_RESULTS_ENV = "Ironcliw_FS_MAX_LIST_RESULTS"
    ALLOW_ROOT_PATHS_ENV = "Ironcliw_FS_ALLOW_ROOT_PATHS"

    REPO_ENV_KEYS: Tuple[str, ...] = (
        "Ironcliw_PATH",
        "Ironcliw_REPO_PATH",
        "Ironcliw_CORE_PATH",
        "Ironcliw_PRIME_PATH",
        "Ironcliw_PRIME_REPO_PATH",
        "REACTOR_CORE_PATH",
        "Ironcliw_REACTOR_PATH",
    )

    SUPPORTED_OPERATIONS: Tuple[str, ...] = (
        "read_text",
        "read_json",
        "write_text",
        "write_json",
        "list_files",
        "stat",
        "exists",
        "mkdir",
        "delete_file",
        "delete_dir",
        "copy_file",
        "move_file",
        "get_policy",
        "get_metrics",
    )

    OPERATION_ALIASES: Dict[str, str] = {
        "read_file": "read_text",
        "write_file": "write_text",
        "list": "list_files",
        "ls": "list_files",
        "policy": "get_policy",
        "metrics": "get_metrics",
        "copy": "copy_file",
        "move": "move_file",
        "remove_file": "delete_file",
        "remove_dir": "delete_dir",
    }

    def __init__(self, permission_manager: Optional[Any] = None):
        metadata = ToolMetadata(
            name="filesystem_agent",
            description=(
                "Secure file system operations with scoped read/write permissions, "
                "atomic writes, and policy-driven path controls"
            ),
            category=ToolCategory.FILE_SYSTEM,
            risk_level=ToolRiskLevel.MEDIUM,
            requires_permission=False,
            timeout_seconds=60.0,
            capabilities=[
                "file_read",
                "file_write",
                "file_delete",
                "file_listing",
                "filesystem_metadata",
                "secure_filesystem",
            ],
            tags=["filesystem", "allowlist", "atomic", "secure"],
        )
        super().__init__(metadata, permission_manager)
        self._atomic_ops = get_atomic_file_ops()
        self._policy_lock = asyncio.Lock()
        self._policy_signature: Optional[Tuple[str, ...]] = None
        self._policy = self._build_policy()
        self._policy_signature = self._compute_policy_signature()
        self._max_read_bytes = self._env_int(self.MAX_READ_BYTES_ENV, 1_000_000, minimum=1_024)
        self._max_list_results = self._env_int(self.MAX_LIST_RESULTS_ENV, 1_000, minimum=1)

    async def _execute(
        self,
        operation: str = "",
        path: Optional[str] = None,
        source: Optional[str] = None,
        destination: Optional[str] = None,
        content: Optional[Any] = None,
        data: Optional[Any] = None,
        pattern: str = "*",
        recursive: bool = False,
        encoding: str = "utf-8",
        max_results: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """Execute a secure file operation."""
        await self._refresh_policy_if_changed()

        op = (operation or kwargs.get("action") or kwargs.get("op") or "").strip().lower()
        op = self.OPERATION_ALIASES.get(op, op)
        if not op:
            raise ValueError("Missing required parameter: operation")
        if op not in self.SUPPORTED_OPERATIONS:
            raise ValueError(
                f"Unsupported operation '{op}'. Supported operations: {', '.join(self.SUPPORTED_OPERATIONS)}"
            )

        resolved_path = path or kwargs.get("file_path")
        source_path = source or kwargs.get("source_path")
        destination_path = destination or kwargs.get("destination_path")

        if op == "read_text":
            target = self._resolve_and_validate(resolved_path, access="read")
            raw = await self._atomic_ops.read_bytes(target)
            self._enforce_read_limit(raw, target)
            return {
                "operation": op,
                "path": str(target),
                "content": raw.decode(encoding),
                "bytes_read": len(raw),
            }

        if op == "read_json":
            target = self._resolve_and_validate(resolved_path, access="read")
            raw = await self._atomic_ops.read_bytes(target)
            self._enforce_read_limit(raw, target)
            try:
                parsed = json.loads(raw.decode(encoding))
            except json.JSONDecodeError as exc:
                raise ValueError(f"File is not valid JSON: {target}") from exc
            return {
                "operation": op,
                "path": str(target),
                "data": parsed,
                "bytes_read": len(raw),
            }

        if op == "write_text":
            target = self._resolve_and_validate(resolved_path, access="write")
            text_content = self._resolve_text_payload(content=content, data=data, kwargs=kwargs)
            create_parents = self._to_bool(kwargs.get("create_parents"), default=True)
            if create_parents:
                await self._ensure_directory(target.parent)
            checksum = await self._atomic_ops.write_text(target, text_content, encoding=encoding)
            return {
                "operation": op,
                "path": str(target),
                "checksum": checksum,
                "bytes_written": len(text_content.encode(encoding)),
            }

        if op == "write_json":
            target = self._resolve_and_validate(resolved_path, access="write")
            payload = self._resolve_json_payload(content=content, data=data, kwargs=kwargs)
            create_parents = self._to_bool(kwargs.get("create_parents"), default=True)
            if create_parents:
                await self._ensure_directory(target.parent)
            indent = self._coerce_int(kwargs.get("indent"), default=2, minimum=0)
            checksum = await self._atomic_ops.write_json(target, payload, indent=indent)
            return {
                "operation": op,
                "path": str(target),
                "checksum": checksum,
            }

        if op == "list_files":
            target = self._resolve_and_validate(resolved_path or ".", access="read")
            recursive_flag = self._to_bool(kwargs.get("recursive", recursive), default=recursive)
            listed = await self._atomic_ops.list_files(
                directory=target,
                pattern=pattern or kwargs.get("glob", "*"),
                recursive=recursive_flag,
            )
            limit = self._coerce_int(
                max_results if max_results is not None else kwargs.get("max_results"),
                default=self._max_list_results,
                minimum=1,
            )
            normalized_files = sorted(str(path) for path in listed)[:limit]
            return {
                "operation": op,
                "directory": str(target),
                "pattern": pattern or kwargs.get("glob", "*"),
                "recursive": recursive_flag,
                "count": len(normalized_files),
                "files": normalized_files,
            }

        if op == "stat":
            target = self._resolve_and_validate(resolved_path, access="read")
            exists = await asyncio.to_thread(target.exists)
            if not exists:
                return {"operation": op, "path": str(target), "exists": False}
            stat_result = await asyncio.to_thread(target.stat)
            return {
                "operation": op,
                "path": str(target),
                "exists": True,
                "is_file": await asyncio.to_thread(target.is_file),
                "is_dir": await asyncio.to_thread(target.is_dir),
                "size_bytes": stat_result.st_size,
                "modified_ts": stat_result.st_mtime,
                "created_ts": stat_result.st_ctime,
                "mode": stat_result.st_mode,
            }

        if op == "exists":
            target = self._resolve_and_validate(resolved_path, access="read")
            return {
                "operation": op,
                "path": str(target),
                "exists": await asyncio.to_thread(target.exists),
            }

        if op == "mkdir":
            target = self._resolve_and_validate(resolved_path, access="write")
            parents = self._to_bool(kwargs.get("parents"), default=True)
            exist_ok = self._to_bool(kwargs.get("exist_ok"), default=True)
            await asyncio.to_thread(target.mkdir, parents=parents, exist_ok=exist_ok)
            return {"operation": op, "path": str(target), "created": True}

        if op == "delete_file":
            target = self._resolve_and_validate(resolved_path, access="write")
            missing_ok = self._to_bool(kwargs.get("missing_ok"), default=True)
            deleted = await self._atomic_ops.delete(target, missing_ok=missing_ok)
            return {"operation": op, "path": str(target), "deleted": deleted}

        if op == "delete_dir":
            target = self._resolve_and_validate(resolved_path, access="write")
            recursive_flag = self._to_bool(kwargs.get("recursive", recursive), default=False)
            missing_ok = self._to_bool(kwargs.get("missing_ok"), default=True)
            deleted = await self._atomic_ops.delete_dir(
                target,
                recursive=recursive_flag,
                missing_ok=missing_ok,
            )
            return {
                "operation": op,
                "path": str(target),
                "deleted": deleted,
                "recursive": recursive_flag,
            }

        if op == "copy_file":
            src = self._resolve_and_validate(source_path or resolved_path, access="read")
            dest = self._resolve_and_validate(destination_path, access="write")
            overwrite = self._to_bool(kwargs.get("overwrite"), default=True)
            create_parents = self._to_bool(kwargs.get("create_parents"), default=True)
            await self._ensure_file_exists(src)
            if create_parents:
                await self._ensure_directory(dest.parent)
            if not overwrite and await asyncio.to_thread(dest.exists):
                raise FileExistsError(f"Destination already exists: {dest}")
            data_bytes = await self._atomic_ops.read_bytes(src)
            checksum = await self._atomic_ops.write_bytes(dest, data_bytes)
            return {
                "operation": op,
                "source": str(src),
                "destination": str(dest),
                "checksum": checksum,
                "bytes_copied": len(data_bytes),
            }

        if op == "move_file":
            src = self._resolve_and_validate(source_path or resolved_path, access="write")
            dest = self._resolve_and_validate(destination_path, access="write")
            self._assert_access(src, "read")
            overwrite = self._to_bool(kwargs.get("overwrite"), default=True)
            create_parents = self._to_bool(kwargs.get("create_parents"), default=True)
            await self._ensure_file_exists(src)
            if create_parents:
                await self._ensure_directory(dest.parent)
            if src == dest:
                return {
                    "operation": op,
                    "source": str(src),
                    "destination": str(dest),
                    "moved": True,
                    "note": "source and destination are identical",
                }
            if not overwrite and await asyncio.to_thread(dest.exists):
                raise FileExistsError(f"Destination already exists: {dest}")

            moved_via_copy = False
            try:
                await asyncio.to_thread(os.replace, src, dest)
            except OSError as exc:
                if exc.errno != errno.EXDEV:
                    raise
                moved_via_copy = True
                data_bytes = await self._atomic_ops.read_bytes(src)
                await self._atomic_ops.write_bytes(dest, data_bytes)
                await self._atomic_ops.delete(src, missing_ok=False)

            return {
                "operation": op,
                "source": str(src),
                "destination": str(dest),
                "moved": True,
                "used_cross_device_fallback": moved_via_copy,
            }

        if op == "get_policy":
            return {
                "operation": op,
                "policy": self._policy.as_dict(),
                "max_read_bytes": self._max_read_bytes,
                "max_list_results": self._max_list_results,
            }

        if op == "get_metrics":
            return {"operation": op, "metrics": self._atomic_ops.get_metrics()}

        # Should not be reachable due supported operation check
        raise RuntimeError(f"Unhandled operation: {op}")

    def _resolve_and_validate(self, raw_path: Optional[str], access: str) -> Path:
        if not raw_path:
            raise ValueError("Missing required parameter: path")
        resolved = self._resolve_user_path(raw_path)
        self._assert_access(resolved, access)
        return resolved

    async def _refresh_policy_if_changed(self) -> None:
        signature = self._compute_policy_signature()
        if signature == self._policy_signature:
            return
        async with self._policy_lock:
            signature = self._compute_policy_signature()
            if signature == self._policy_signature:
                return
            self._policy = self._build_policy()
            self._policy_signature = signature

    def _build_policy(self) -> FileSystemAccessPolicy:
        read_roots = self._canonicalize_paths(self._parse_env_paths(self.READ_ALLOWLIST_ENV))
        write_roots = self._canonicalize_paths(self._parse_env_paths(self.WRITE_ALLOWLIST_ENV))
        deny_roots = self._canonicalize_paths(self._parse_env_paths(self.DENYLIST_ENV))

        if not read_roots:
            read_roots = self._default_read_roots()
        if not write_roots:
            write_roots = self._default_write_roots(read_roots)

        if not read_roots:
            cwd_root = self._resolve_user_path(str(Path.cwd()))
            read_roots = (cwd_root,)
        if not write_roots:
            write_roots = tuple(path for path in read_roots if self._is_relative(path, Path.cwd()))
            if not write_roots:
                write_roots = (self._resolve_user_path(str(Path.cwd())),)

        return FileSystemAccessPolicy(
            read_roots=read_roots,
            write_roots=write_roots,
            deny_roots=deny_roots,
        )

    def _default_read_roots(self) -> Tuple[Path, ...]:
        roots: List[Path] = []
        roots.extend(self._parse_env_paths(self.REPO_ROOTS_ENV))
        for key in self.REPO_ENV_KEYS:
            value = os.getenv(key, "").strip()
            if value:
                roots.append(Path(value))
        roots.append(Path(__file__).resolve().parents[2])
        roots.append(Path.home() / ".jarvis")
        return self._canonicalize_paths(roots)

    def _default_write_roots(self, read_roots: Tuple[Path, ...]) -> Tuple[Path, ...]:
        write_roots: List[Path] = [Path.home() / ".jarvis"]
        for root in read_roots:
            if any(self._is_relative(root, candidate) for candidate in write_roots):
                continue
            write_roots.append(root)
        return self._canonicalize_paths(write_roots)

    def _parse_env_paths(self, env_key: str) -> List[Path]:
        raw = os.getenv(env_key, "").strip()
        if not raw:
            return []

        values: List[str] = []
        if raw.startswith("["):
            try:
                parsed = json.loads(raw)
                if isinstance(parsed, list):
                    values = [str(item).strip() for item in parsed if str(item).strip()]
            except Exception:
                values = []
        if not values:
            values = [item.strip() for item in re.split(r"[,;\n]+", raw) if item.strip()]

        return [Path(value).expanduser() for value in values]

    def _canonicalize_paths(self, paths: Sequence[Path]) -> Tuple[Path, ...]:
        allow_root_paths = self._to_bool(os.getenv(self.ALLOW_ROOT_PATHS_ENV), default=False)
        normalized: List[Path] = []
        for path in paths:
            try:
                resolved = self._resolve_user_path(str(path))
                if not allow_root_paths and resolved == Path(resolved.anchor):
                    self.logger.warning("Skipping filesystem allowlist root path for safety: %s", resolved)
                    continue
                normalized.append(resolved)
            except Exception:
                continue

        unique: List[Path] = []
        for path in sorted(set(normalized), key=lambda candidate: len(candidate.parts)):
            if any(self._is_relative(path, existing) for existing in unique):
                continue
            unique.append(path)

        return tuple(unique)

    def _compute_policy_signature(self) -> Tuple[str, ...]:
        values = [
            os.getenv(self.READ_ALLOWLIST_ENV, ""),
            os.getenv(self.WRITE_ALLOWLIST_ENV, ""),
            os.getenv(self.DENYLIST_ENV, ""),
            os.getenv(self.REPO_ROOTS_ENV, ""),
        ]
        values.extend(os.getenv(key, "") for key in self.REPO_ENV_KEYS)
        return tuple(values)

    @staticmethod
    def _resolve_user_path(raw_path: str) -> Path:
        candidate = Path(raw_path).expanduser()
        if not candidate.is_absolute():
            candidate = Path.cwd() / candidate

        missing_parts: List[str] = []
        probe = candidate
        while not probe.exists():
            missing_parts.append(probe.name)
            parent = probe.parent
            if parent == probe:
                break
            probe = parent

        resolved_base = probe.resolve()
        for part in reversed(missing_parts):
            resolved_base = resolved_base / part
        return resolved_base

    def _assert_access(self, path: Path, access: str) -> None:
        normalized = self._resolve_user_path(str(path))

        if any(self._is_relative(normalized, denied) for denied in self._policy.deny_roots):
            raise PermissionError(f"Path is explicitly denied by filesystem policy: {normalized}")

        allowed_roots = self._policy.read_roots if access == "read" else self._policy.write_roots
        if not any(self._is_relative(normalized, root) for root in allowed_roots):
            raise PermissionError(f"{access} access denied by filesystem policy: {normalized}")

    @staticmethod
    def _is_relative(path: Path, root: Path) -> bool:
        try:
            path.relative_to(root)
            return True
        except ValueError:
            return False

    async def _ensure_directory(self, directory: Path) -> None:
        self._assert_access(directory, "write")
        await asyncio.to_thread(directory.mkdir, parents=True, exist_ok=True)

    async def _ensure_file_exists(self, path: Path) -> None:
        exists = await asyncio.to_thread(path.exists)
        if not exists:
            raise FileNotFoundError(f"Path does not exist: {path}")
        is_file = await asyncio.to_thread(path.is_file)
        if not is_file:
            raise IsADirectoryError(f"Expected a file path, got: {path}")

    def _enforce_read_limit(self, payload: bytes, path: Path) -> None:
        if len(payload) > self._max_read_bytes:
            raise ValueError(
                f"Read aborted: {path} is {len(payload)} bytes, exceeding "
                f"limit of {self._max_read_bytes} bytes"
            )

    def _resolve_text_payload(self, content: Any, data: Any, kwargs: Dict[str, Any]) -> str:
        candidate = content if content is not None else data
        if candidate is None:
            candidate = kwargs.get("text")
        if candidate is None:
            raise ValueError("Missing text payload. Provide 'content', 'data', or 'text'.")
        if isinstance(candidate, bytes):
            return candidate.decode("utf-8")
        if isinstance(candidate, str):
            return candidate
        return json.dumps(candidate, default=str, indent=2)

    def _resolve_json_payload(self, content: Any, data: Any, kwargs: Dict[str, Any]) -> Any:
        candidate = data if data is not None else kwargs.get("json_data")
        if candidate is None:
            candidate = content
        if candidate is None:
            raise ValueError("Missing JSON payload. Provide 'data', 'json_data', or 'content'.")
        if isinstance(candidate, str):
            try:
                return json.loads(candidate)
            except json.JSONDecodeError as exc:
                raise ValueError("String payload is not valid JSON") from exc
        return candidate

    @staticmethod
    def _to_bool(value: Any, default: bool) -> bool:
        if value is None:
            return default
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            lowered = value.strip().lower()
            if lowered in {"1", "true", "yes", "y", "on"}:
                return True
            if lowered in {"0", "false", "no", "n", "off"}:
                return False
        return bool(value)

    @staticmethod
    def _coerce_int(value: Any, default: int, minimum: int = 0) -> int:
        if value is None:
            return default
        try:
            coerced = int(value)
            return max(coerced, minimum)
        except (TypeError, ValueError):
            return default

    @classmethod
    def _env_int(cls, env_key: str, default: int, minimum: int = 0) -> int:
        raw = os.getenv(env_key, "").strip()
        if not raw:
            return default
        try:
            value = int(raw)
            return max(value, minimum)
        except ValueError:
            return default


class SystemInfoTool(IroncliwTool):
    """Tool for getting system information."""

    def __init__(self, permission_manager: Optional[Any] = None):
        metadata = ToolMetadata(
            name="system_info",
            description="Get current system information including CPU, memory, and disk usage",
            category=ToolCategory.SYSTEM,
            risk_level=ToolRiskLevel.SAFE,
            requires_permission=False,
            capabilities=["system_monitoring", "resource_info"]
        )
        super().__init__(metadata, permission_manager)

    async def _execute(self, **kwargs) -> Dict[str, Any]:
        """Get system information."""
        import platform
        import os

        return {
            "platform": platform.system(),
            "platform_release": platform.release(),
            "platform_version": platform.version(),
            "architecture": platform.machine(),
            "processor": platform.processor(),
            "python_version": platform.python_version(),
            "cpu_count": os.cpu_count(),
            "pid": os.getpid()
        }


class CalculatorTool(IroncliwTool):
    """Tool for mathematical calculations."""

    def __init__(self, permission_manager: Optional[Any] = None):
        metadata = ToolMetadata(
            name="calculator",
            description="Perform mathematical calculations safely",
            category=ToolCategory.UTILITY,
            risk_level=ToolRiskLevel.SAFE,
            requires_permission=False,
            capabilities=["math", "calculation"]
        )
        super().__init__(metadata, permission_manager)

    async def _execute(self, expression: str, **kwargs) -> Dict[str, Any]:
        """
        Evaluate a mathematical expression safely.

        Args:
            expression: Mathematical expression to evaluate

        Returns:
            Result of the calculation
        """
        import ast
        import operator

        # Safe operators
        operators = {
            ast.Add: operator.add,
            ast.Sub: operator.sub,
            ast.Mult: operator.mul,
            ast.Div: operator.truediv,
            ast.FloorDiv: operator.floordiv,
            ast.Mod: operator.mod,
            ast.Pow: operator.pow,
            ast.USub: operator.neg,
            ast.UAdd: operator.pos
        }

        def eval_node(node):
            if isinstance(node, ast.Constant):
                return node.value
            elif isinstance(node, ast.BinOp):
                left = eval_node(node.left)
                right = eval_node(node.right)
                return operators[type(node.op)](left, right)
            elif isinstance(node, ast.UnaryOp):
                operand = eval_node(node.operand)
                return operators[type(node.op)](operand)
            else:
                raise ValueError(f"Unsupported operation: {type(node)}")

        try:
            tree = ast.parse(expression, mode='eval')
            result = eval_node(tree.body)
            return {
                "expression": expression,
                "result": result,
                "success": True
            }
        except Exception as e:
            return {
                "expression": expression,
                "result": None,
                "success": False,
                "error": str(e)
            }


class DateTimeTool(IroncliwTool):
    """Tool for date and time operations."""

    def __init__(self, permission_manager: Optional[Any] = None):
        metadata = ToolMetadata(
            name="datetime",
            description="Get current date/time or perform date calculations",
            category=ToolCategory.UTILITY,
            risk_level=ToolRiskLevel.SAFE,
            requires_permission=False,
            capabilities=["datetime", "timezone"]
        )
        super().__init__(metadata, permission_manager)

    async def _execute(
        self,
        operation: str = "now",
        timezone: Optional[str] = None,
        format: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Perform date/time operations.

        Args:
            operation: Operation to perform ('now', 'date', 'time', 'timestamp')
            timezone: Timezone name (optional)
            format: Output format string (optional)
        """
        from datetime import datetime, timezone as tz

        now = datetime.now(tz.utc)

        if operation == "now":
            result = now.isoformat()
        elif operation == "date":
            result = now.date().isoformat()
        elif operation == "time":
            result = now.time().isoformat()
        elif operation == "timestamp":
            result = now.timestamp()
        else:
            result = now.isoformat()

        if format:
            try:
                result = now.strftime(format)
            except ValueError:
                pass

        return {
            "operation": operation,
            "result": result,
            "timezone": "UTC",
            "timestamp": now.timestamp()
        }


# ============================================================================
# Tool Factory
# ============================================================================

class ToolFactory:
    """Factory for creating tools dynamically."""

    @staticmethod
    def create_from_action_handler(
        handler: Callable,
        action_type: str,
        permission_manager: Optional[Any] = None
    ) -> IroncliwTool:
        """
        Create a tool from an existing Ironcliw action handler.

        Args:
            handler: Action handler function
            action_type: Type of action
            permission_manager: Permission manager instance

        Returns:
            Created tool
        """
        # Infer category from action type
        category_mapping = {
            "handle_notifications": ToolCategory.COMMUNICATION,
            "prepare_meeting": ToolCategory.AUTOMATION,
            "organize_workspace": ToolCategory.UI,
            "security_alert": ToolCategory.SECURITY,
            "respond_message": ToolCategory.COMMUNICATION,
            "cleanup_workspace": ToolCategory.FILE_SYSTEM,
            "minimize_distractions": ToolCategory.UI,
            "routine_automation": ToolCategory.AUTOMATION,
            "handle_urgent_item": ToolCategory.AUTOMATION
        }

        category = category_mapping.get(action_type, ToolCategory.UTILITY)

        # Infer risk level
        risk_mapping = {
            "security_alert": ToolRiskLevel.HIGH,
            "cleanup_workspace": ToolRiskLevel.MEDIUM,
            "organize_workspace": ToolRiskLevel.LOW,
            "handle_notifications": ToolRiskLevel.SAFE
        }

        risk_level = risk_mapping.get(action_type, ToolRiskLevel.LOW)

        metadata = ToolMetadata(
            name=f"action_{action_type}",
            description=f"Execute {action_type} action",
            category=category,
            risk_level=risk_level,
            requires_permission=True,
            capabilities=[action_type, "action_execution"]
        )

        return FunctionTool(
            func=handler,
            metadata=metadata,
            permission_manager=permission_manager
        )

    @staticmethod
    def create_from_config(
        config: Dict[str, Any],
        permission_manager: Optional[Any] = None
    ) -> Optional[IroncliwTool]:
        """
        Create a tool from configuration dictionary.

        Args:
            config: Tool configuration
            permission_manager: Permission manager instance

        Returns:
            Created tool or None
        """
        try:
            # Load function from module
            module_path = config.get("module")
            function_name = config.get("function")

            if not module_path or not function_name:
                return None

            module = importlib.import_module(module_path)
            func = getattr(module, function_name)

            metadata = ToolMetadata(
                name=config.get("name", function_name),
                description=config.get("description", ""),
                category=ToolCategory(config.get("category", "utility")),
                risk_level=ToolRiskLevel(config.get("risk_level", "low")),
                requires_permission=config.get("requires_permission", True),
                timeout_seconds=config.get("timeout", 30.0),
                retry_count=config.get("retry_count", 3),
                capabilities=config.get("capabilities", []),
                tags=config.get("tags", [])
            )

            return FunctionTool(
                func=func,
                metadata=metadata,
                permission_manager=permission_manager
            )

        except Exception as e:
            logger.error(f"Failed to create tool from config: {e}")
            return None


# ============================================================================
# Auto-Registration
# ============================================================================

def register_builtin_tools(
    registry: Optional[ToolRegistry] = None,
    permission_manager: Optional[Any] = None,
) -> int:
    """
    Register built-in tools.

    Args:
        registry: Tool registry (uses singleton if not provided)
        permission_manager: Permission manager passed to built-in tools

    Returns:
        Number of tools registered
    """
    if registry is None:
        registry = ToolRegistry.get_instance()

    builtin_tools = [
        SystemInfoTool(),
        CalculatorTool(),
        DateTimeTool(),
        WebResearchTool(),
        MediaControlTool(permission_manager=permission_manager),
        ImageGenerationTool(permission_manager=permission_manager),
        ShellCommandTool(permission_manager=permission_manager),
        FileSystemAgentTool(permission_manager=permission_manager),
    ]

    for tool in builtin_tools:
        registry.register(tool, replace=True)

    return len(builtin_tools)


def auto_discover_tools(
    base_paths: Optional[List[str]] = None,
    registry: Optional[ToolRegistry] = None
) -> int:
    """
    Auto-discover and register tools from the codebase.

    Args:
        base_paths: Paths to search (defaults to Ironcliw tool paths)
        registry: Tool registry (uses singleton if not provided)

    Returns:
        Total tools discovered
    """
    if registry is None:
        registry = ToolRegistry.get_instance()

    if base_paths is None:
        # Default Ironcliw tool paths
        base_dir = Path(__file__).parent.parent
        base_paths = [
            str(base_dir / "tools"),
            str(base_dir / "api" / "action_executors.py")
        ]

    total = 0

    for path_str in base_paths:
        path = Path(path_str)

        if path.is_file() and path.suffix == '.py':
            # Single file - derive module path
            parts = path.with_suffix('').parts
            # Find backend index
            try:
                backend_idx = parts.index('backend')
                module_path = '.'.join(parts[backend_idx:])
                total += registry.discover_from_module(module_path)
            except ValueError:
                pass

        elif path.is_dir():
            total += registry.discover_from_directory(path)

    return total


# ============================================================================
# Convenience Functions
# ============================================================================

def get_tool(name: str) -> Optional[IroncliwTool]:
    """Get a tool by name from the global registry."""
    return ToolRegistry.get_instance().get(name)


def list_tools() -> List[str]:
    """List all registered tool names."""
    return [t.name for t in ToolRegistry.get_instance().get_all()]


def search_tools(query: str, **kwargs) -> List[IroncliwTool]:
    """Search for tools matching a query."""
    return ToolRegistry.get_instance().search(query, **kwargs)


async def execute_tool(name: str, **kwargs) -> Any:
    """Execute a tool by name."""
    tool = get_tool(name)
    if tool is None:
        raise ValueError(f"Tool not found: {name}")
    return await tool.run(**kwargs)
