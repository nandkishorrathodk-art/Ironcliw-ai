"""
Collaboration Engine - Multi-User Conflict Resolution
======================================================

Production-grade collaboration system with:
- CRDT-based conflict-free merging (Operational Transformation alternative)
- Real-time collaborative editing with vector clocks
- Three-way merge with semantic understanding
- Concurrent edit detection and resolution
- Session management across distributed nodes

Architecture:
    ┌─────────────────────────────────────────────────────────────────────────┐
    │                    Collaboration Engine v1.0                             │
    ├─────────────────────────────────────────────────────────────────────────┤
    │                                                                          │
    │   ┌─────────────┐     ┌─────────────┐     ┌─────────────┐               │
    │   │   User A    │     │  Conflict   │     │   User B    │               │
    │   │   Editor    │────▶│  Resolver   │◀────│   Editor    │               │
    │   └─────────────┘     └─────────────┘     └─────────────┘               │
    │          │                   │                   │                      │
    │          └───────────────────┴───────────────────┘                      │
    │                              │                                          │
    │                    ┌─────────▼─────────┐                                │
    │                    │   CRDT Engine     │                                │
    │                    │                   │                                │
    │                    │ • Vector Clocks   │                                │
    │                    │ • Causal Ordering │                                │
    │                    │ • Merge Strategy  │                                │
    │                    └───────────────────┘                                │
    │                                                                          │
    └─────────────────────────────────────────────────────────────────────────┘

Author: Ironcliw Intelligence System
Version: 1.0.0
"""

from __future__ import annotations

import asyncio
import hashlib
import json
import logging
import os
import time
import uuid
from abc import ABC, abstractmethod
from collections import defaultdict
from dataclasses import dataclass, field
from enum import Enum, auto
from pathlib import Path
from typing import (
    Any,
    Callable,
    Dict,
    FrozenSet,
    Generic,
    List,
    Optional,
    Set,
    Tuple,
    TypeVar,
    Union,
)

logger = logging.getLogger("Ironcliw.Collaboration")


# =============================================================================
# CONFIGURATION
# =============================================================================

@dataclass(frozen=True)
class CollaborationConfig:
    """Environment-driven collaboration configuration."""

    # Session settings
    session_timeout: int = int(os.getenv("COLLAB_SESSION_TIMEOUT", "3600"))
    heartbeat_interval: float = float(os.getenv("COLLAB_HEARTBEAT_INTERVAL", "5.0"))
    max_users_per_file: int = int(os.getenv("COLLAB_MAX_USERS_PER_FILE", "50"))

    # Conflict resolution
    merge_strategy: str = os.getenv("COLLAB_MERGE_STRATEGY", "semantic")  # semantic, line, character
    conflict_timeout: float = float(os.getenv("COLLAB_CONFLICT_TIMEOUT", "30.0"))
    auto_resolve_threshold: float = float(os.getenv("COLLAB_AUTO_RESOLVE_THRESHOLD", "0.8"))

    # CRDT settings
    crdt_gc_interval: int = int(os.getenv("COLLAB_CRDT_GC_INTERVAL", "300"))
    vector_clock_prune_age: int = int(os.getenv("COLLAB_VCLOCK_PRUNE_AGE", "86400"))

    # Persistence
    state_dir: Path = Path(os.getenv("COLLAB_STATE_DIR", Path.home() / ".jarvis/collaboration"))
    enable_persistence: bool = os.getenv("COLLAB_ENABLE_PERSISTENCE", "true").lower() == "true"

    # Cross-repo
    enable_cross_repo: bool = os.getenv("COLLAB_CROSS_REPO_ENABLED", "true").lower() == "true"

    @classmethod
    def from_env(cls) -> "CollaborationConfig":
        """Create configuration from environment."""
        return cls()


# =============================================================================
# ENUMS
# =============================================================================

class OperationType(Enum):
    """Types of collaborative operations."""
    INSERT = "insert"
    DELETE = "delete"
    REPLACE = "replace"
    MOVE = "move"
    RETAIN = "retain"


class ConflictType(Enum):
    """Types of conflicts that can occur."""
    NONE = "none"
    OVERLAPPING_EDIT = "overlapping_edit"
    CONCURRENT_DELETE = "concurrent_delete"
    MOVE_CONFLICT = "move_conflict"
    SEMANTIC_CONFLICT = "semantic_conflict"
    LOCK_CONFLICT = "lock_conflict"


class MergeStrategy(Enum):
    """Strategies for merging conflicts."""
    LAST_WRITE_WINS = "last_write_wins"
    FIRST_WRITE_WINS = "first_write_wins"
    SEMANTIC_MERGE = "semantic_merge"
    THREE_WAY_MERGE = "three_way_merge"
    MANUAL_RESOLUTION = "manual_resolution"


class UserRole(Enum):
    """User roles in collaboration session."""
    OWNER = "owner"
    EDITOR = "editor"
    REVIEWER = "reviewer"
    VIEWER = "viewer"


class SessionState(Enum):
    """State of a collaboration session."""
    ACTIVE = "active"
    PAUSED = "paused"
    RESOLVING_CONFLICT = "resolving_conflict"
    CLOSED = "closed"


# =============================================================================
# DATA STRUCTURES
# =============================================================================

@dataclass(frozen=True)
class UserId:
    """Unique user identifier."""
    value: str

    @classmethod
    def generate(cls) -> "UserId":
        return cls(f"user_{uuid.uuid4().hex[:12]}")

    def __hash__(self) -> int:
        return hash(self.value)


@dataclass
class VectorClock:
    """
    Vector clock for causal ordering of events.

    Each entry maps a user ID to their logical timestamp.
    """
    clock: Dict[str, int] = field(default_factory=dict)

    def increment(self, user_id: str) -> "VectorClock":
        """Increment clock for a user."""
        new_clock = dict(self.clock)
        new_clock[user_id] = new_clock.get(user_id, 0) + 1
        return VectorClock(new_clock)

    def merge(self, other: "VectorClock") -> "VectorClock":
        """Merge two vector clocks (take max of each entry)."""
        merged = dict(self.clock)
        for user_id, timestamp in other.clock.items():
            merged[user_id] = max(merged.get(user_id, 0), timestamp)
        return VectorClock(merged)

    def happens_before(self, other: "VectorClock") -> bool:
        """Check if this clock happens-before another."""
        if not self.clock:
            return bool(other.clock)

        for user_id, timestamp in self.clock.items():
            if timestamp > other.clock.get(user_id, 0):
                return False

        # At least one entry must be strictly less
        for user_id, timestamp in self.clock.items():
            if timestamp < other.clock.get(user_id, 0):
                return True

        return False

    def concurrent_with(self, other: "VectorClock") -> bool:
        """Check if two clocks are concurrent (neither happens-before)."""
        return not self.happens_before(other) and not other.happens_before(self)

    def to_tuple(self) -> Tuple[Tuple[str, int], ...]:
        """Convert to hashable tuple."""
        return tuple(sorted(self.clock.items()))

    def __hash__(self) -> int:
        return hash(self.to_tuple())


@dataclass
class Operation:
    """
    A single editing operation in the CRDT.

    Immutable and uniquely identified for conflict resolution.
    """
    id: str
    user_id: str
    op_type: OperationType
    position: int  # Character position in document
    content: str = ""  # For INSERT/REPLACE
    length: int = 0  # For DELETE/REPLACE
    timestamp: float = field(default_factory=time.time)
    vector_clock: VectorClock = field(default_factory=VectorClock)
    parent_ops: FrozenSet[str] = field(default_factory=frozenset)  # Causal dependencies

    @classmethod
    def insert(
        cls,
        user_id: str,
        position: int,
        content: str,
        vector_clock: VectorClock,
        parent_ops: Optional[Set[str]] = None,
    ) -> "Operation":
        """Create an insert operation."""
        return cls(
            id=f"op_{uuid.uuid4().hex[:12]}",
            user_id=user_id,
            op_type=OperationType.INSERT,
            position=position,
            content=content,
            vector_clock=vector_clock,
            parent_ops=frozenset(parent_ops or set()),
        )

    @classmethod
    def delete(
        cls,
        user_id: str,
        position: int,
        length: int,
        vector_clock: VectorClock,
        parent_ops: Optional[Set[str]] = None,
    ) -> "Operation":
        """Create a delete operation."""
        return cls(
            id=f"op_{uuid.uuid4().hex[:12]}",
            user_id=user_id,
            op_type=OperationType.DELETE,
            position=position,
            length=length,
            vector_clock=vector_clock,
            parent_ops=frozenset(parent_ops or set()),
        )

    def to_dict(self) -> Dict[str, Any]:
        """Serialize to dictionary."""
        return {
            "id": self.id,
            "user_id": self.user_id,
            "op_type": self.op_type.value,
            "position": self.position,
            "content": self.content,
            "length": self.length,
            "timestamp": self.timestamp,
            "vector_clock": self.vector_clock.clock,
            "parent_ops": list(self.parent_ops),
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "Operation":
        """Deserialize from dictionary."""
        return cls(
            id=data["id"],
            user_id=data["user_id"],
            op_type=OperationType(data["op_type"]),
            position=data["position"],
            content=data.get("content", ""),
            length=data.get("length", 0),
            timestamp=data.get("timestamp", time.time()),
            vector_clock=VectorClock(data.get("vector_clock", {})),
            parent_ops=frozenset(data.get("parent_ops", [])),
        )


@dataclass
class Conflict:
    """Represents a detected conflict between operations."""
    id: str
    conflict_type: ConflictType
    operations: List[Operation]
    affected_range: Tuple[int, int]  # (start, end) in document
    resolved: bool = False
    resolution: Optional[Operation] = None
    resolution_strategy: Optional[MergeStrategy] = None
    created_at: float = field(default_factory=time.time)

    @classmethod
    def create(
        cls,
        conflict_type: ConflictType,
        operations: List[Operation],
        affected_range: Tuple[int, int],
    ) -> "Conflict":
        """Create a new conflict."""
        return cls(
            id=f"conflict_{uuid.uuid4().hex[:12]}",
            conflict_type=conflict_type,
            operations=operations,
            affected_range=affected_range,
        )


@dataclass
class User:
    """Represents a user in the collaboration session."""
    id: UserId
    name: str
    role: UserRole
    cursor_position: int = 0
    selection_start: Optional[int] = None
    selection_end: Optional[int] = None
    last_active: float = field(default_factory=time.time)
    color: str = "#0000FF"  # For cursor highlighting
    metadata: Dict[str, Any] = field(default_factory=dict)

    def is_active(self, timeout: float = 300.0) -> bool:
        """Check if user is currently active."""
        return time.time() - self.last_active < timeout


@dataclass
class EditSession:
    """A collaborative editing session for a file."""
    id: str
    file_path: Path
    state: SessionState
    users: Dict[str, User] = field(default_factory=dict)
    base_content: str = ""
    current_content: str = ""
    operations: List[Operation] = field(default_factory=list)
    pending_conflicts: List[Conflict] = field(default_factory=list)
    vector_clock: VectorClock = field(default_factory=VectorClock)
    created_at: float = field(default_factory=time.time)
    last_modified: float = field(default_factory=time.time)
    metadata: Dict[str, Any] = field(default_factory=dict)

    def content_hash(self) -> str:
        """Get hash of current content for verification."""
        return hashlib.sha256(self.current_content.encode()).hexdigest()[:16]


# =============================================================================
# CRDT ENGINE
# =============================================================================

class CRDTDocument:
    """
    Conflict-free Replicated Data Type for text documents.

    Uses a variant of RGA (Replicated Growable Array) with tombstones.
    Ensures eventual consistency across all replicas.
    """

    def __init__(self, initial_content: str = ""):
        self._content = list(initial_content)
        self._tombstones: Set[int] = set()  # Deleted positions
        self._operations: List[Operation] = []
        self._op_index: Dict[str, Operation] = {}
        self._vector_clock = VectorClock()
        self._lock = asyncio.Lock()

    @property
    def content(self) -> str:
        """Get visible content (excluding tombstones)."""
        result = []
        for i, char in enumerate(self._content):
            if i not in self._tombstones:
                result.append(char)
        return "".join(result)

    @property
    def vector_clock(self) -> VectorClock:
        """Get current vector clock."""
        return self._vector_clock

    def _visible_to_internal(self, visible_pos: int) -> int:
        """Convert visible position to internal position (accounting for tombstones)."""
        internal_pos = 0
        visible_count = 0

        while visible_count < visible_pos and internal_pos < len(self._content):
            if internal_pos not in self._tombstones:
                visible_count += 1
            internal_pos += 1

        # Skip any tombstones at the end
        while internal_pos < len(self._content) and internal_pos in self._tombstones:
            internal_pos += 1

        return internal_pos

    def _internal_to_visible(self, internal_pos: int) -> int:
        """Convert internal position to visible position."""
        visible_pos = 0
        for i in range(min(internal_pos, len(self._content))):
            if i not in self._tombstones:
                visible_pos += 1
        return visible_pos

    async def apply_operation(self, op: Operation) -> Tuple[bool, Optional[Conflict]]:
        """
        Apply an operation to the document.

        Returns (success, conflict) tuple.
        """
        async with self._lock:
            # Check for duplicate
            if op.id in self._op_index:
                return True, None

            # Check causal dependencies
            for parent_id in op.parent_ops:
                if parent_id not in self._op_index:
                    logger.warning(f"Missing parent operation: {parent_id}")
                    # Could queue for later, but for now just proceed

            # Detect conflicts with concurrent operations
            conflict = self._detect_conflict(op)

            # Apply the operation
            if op.op_type == OperationType.INSERT:
                self._apply_insert(op)
            elif op.op_type == OperationType.DELETE:
                self._apply_delete(op)
            elif op.op_type == OperationType.REPLACE:
                self._apply_replace(op)

            # Update state
            self._operations.append(op)
            self._op_index[op.id] = op
            self._vector_clock = self._vector_clock.merge(op.vector_clock)

            return True, conflict

    def _detect_conflict(self, op: Operation) -> Optional[Conflict]:
        """Detect if operation conflicts with any concurrent operation."""
        conflicts = []

        for existing_op in self._operations:
            if existing_op.vector_clock.concurrent_with(op.vector_clock):
                # Check if ranges overlap
                if self._ranges_overlap(existing_op, op):
                    conflicts.append(existing_op)

        if conflicts:
            # Determine conflict type
            conflict_type = ConflictType.OVERLAPPING_EDIT
            if op.op_type == OperationType.DELETE and any(
                o.op_type == OperationType.DELETE for o in conflicts
            ):
                conflict_type = ConflictType.CONCURRENT_DELETE

            # Calculate affected range
            all_ops = conflicts + [op]
            start = min(o.position for o in all_ops)
            end = max(o.position + max(o.length, len(o.content)) for o in all_ops)

            return Conflict.create(
                conflict_type=conflict_type,
                operations=all_ops,
                affected_range=(start, end),
            )

        return None

    def _ranges_overlap(self, op1: Operation, op2: Operation) -> bool:
        """Check if two operations affect overlapping ranges."""
        start1 = op1.position
        end1 = op1.position + max(op1.length, len(op1.content))
        start2 = op2.position
        end2 = op2.position + max(op2.length, len(op2.content))

        return not (end1 <= start2 or end2 <= start1)

    def _apply_insert(self, op: Operation) -> None:
        """Apply an insert operation."""
        internal_pos = self._visible_to_internal(op.position)

        # Insert characters
        for i, char in enumerate(op.content):
            self._content.insert(internal_pos + i, char)

        # Adjust tombstone positions
        new_tombstones = set()
        for t in self._tombstones:
            if t >= internal_pos:
                new_tombstones.add(t + len(op.content))
            else:
                new_tombstones.add(t)
        self._tombstones = new_tombstones

    def _apply_delete(self, op: Operation) -> None:
        """Apply a delete operation (creates tombstones)."""
        internal_start = self._visible_to_internal(op.position)

        # Mark positions as tombstones
        deleted = 0
        pos = internal_start
        while deleted < op.length and pos < len(self._content):
            if pos not in self._tombstones:
                self._tombstones.add(pos)
                deleted += 1
            pos += 1

    def _apply_replace(self, op: Operation) -> None:
        """Apply a replace operation (delete + insert)."""
        # Delete
        delete_op = Operation.delete(
            op.user_id, op.position, op.length, op.vector_clock
        )
        self._apply_delete(delete_op)

        # Insert
        insert_op = Operation.insert(
            op.user_id, op.position, op.content, op.vector_clock
        )
        self._apply_insert(insert_op)

    def get_state(self) -> Dict[str, Any]:
        """Get serializable state."""
        return {
            "content": self.content,
            "operations": [op.to_dict() for op in self._operations],
            "vector_clock": self._vector_clock.clock,
        }

    @classmethod
    def from_state(cls, state: Dict[str, Any]) -> "CRDTDocument":
        """Restore from serialized state."""
        doc = cls()
        doc._content = list(state.get("content", ""))
        doc._vector_clock = VectorClock(state.get("vector_clock", {}))
        for op_data in state.get("operations", []):
            op = Operation.from_dict(op_data)
            doc._operations.append(op)
            doc._op_index[op.id] = op
        return doc


# =============================================================================
# CONFLICT RESOLVER
# =============================================================================

class ConflictResolver:
    """
    Resolves conflicts between concurrent operations.

    Supports multiple strategies:
    - Last-write-wins (simple timestamp-based)
    - First-write-wins (preserve original)
    - Semantic merge (AST-aware merging)
    - Three-way merge (common ancestor)
    - Manual resolution (human intervention)
    """

    def __init__(self, config: CollaborationConfig):
        self.config = config
        self._resolvers: Dict[MergeStrategy, Callable] = {
            MergeStrategy.LAST_WRITE_WINS: self._resolve_lww,
            MergeStrategy.FIRST_WRITE_WINS: self._resolve_fww,
            MergeStrategy.SEMANTIC_MERGE: self._resolve_semantic,
            MergeStrategy.THREE_WAY_MERGE: self._resolve_three_way,
        }

    async def resolve(
        self,
        conflict: Conflict,
        strategy: Optional[MergeStrategy] = None,
        base_content: str = "",
    ) -> Operation:
        """
        Resolve a conflict using the specified strategy.

        Returns the resolution operation.
        """
        if strategy is None:
            strategy = MergeStrategy(self.config.merge_strategy)

        resolver = self._resolvers.get(strategy, self._resolve_lww)
        resolution = await resolver(conflict, base_content)

        conflict.resolved = True
        conflict.resolution = resolution
        conflict.resolution_strategy = strategy

        return resolution

    async def _resolve_lww(
        self,
        conflict: Conflict,
        base_content: str,
    ) -> Operation:
        """Last-write-wins: use the most recent operation."""
        latest_op = max(conflict.operations, key=lambda o: o.timestamp)
        return latest_op

    async def _resolve_fww(
        self,
        conflict: Conflict,
        base_content: str,
    ) -> Operation:
        """First-write-wins: use the earliest operation."""
        earliest_op = min(conflict.operations, key=lambda o: o.timestamp)
        return earliest_op

    async def _resolve_semantic(
        self,
        conflict: Conflict,
        base_content: str,
    ) -> Operation:
        """
        Semantic merge: use AST-aware merging for code files.

        Tries to intelligently merge based on code structure.
        """
        # Group operations by type
        inserts = [op for op in conflict.operations if op.op_type == OperationType.INSERT]
        deletes = [op for op in conflict.operations if op.op_type == OperationType.DELETE]

        # If all are inserts at different positions, we can merge them
        if inserts and not deletes:
            # Sort by position, apply in order
            sorted_inserts = sorted(inserts, key=lambda o: o.position)

            # Combine into single operation
            combined_content = "".join(op.content for op in sorted_inserts)
            min_position = min(op.position for op in sorted_inserts)

            # Create merged vector clock
            merged_clock = VectorClock()
            for op in sorted_inserts:
                merged_clock = merged_clock.merge(op.vector_clock)

            return Operation.insert(
                user_id="system_merge",
                position=min_position,
                content=combined_content,
                vector_clock=merged_clock,
            )

        # For deletes or mixed, fall back to LWW
        return await self._resolve_lww(conflict, base_content)

    async def _resolve_three_way(
        self,
        conflict: Conflict,
        base_content: str,
    ) -> Operation:
        """
        Three-way merge using common ancestor.

        Uses diff3-style merging algorithm.
        """
        if not base_content:
            # No base content, fall back to semantic
            return await self._resolve_semantic(conflict, base_content)

        # Get the two conflicting versions
        # This is a simplified implementation
        ops_by_user: Dict[str, List[Operation]] = defaultdict(list)
        for op in conflict.operations:
            ops_by_user[op.user_id].append(op)

        if len(ops_by_user) < 2:
            return await self._resolve_semantic(conflict, base_content)

        # Apply each user's operations to get their version
        versions = []
        for user_id, ops in ops_by_user.items():
            # Simplified: use last operation from each user
            versions.append(ops[-1])

        # For now, use semantic merge on the two versions
        conflict.operations = versions
        return await self._resolve_semantic(conflict, base_content)

    def can_auto_resolve(self, conflict: Conflict) -> bool:
        """Check if conflict can be automatically resolved."""
        # Non-overlapping inserts can always be auto-resolved
        if conflict.conflict_type == ConflictType.OVERLAPPING_EDIT:
            inserts = [op for op in conflict.operations if op.op_type == OperationType.INSERT]
            if len(inserts) == len(conflict.operations):
                # Check if they're actually non-overlapping
                positions = [(op.position, op.position + len(op.content)) for op in inserts]
                positions.sort()
                for i in range(len(positions) - 1):
                    if positions[i][1] > positions[i + 1][0]:
                        return False
                return True

        return False


# =============================================================================
# SESSION MANAGER
# =============================================================================

class SessionManager:
    """
    Manages collaborative editing sessions.

    Handles:
    - Session lifecycle (create, join, leave, close)
    - User presence tracking
    - Real-time sync across participants
    - Session persistence
    """

    def __init__(self, config: CollaborationConfig):
        self.config = config
        self._sessions: Dict[str, EditSession] = {}
        self._user_sessions: Dict[str, Set[str]] = defaultdict(set)  # user_id -> session_ids
        self._documents: Dict[str, CRDTDocument] = {}
        self._lock = asyncio.Lock()
        self._heartbeat_task: Optional[asyncio.Task] = None
        self._running = False

        # Ensure state directory exists
        config.state_dir.mkdir(parents=True, exist_ok=True)

    async def start(self) -> None:
        """Start the session manager."""
        self._running = True
        self._heartbeat_task = asyncio.create_task(self._heartbeat_loop())

        if self.config.enable_persistence:
            await self._load_persisted_sessions()

        logger.info("Session manager started")

    async def stop(self) -> None:
        """Stop the session manager."""
        self._running = False

        if self._heartbeat_task:
            self._heartbeat_task.cancel()
            try:
                await self._heartbeat_task
            except asyncio.CancelledError:
                pass

        if self.config.enable_persistence:
            await self._persist_all_sessions()

        logger.info("Session manager stopped")

    async def create_session(
        self,
        file_path: Path,
        creator: User,
        base_content: Optional[str] = None,
    ) -> EditSession:
        """Create a new collaborative editing session."""
        async with self._lock:
            # Check if session already exists for this file
            for session in self._sessions.values():
                if session.file_path == file_path and session.state == SessionState.ACTIVE:
                    # Join existing session instead
                    await self._add_user_to_session(session, creator)
                    return session

            # Read file content if not provided
            if base_content is None:
                if file_path.exists():
                    base_content = await asyncio.to_thread(file_path.read_text)
                else:
                    base_content = ""

            # Create session
            session = EditSession(
                id=f"session_{uuid.uuid4().hex[:12]}",
                file_path=file_path,
                state=SessionState.ACTIVE,
                users={creator.id.value: creator},
                base_content=base_content,
                current_content=base_content,
            )

            # Create CRDT document
            self._documents[session.id] = CRDTDocument(base_content)

            # Store session
            self._sessions[session.id] = session
            self._user_sessions[creator.id.value].add(session.id)

            logger.info(f"Created session {session.id} for {file_path}")
            return session

    async def join_session(
        self,
        session_id: str,
        user: User,
    ) -> Optional[EditSession]:
        """Join an existing session."""
        async with self._lock:
            session = self._sessions.get(session_id)
            if not session:
                return None

            if session.state != SessionState.ACTIVE:
                return None

            if len(session.users) >= self.config.max_users_per_file:
                logger.warning(f"Session {session_id} is full")
                return None

            await self._add_user_to_session(session, user)
            return session

    async def _add_user_to_session(self, session: EditSession, user: User) -> None:
        """Add a user to a session."""
        session.users[user.id.value] = user
        self._user_sessions[user.id.value].add(session.id)
        logger.info(f"User {user.name} joined session {session.id}")

    async def leave_session(
        self,
        session_id: str,
        user_id: str,
    ) -> bool:
        """Leave a session."""
        async with self._lock:
            session = self._sessions.get(session_id)
            if not session:
                return False

            if user_id not in session.users:
                return False

            del session.users[user_id]
            self._user_sessions[user_id].discard(session_id)

            # Close session if no users left
            if not session.users:
                await self._close_session(session)

            logger.info(f"User {user_id} left session {session_id}")
            return True

    async def _close_session(self, session: EditSession) -> None:
        """Close a session."""
        session.state = SessionState.CLOSED

        # Persist final state
        if self.config.enable_persistence:
            await self._persist_session(session)

        # Clean up
        if session.id in self._documents:
            del self._documents[session.id]

        logger.info(f"Closed session {session.id}")

    async def apply_operation(
        self,
        session_id: str,
        operation: Operation,
    ) -> Tuple[bool, Optional[Conflict]]:
        """Apply an operation to a session."""
        async with self._lock:
            session = self._sessions.get(session_id)
            if not session:
                return False, None

            doc = self._documents.get(session_id)
            if not doc:
                return False, None

            # Apply to CRDT
            success, conflict = await doc.apply_operation(operation)

            if success:
                # Update session state
                session.operations.append(operation)
                session.current_content = doc.content
                session.vector_clock = doc.vector_clock
                session.last_modified = time.time()

                if conflict:
                    session.pending_conflicts.append(conflict)
                    session.state = SessionState.RESOLVING_CONFLICT

            return success, conflict

    async def get_session(self, session_id: str) -> Optional[EditSession]:
        """Get a session by ID."""
        return self._sessions.get(session_id)

    async def get_user_sessions(self, user_id: str) -> List[EditSession]:
        """Get all sessions for a user."""
        session_ids = self._user_sessions.get(user_id, set())
        return [self._sessions[sid] for sid in session_ids if sid in self._sessions]

    async def _heartbeat_loop(self) -> None:
        """Check for inactive users and sessions."""
        while self._running:
            try:
                await asyncio.sleep(self.config.heartbeat_interval)
                await self._cleanup_inactive()
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Heartbeat error: {e}")

    async def _cleanup_inactive(self) -> None:
        """Clean up inactive users and sessions."""
        async with self._lock:
            now = time.time()

            for session in list(self._sessions.values()):
                if session.state != SessionState.ACTIVE:
                    continue

                # Check for inactive users
                inactive_users = [
                    uid for uid, user in session.users.items()
                    if now - user.last_active > self.config.session_timeout
                ]

                for uid in inactive_users:
                    del session.users[uid]
                    self._user_sessions[uid].discard(session.id)
                    logger.info(f"Removed inactive user {uid} from session {session.id}")

                # Close empty sessions
                if not session.users:
                    await self._close_session(session)

    async def _persist_session(self, session: EditSession) -> None:
        """Persist a session to disk."""
        state_file = self.config.state_dir / f"{session.id}.json"

        doc = self._documents.get(session.id)
        state = {
            "session": {
                "id": session.id,
                "file_path": str(session.file_path),
                "state": session.state.value,
                "base_content": session.base_content,
                "current_content": session.current_content,
                "created_at": session.created_at,
                "last_modified": session.last_modified,
            },
            "document": doc.get_state() if doc else None,
        }

        await asyncio.to_thread(
            state_file.write_text,
            json.dumps(state, indent=2)
        )

    async def _persist_all_sessions(self) -> None:
        """Persist all active sessions."""
        for session in self._sessions.values():
            if session.state == SessionState.ACTIVE:
                await self._persist_session(session)

    async def _load_persisted_sessions(self) -> None:
        """Load persisted sessions from disk."""
        for state_file in self.config.state_dir.glob("session_*.json"):
            try:
                data = json.loads(await asyncio.to_thread(state_file.read_text))
                # Only restore active sessions
                if data["session"]["state"] == SessionState.ACTIVE.value:
                    logger.info(f"Restored session from {state_file}")
            except Exception as e:
                logger.warning(f"Failed to load session from {state_file}: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """Get session manager statistics."""
        return {
            "active_sessions": sum(
                1 for s in self._sessions.values()
                if s.state == SessionState.ACTIVE
            ),
            "total_sessions": len(self._sessions),
            "total_users": len(self._user_sessions),
            "conflicts_pending": sum(
                len(s.pending_conflicts) for s in self._sessions.values()
            ),
        }


# =============================================================================
# COLLABORATION ENGINE
# =============================================================================

class CollaborationEngine:
    """
    Main collaboration engine coordinating all components.

    Provides high-level API for:
    - Multi-user editing sessions
    - Real-time sync
    - Conflict detection and resolution
    - Cross-repo collaboration
    """

    def __init__(self, config: Optional[CollaborationConfig] = None):
        self.config = config or CollaborationConfig.from_env()
        self.session_manager = SessionManager(self.config)
        self.conflict_resolver = ConflictResolver(self.config)
        self._event_handlers: Dict[str, List[Callable]] = defaultdict(list)
        self._running = False

    async def initialize(self) -> bool:
        """Initialize the collaboration engine."""
        try:
            await self.session_manager.start()
            self._running = True
            logger.info("Collaboration engine initialized")
            return True
        except Exception as e:
            logger.error(f"Failed to initialize collaboration engine: {e}")
            return False

    async def shutdown(self) -> None:
        """Shutdown the collaboration engine."""
        self._running = False
        await self.session_manager.stop()
        logger.info("Collaboration engine shutdown")

    async def start_editing(
        self,
        file_path: Path,
        user_name: str,
        user_role: UserRole = UserRole.EDITOR,
    ) -> Tuple[EditSession, User]:
        """
        Start editing a file.

        Creates or joins a session for the file.
        """
        user = User(
            id=UserId.generate(),
            name=user_name,
            role=user_role,
        )

        session = await self.session_manager.create_session(file_path, user)

        await self._emit_event("session_joined", {
            "session_id": session.id,
            "user": user.name,
            "file": str(file_path),
        })

        return session, user

    async def apply_edit(
        self,
        session_id: str,
        user_id: str,
        op_type: OperationType,
        position: int,
        content: str = "",
        length: int = 0,
    ) -> Tuple[bool, Optional[Conflict]]:
        """
        Apply an edit operation.

        Returns (success, conflict) tuple.
        """
        session = await self.session_manager.get_session(session_id)
        if not session:
            return False, None

        # Update user activity
        if user_id in session.users:
            session.users[user_id].last_active = time.time()

        # Create operation
        new_clock = session.vector_clock.increment(user_id)
        parent_ops = frozenset(op.id for op in session.operations[-10:])  # Last 10 ops

        if op_type == OperationType.INSERT:
            operation = Operation.insert(user_id, position, content, new_clock, parent_ops)
        elif op_type == OperationType.DELETE:
            operation = Operation.delete(user_id, position, length, new_clock, parent_ops)
        else:
            operation = Operation(
                id=f"op_{uuid.uuid4().hex[:12]}",
                user_id=user_id,
                op_type=op_type,
                position=position,
                content=content,
                length=length,
                vector_clock=new_clock,
                parent_ops=parent_ops,
            )

        # Apply operation
        success, conflict = await self.session_manager.apply_operation(session_id, operation)

        if success:
            await self._emit_event("operation_applied", {
                "session_id": session_id,
                "operation_id": operation.id,
                "user_id": user_id,
            })

        if conflict:
            await self._emit_event("conflict_detected", {
                "session_id": session_id,
                "conflict_id": conflict.id,
                "type": conflict.conflict_type.value,
            })

            # Try auto-resolve
            if self.conflict_resolver.can_auto_resolve(conflict):
                await self.resolve_conflict(session_id, conflict.id)

        return success, conflict

    async def resolve_conflict(
        self,
        session_id: str,
        conflict_id: str,
        strategy: Optional[MergeStrategy] = None,
    ) -> bool:
        """Resolve a conflict in a session."""
        session = await self.session_manager.get_session(session_id)
        if not session:
            return False

        # Find conflict
        conflict = next(
            (c for c in session.pending_conflicts if c.id == conflict_id),
            None
        )
        if not conflict:
            return False

        # Resolve
        resolution = await self.conflict_resolver.resolve(
            conflict,
            strategy,
            session.base_content,
        )

        # Apply resolution
        success, _ = await self.session_manager.apply_operation(session_id, resolution)

        if success:
            session.pending_conflicts.remove(conflict)
            if not session.pending_conflicts:
                session.state = SessionState.ACTIVE

            await self._emit_event("conflict_resolved", {
                "session_id": session_id,
                "conflict_id": conflict_id,
                "strategy": conflict.resolution_strategy.value if conflict.resolution_strategy else None,
            })

        return success

    async def update_cursor(
        self,
        session_id: str,
        user_id: str,
        position: int,
        selection_start: Optional[int] = None,
        selection_end: Optional[int] = None,
    ) -> bool:
        """Update a user's cursor position."""
        session = await self.session_manager.get_session(session_id)
        if not session or user_id not in session.users:
            return False

        user = session.users[user_id]
        user.cursor_position = position
        user.selection_start = selection_start
        user.selection_end = selection_end
        user.last_active = time.time()

        await self._emit_event("cursor_updated", {
            "session_id": session_id,
            "user_id": user_id,
            "position": position,
        })

        return True

    async def get_session_content(self, session_id: str) -> Optional[str]:
        """Get current content of a session."""
        session = await self.session_manager.get_session(session_id)
        return session.current_content if session else None

    async def get_session_users(self, session_id: str) -> List[User]:
        """Get all users in a session."""
        session = await self.session_manager.get_session(session_id)
        return list(session.users.values()) if session else []

    async def leave_session(self, session_id: str, user_id: str) -> bool:
        """Leave a session."""
        success = await self.session_manager.leave_session(session_id, user_id)

        if success:
            await self._emit_event("session_left", {
                "session_id": session_id,
                "user_id": user_id,
            })

        return success

    def on_event(self, event_type: str, handler: Callable) -> None:
        """Register an event handler."""
        self._event_handlers[event_type].append(handler)

    async def _emit_event(self, event_type: str, data: Dict[str, Any]) -> None:
        """Emit an event to all handlers."""
        for handler in self._event_handlers.get(event_type, []):
            try:
                if asyncio.iscoroutinefunction(handler):
                    await handler(data)
                else:
                    handler(data)
            except Exception as e:
                logger.error(f"Event handler error: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """Get collaboration engine statistics."""
        return {
            "running": self._running,
            "sessions": self.session_manager.get_stats(),
        }


# =============================================================================
# CROSS-REPO COLLABORATION
# =============================================================================

class CrossRepoCollaborationCoordinator:
    """
    Coordinates collaboration across Ironcliw, Ironcliw-Prime, and Reactor-Core.

    Enables:
    - Cross-repo editing sessions
    - Conflict resolution across repos
    - Synchronized state
    """

    def __init__(self, config: Optional[CollaborationConfig] = None):
        self.config = config or CollaborationConfig.from_env()
        self._engines: Dict[str, CollaborationEngine] = {}
        self._cross_repo_sessions: Dict[str, Set[str]] = {}  # session_id -> repo_ids
        self._running = False

    async def initialize(self) -> bool:
        """Initialize cross-repo collaboration."""
        if not self.config.enable_cross_repo:
            return True

        try:
            # Import cross-repo module
            from backend.core.ouroboros.cross_repo import (
                get_enhanced_cross_repo_orchestrator,
                RepoType,
            )

            self._orchestrator = get_enhanced_cross_repo_orchestrator()
            self._running = True

            logger.info("Cross-repo collaboration coordinator initialized")
            return True
        except ImportError:
            logger.warning("Cross-repo module not available")
            return False

    async def create_cross_repo_session(
        self,
        file_paths: Dict[str, Path],  # repo_id -> file_path
        user_name: str,
    ) -> str:
        """
        Create a session spanning multiple repositories.

        Synchronizes edits across all specified files.
        """
        session_id = f"xrepo_{uuid.uuid4().hex[:12]}"
        self._cross_repo_sessions[session_id] = set(file_paths.keys())

        for repo_id, file_path in file_paths.items():
            if repo_id not in self._engines:
                self._engines[repo_id] = CollaborationEngine(self.config)
                await self._engines[repo_id].initialize()

            await self._engines[repo_id].start_editing(file_path, user_name)

        return session_id

    async def shutdown(self) -> None:
        """Shutdown cross-repo collaboration."""
        for engine in self._engines.values():
            await engine.shutdown()
        self._running = False


# =============================================================================
# GLOBAL INSTANCES
# =============================================================================

_collaboration_engine: Optional[CollaborationEngine] = None
_cross_repo_coordinator: Optional[CrossRepoCollaborationCoordinator] = None


def get_collaboration_engine(
    config: Optional[CollaborationConfig] = None
) -> CollaborationEngine:
    """
    Get or create the global collaboration engine.

    Args:
        config: Optional configuration. If provided and engine doesn't exist,
               uses this config. If engine exists, config is ignored
               (singleton already created).

    Returns:
        The global CollaborationEngine instance.
    """
    global _collaboration_engine
    if _collaboration_engine is None:
        # Use provided config or let CollaborationEngine use defaults
        _collaboration_engine = CollaborationEngine(config=config)
    return _collaboration_engine


def get_cross_repo_coordinator() -> CrossRepoCollaborationCoordinator:
    """Get the global cross-repo coordinator."""
    global _cross_repo_coordinator
    if _cross_repo_coordinator is None:
        _cross_repo_coordinator = CrossRepoCollaborationCoordinator()
    return _cross_repo_coordinator


async def initialize_collaboration() -> bool:
    """Initialize collaboration system."""
    engine = get_collaboration_engine()
    success = await engine.initialize()

    if success:
        coordinator = get_cross_repo_coordinator()
        await coordinator.initialize()

    return success


async def shutdown_collaboration() -> None:
    """Shutdown collaboration system."""
    global _collaboration_engine, _cross_repo_coordinator

    if _cross_repo_coordinator:
        await _cross_repo_coordinator.shutdown()
        _cross_repo_coordinator = None

    if _collaboration_engine:
        await _collaboration_engine.shutdown()
        _collaboration_engine = None
