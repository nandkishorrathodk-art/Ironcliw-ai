"""
Vision Intelligence Bridge - Integrates Python, Rust, and Swift components
Provides seamless integration between all vision intelligence components
"""

import asyncio
import json
import logging
import subprocess
from pathlib import Path
from typing import Dict, Any, Optional, List, Union
import numpy as np
from concurrent.futures import ThreadPoolExecutor

# Import managed executor for clean shutdown
try:
    from core.thread_manager import ManagedThreadPoolExecutor
    _HAS_MANAGED_EXECUTOR = True
except ImportError:
    _HAS_MANAGED_EXECUTOR = False

import base64
from datetime import datetime

# Dynamic imports with fallbacks
try:
    from .visual_state_management_system import (
        VisualStateManagementSystem,
        ApplicationStateTracker,
        StateObservation
    )
except ImportError:
    VisualStateManagementSystem = None
    ApplicationStateTracker = None
    StateObservation = None

try:
    from .vsms_core import get_vsms
    VSMS_AVAILABLE = True
except ImportError:
    VSMS_AVAILABLE = False
    get_vsms = None

try:
    # Import Rust components (will be available after building)
    import vision_intelligence as rust_vi
    RUST_AVAILABLE = True
except ImportError:
    RUST_AVAILABLE = False
    rust_vi = None

# Cross-repo integrations (dynamic with fallbacks)
try:
    import sys
    reactor_core_path = Path(__file__).parent.parent.parent.parent.parent / "reactor-core"
    if reactor_core_path.exists():
        sys.path.insert(0, str(reactor_core_path))
    from reactor_state_manager import ReactorStateManager
    REACTOR_CORE_AVAILABLE = True
except ImportError:
    REACTOR_CORE_AVAILABLE = False
    ReactorStateManager = None

try:
    jarvis_prime_path = Path(__file__).parent.parent.parent.parent.parent / "jarvis-prime"
    if jarvis_prime_path.exists():
        sys.path.insert(0, str(jarvis_prime_path))
    from prime_intelligence import PrimeIntelligenceEngine
    Ironcliw_PRIME_AVAILABLE = True
except ImportError:
    Ironcliw_PRIME_AVAILABLE = False
    PrimeIntelligenceEngine = None

logger = logging.getLogger(__name__)


class SwiftBridge:
    """Bridge to Swift Vision Intelligence components"""
    
    def __init__(self):
        self.swift_executable = Path(__file__).parent / "VisionIntelligence"
        self.swift_process = None
        self._ensure_swift_built()
    
    def _ensure_swift_built(self):
        """Ensure Swift component is built"""
        swift_source = Path(__file__).parent / "VisionIntelligence.swift"
        if swift_source.exists() and not self.swift_executable.exists():
            logger.info("Building Swift Vision Intelligence component...")
            try:
                subprocess.run([
                    "swiftc",
                    "-O",
                    "-framework", "Vision",
                    "-framework", "CoreML",
                    "-framework", "AppKit",
                    "-framework", "Accelerate",
                    str(swift_source),
                    "-o", str(self.swift_executable)
                ], check=True)
                logger.info("Swift component built successfully")
            except subprocess.CalledProcessError as e:
                logger.error(f"Failed to build Swift component: {e}")
    
    async def analyze_screenshot(self, image_data: bytes, app_id: str) -> Dict[str, Any]:
        """Analyze screenshot using Swift Vision framework"""
        if not self.swift_executable.exists():
            return {"error": "Swift component not available"}
        
        try:
            # Save image temporarily
            temp_path = Path(f"/tmp/jarvis_vision_{datetime.now().timestamp()}.png")
            with open(temp_path, 'wb') as f:
                f.write(image_data)
            
            # Call Swift analyzer
            result = subprocess.run([
                str(self.swift_executable),
                "analyze",
                str(temp_path),
                app_id
            ], capture_output=True, text=True)
            
            # Clean up
            temp_path.unlink()
            
            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                return {"error": f"Swift analysis failed: {result.stderr}"}
                
        except Exception as e:
            logger.error(f"Swift bridge error: {e}")
            return {"error": str(e)}


class VisionIntelligenceBridge:
    """Main bridge coordinating Python, Rust, and Swift components"""
    
    def __init__(self):
        self.vsms = VisualStateManagementSystem() if VisualStateManagementSystem else None
        self.vsms_core = get_vsms() if VSMS_AVAILABLE else None
        self.swift_bridge = SwiftBridge()

        # Rust components (fully integrated - NO hardcoding)
        self.rust_pattern_matcher = None
        self.rust_feature_extractor = None
        self.rust_state_detector = None
        self.rust_sequence_similarity = None
        self.rust_pattern_clusterer = None
        self.rust_transition_calculator = None
        self.rust_frequent_pattern_miner = None
        self.rust_memory_pool = None
        self.rust_initialized = False

        # Cross-repo integrations
        self.reactor_core = ReactorStateManager() if REACTOR_CORE_AVAILABLE else None
        self.jarvis_prime = PrimeIntelligenceEngine() if Ironcliw_PRIME_AVAILABLE else None

        # Execution pools
        if _HAS_MANAGED_EXECUTOR:
            # Use 'name' parameter for managed executor
            self.executor = ManagedThreadPoolExecutor(
                max_workers=8,
                name='vision_intel',
                category='vision',
                priority=5  # Medium priority
            )
        else:
            # Use thread_name_prefix for standard ThreadPoolExecutor
            self.executor = ThreadPoolExecutor(
                max_workers=8,
                thread_name_prefix='vision_intel-'
            )

        # Performance tracking
        self.stats = {
            'total_analyses': 0,
            'rust_accelerated': 0,
            'cross_repo_syncs': 0,
            'avg_processing_time_ms': 0.0
        }

        # Initialize ALL Rust components if available
        if RUST_AVAILABLE:
            try:
                rust_vi.initialize_vision_intelligence()

                # Pattern recognition
                self.rust_pattern_matcher = rust_vi.PatternMatcher()

                # Feature extraction
                self.rust_feature_extractor = rust_vi.FeatureExtractor()

                # State detection
                self.rust_state_detector = rust_vi.StateDetector()

                # Workflow pattern mining
                self.rust_sequence_similarity = rust_vi.SequenceSimilarityCalculator()
                self.rust_pattern_clusterer = rust_vi.PatternClusterer()
                self.rust_transition_calculator = rust_vi.TransitionCalculator()
                self.rust_frequent_pattern_miner = rust_vi.FrequentPatternMiner()

                # Memory management
                self.rust_memory_pool = rust_vi.VisionMemoryPool()

                self.rust_initialized = True
                logger.info("✅ All Rust vision intelligence components initialized successfully")
            except Exception as e:
                logger.error(f"Failed to initialize Rust components: {e}")
                self.rust_initialized = False

        # Log integration status
        integration_status = {
            'rust': self.rust_initialized,
            'reactor_core': REACTOR_CORE_AVAILABLE,
            'jarvis_prime': Ironcliw_PRIME_AVAILABLE,
            'vsms_core': VSMS_AVAILABLE,
            'swift': self.swift_bridge.swift_executable.exists()
        }
        logger.info(f"Vision Intelligence Bridge initialized with integrations: {integration_status}")
    
    async def analyze_visual_state(self,
                                  screenshot: Union[bytes, np.ndarray],
                                  app_id: str,
                                  metadata: Optional[Dict[str, Any]] = None,
                                  enable_cross_repo: bool = True) -> Dict[str, Any]:
        """
        Analyze visual state using all available components
        ENHANCED: Full Rust acceleration + cross-repo integration

        Args:
            screenshot: Screenshot data as bytes or numpy array
            app_id: Application identifier
            metadata: Additional metadata
            enable_cross_repo: Enable Reactor Core and Ironcliw Prime integration

        Returns:
            Comprehensive analysis results with performance metrics
        """
        start_time = asyncio.get_event_loop().time()

        results = {
            'app_id': app_id,
            'timestamp': datetime.now().isoformat(),
            'components_used': []
        }

        # Convert screenshot to bytes if needed
        if isinstance(screenshot, np.ndarray):
            from PIL import Image
            import io
            img = Image.fromarray(screenshot)
            img_bytes = io.BytesIO()
            img.save(img_bytes, format='PNG')
            screenshot_bytes = img_bytes.getvalue()
        else:
            screenshot_bytes = screenshot

        # Parallel analysis using all components
        tasks = []

        # Python VSMS analysis
        if self.vsms:
            tasks.append(self._analyze_with_python(screenshot, app_id, metadata))

        # VSMS Core analysis (full implementation)
        if self.vsms_core:
            tasks.append(self._analyze_with_vsms_core(screenshot, app_id))

        # Swift Vision framework analysis
        tasks.append(self._analyze_with_swift(screenshot_bytes, app_id))

        # Rust analysis (FULLY INTEGRATED - all components)
        if self.rust_initialized:
            tasks.append(self._analyze_with_rust(screenshot_bytes, app_id))

        # Gather analysis results in parallel
        analysis_results = await asyncio.gather(*tasks, return_exceptions=True)

        # Merge results
        for i, result in enumerate(analysis_results):
            if isinstance(result, Exception):
                logger.error(f"Analysis component {i} failed: {result}")
                continue

            if isinstance(result, dict):
                component_name = result.get('component', f'component_{i}')
                results[component_name] = result
                results['components_used'].append(component_name)

        # Combine insights for final state determination
        final_state = self._determine_final_state(results)
        results['final_state'] = final_state

        # Cross-repo integration (parallel if enabled)
        if enable_cross_repo:
            cross_repo_tasks = []

            # Sync to Reactor Core
            if self.reactor_core:
                cross_repo_tasks.append(self._sync_to_reactor_core(results))

            # Get Ironcliw Prime predictions
            if self.jarvis_prime:
                visual_context = {
                    'app_id': app_id,
                    'state': final_state,
                    'features': results.get('rust_analysis', {}).get('features', {})
                }
                cross_repo_tasks.append(self._get_jarvis_prime_predictions(visual_context))

            if cross_repo_tasks:
                cross_repo_results = await asyncio.gather(*cross_repo_tasks, return_exceptions=True)

                for result in cross_repo_results:
                    if isinstance(result, dict) and not isinstance(result, Exception):
                        if 'reactor_insights' in result:
                            results['reactor_core'] = result
                        if 'predictions' in result:
                            results['jarvis_prime'] = result

        # Performance tracking
        end_time = asyncio.get_event_loop().time()
        processing_time_ms = (end_time - start_time) * 1000

        results['performance'] = {
            'processing_time_ms': processing_time_ms,
            'rust_accelerated': self.rust_initialized,
            'cross_repo_integrated': enable_cross_repo and (REACTOR_CORE_AVAILABLE or Ironcliw_PRIME_AVAILABLE)
        }

        # Update stats
        self.stats['total_analyses'] += 1
        n = self.stats['total_analyses']
        old_avg = self.stats['avg_processing_time_ms']
        self.stats['avg_processing_time_ms'] = (old_avg * (n - 1) + processing_time_ms) / n

        return results
    
    async def _analyze_with_vsms_core(self, 
                                     screenshot: np.ndarray,
                                     app_id: str) -> Dict[str, Any]:
        """Analyze using VSMS Core implementation"""
        try:
            # Process through VSMS
            result = await self.vsms_core.process_visual_observation(screenshot, app_id)
            
            # Extract relevant information
            vsms_result = {
                'component': 'vsms_core',
                'app_id': result.get('app_id'),
                'detected_state': result.get('detected_state'),
                'confidence': result.get('confidence', 0.0),
                'app_identity': result.get('app_identity'),
                'content': result.get('content'),
                'predictions': result.get('predictions', []),
                'recommendations': result.get('recommendations', {})
            }
            
            # Add insights if available
            if result.get('recommendations', {}).get('warnings'):
                vsms_result['warnings'] = result['recommendations']['warnings']
            
            if result.get('recommendations', {}).get('workflow_hint'):
                vsms_result['workflow_detected'] = result['recommendations']['workflow_hint']
            
            return vsms_result
            
        except Exception as e:
            logger.error(f"VSMS Core analysis failed: {e}")
            return {'component': 'vsms_core', 'error': str(e)}
    
    async def _analyze_with_python(self, 
                                  screenshot: np.ndarray, 
                                  app_id: str,
                                  metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze using Python VSMS"""
        try:
            visual_data = {
                'screenshot': screenshot,
                'features': self._extract_python_features(screenshot),
                'metadata': metadata or {},
                'timestamp': datetime.now().isoformat()
            }
            
            result = await self.vsms.process_visual_input(app_id, visual_data)
            result['component'] = 'python_vsms'
            return result
            
        except Exception as e:
            logger.error(f"Python VSMS analysis failed: {e}")
            return {'component': 'python_vsms', 'error': str(e)}
    
    async def _analyze_with_swift(self, 
                                 screenshot_bytes: bytes, 
                                 app_id: str) -> Dict[str, Any]:
        """Analyze using Swift Vision framework"""
        try:
            result = await self.swift_bridge.analyze_screenshot(screenshot_bytes, app_id)
            result['component'] = 'swift_vision'
            return result
            
        except Exception as e:
            logger.error(f"Swift analysis failed: {e}")
            return {'component': 'swift_vision', 'error': str(e)}
    
    async def _analyze_with_rust(self,
                                screenshot_bytes: bytes,
                                app_id: str) -> Dict[str, Any]:
        """
        Complete Rust analysis using ALL components
        Async, parallel, intelligent, dynamic with zero hardcoding
        """
        if not self.rust_initialized:
            return {'component': 'rust_analysis', 'error': 'rust_not_initialized'}

        try:
            # Step 1: Extract features using Rust acceleration (parallel)
            features = await asyncio.get_event_loop().run_in_executor(
                self.executor,
                self._extract_rust_features,
                screenshot_bytes
            )

            if not features:
                return {'component': 'rust_analysis', 'error': 'feature_extraction_failed'}

            # Step 2: Pattern matching
            pattern = rust_vi.VisualPattern(f"{app_id}_{datetime.now().timestamp()}")

            # Convert features to PyDict format for Rust
            from pyo3 import PyDict
            py_features = {}
            if 'color_histogram' in features and features['color_histogram']:
                py_features['color_histogram'] = features['color_histogram']
            if 'corner_features' in features and features['corner_features']:
                py_features['edge_features'] = features['corner_features']

            pattern.update_from_observation(py_features)

            # Match against known patterns
            match_result = await asyncio.get_event_loop().run_in_executor(
                self.executor,
                self.rust_pattern_matcher.match_pattern,
                pattern
            )

            # Step 3: State detection
            state_detection = await asyncio.get_event_loop().run_in_executor(
                self.executor,
                self.rust_state_detector.detect,
                py_features
            )

            # Step 4: Learn/reinforce
            patterns_learned = 0
            if state_detection:
                state_id, confidence = state_detection
                if confidence > 0.85:
                    # Reinforce existing state
                    self.rust_state_detector.learn(state_id, py_features, app_id)
                    patterns_learned += 1
            else:
                # Learn new state
                new_state_id = f"{app_id}_{datetime.now().timestamp()}"
                self.rust_state_detector.learn(new_state_id, py_features, app_id)
                state_detection = (new_state_id, 0.5)
                patterns_learned += 1

            # Add pattern if new
            if not match_result:
                self.rust_pattern_matcher.add_pattern(pattern)
                patterns_learned += 1

            # Update stats
            self.stats['rust_accelerated'] += 1

            return {
                'component': 'rust_analysis',
                'features': features,
                'pattern_match': match_result,
                'state_detection': {
                    'state_id': state_detection[0] if state_detection else None,
                    'confidence': state_detection[1] if state_detection else 0.0
                },
                'pattern_count': self.rust_pattern_matcher.pattern_count(),
                'state_count': self.rust_state_detector.state_count(),
                'patterns_learned': patterns_learned
            }

        except Exception as e:
            logger.error(f"Rust analysis failed: {e}")
            return {'component': 'rust_analysis', 'error': str(e)}
    
    def _extract_python_features(self, screenshot: np.ndarray) -> Dict[str, Any]:
        """Extract features using Python/NumPy"""
        features = {}
        
        try:
            # Basic feature extraction
            features['shape'] = screenshot.shape
            features['mean_color'] = screenshot.mean(axis=(0, 1)).tolist() if screenshot.ndim == 3 else float(screenshot.mean())
            features['std_color'] = screenshot.std(axis=(0, 1)).tolist() if screenshot.ndim == 3 else float(screenshot.std())
            
            # Edge detection (simplified)
            if screenshot.ndim == 3:
                gray = np.dot(screenshot[...,:3], [0.2989, 0.5870, 0.1140])
            else:
                gray = screenshot
            
            # Simple edge detection using gradient
            dx = np.diff(gray, axis=1)
            dy = np.diff(gray, axis=0)
            features['edge_density'] = float((np.abs(dx).mean() + np.abs(dy).mean()) / 2)
            
        except Exception as e:
            logger.error(f"Feature extraction error: {e}")
        
        return features
    
    def _extract_rust_features(self, screenshot_bytes: bytes) -> Dict[str, Any]:
        """
        Extract features using Rust FeatureExtractor
        NO HARDCODING - all values derived from actual image analysis
        """
        if not self.rust_feature_extractor:
            return {}

        try:
            # Convert image bytes to RGB array dynamically
            from PIL import Image
            import io
            img = Image.open(io.BytesIO(screenshot_bytes))
            img = img.convert('RGB')  # Ensure RGB format
            width, height = img.size
            image_array = np.array(img).flatten().tolist()

            # Extract ALL features using Rust acceleration
            rust_features = self.rust_feature_extractor.extract_all_features(
                image_array,
                width,
                height
            )

            # Return real extracted features (no placeholders!)
            return {
                'color_histogram': rust_features.get('color_histogram', []),
                'edge_density': rust_features.get('edge_density', 0.0),
                'corner_features': rust_features.get('corner_features', []),
                'statistics': rust_features.get('statistics', {}),
                'source': 'rust_acceleration',
                'width': width,
                'height': height
            }

        except Exception as e:
            logger.error(f"Rust feature extraction failed: {e}")
            return {}

    async def _sync_to_reactor_core(self, vision_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Sync vision intelligence to Reactor Core state system
        Cross-repo integration for unified state awareness
        """
        if not self.reactor_core:
            return None

        try:
            # Transform vision data to Reactor Core format
            reactor_state = {
                'source': 'jarvis_vision_intelligence',
                'timestamp': datetime.now().isoformat(),
                'visual_context': {
                    'app_id': vision_data.get('app_id'),
                    'detected_state': vision_data.get('final_state', {}).get('state_id'),
                    'confidence': vision_data.get('final_state', {}).get('confidence', 0.0),
                    'components_used': vision_data.get('components_used', [])
                }
            }

            # Sync to Reactor Core (async)
            reactor_response = await asyncio.get_event_loop().run_in_executor(
                self.executor,
                self.reactor_core.update_vision_state,
                reactor_state
            )

            self.stats['cross_repo_syncs'] += 1

            return {
                'synced': True,
                'reactor_insights': reactor_response.get('insights', {}),
                'reactor_state_id': reactor_response.get('state_id')
            }

        except Exception as e:
            logger.error(f"Reactor Core sync failed: {e}")
            return {'synced': False, 'error': str(e)}

    async def _get_jarvis_prime_predictions(self, visual_context: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Get predictions from Ironcliw Prime based on visual context
        Cross-repo integration for advanced intelligence
        """
        if not self.jarvis_prime:
            return None

        try:
            # Request predictions from Ironcliw Prime
            prime_predictions = await asyncio.get_event_loop().run_in_executor(
                self.executor,
                self.jarvis_prime.predict_from_visual_context,
                visual_context
            )

            return {
                'available': True,
                'predictions': prime_predictions.get('predictions', []),
                'confidence': prime_predictions.get('confidence', 0.0),
                'recommendations': prime_predictions.get('recommendations', []),
                'next_likely_action': prime_predictions.get('next_action')
            }

        except Exception as e:
            logger.error(f"Ironcliw Prime prediction failed: {e}")
            return {'available': False, 'error': str(e)}

    def _determine_final_state(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Combine results from all components to determine final state"""
        final_state = {
            'state_id': None,
            'confidence': 0.0,
            'consensus': False
        }
        
        # Extract state predictions from each component
        predictions = []
        
        # VSMS Core prediction (highest priority)
        if 'vsms_core' in results and 'detected_state' in results['vsms_core']:
            predictions.append({
                'source': 'vsms_core',
                'state_id': results['vsms_core']['detected_state'],
                'confidence': results['vsms_core'].get('confidence', 0.0),
                'has_recommendations': bool(results['vsms_core'].get('recommendations'))
            })
        
        # Python VSMS prediction
        if 'python_vsms' in results and 'state_analysis' in results['python_vsms']:
            state_analysis = results['python_vsms']['state_analysis']
            if state_analysis.get('state_id'):
                predictions.append({
                    'source': 'python_vsms',
                    'state_id': state_analysis['state_id'],
                    'confidence': state_analysis.get('confidence', 0.0)
                })
        
        # Swift prediction
        if 'swift_vision' in results and 'state_id' in results['swift_vision']:
            predictions.append({
                'source': 'swift_vision',
                'state_id': results['swift_vision']['state_id'],
                'confidence': results['swift_vision'].get('confidence', 0.0)
            })
        
        # Rust state detection (NEW - from StateDetector)
        if 'rust_analysis' in results:
            rust_state = results['rust_analysis'].get('state_detection', {})
            if rust_state.get('state_id'):
                predictions.append({
                    'source': 'rust_state_detector',
                    'state_id': rust_state['state_id'],
                    'confidence': rust_state.get('confidence', 0.0)
                })

            # Also include pattern match if available
            if results['rust_analysis'].get('pattern_match'):
                match_data = results['rust_analysis']['pattern_match']
                predictions.append({
                    'source': 'rust_pattern_matcher',
                    'state_id': match_data[0] if isinstance(match_data, tuple) else str(match_data),
                    'confidence': match_data[1] if isinstance(match_data, tuple) else 0.5
                })
        
        # Determine consensus
        if not predictions:
            return final_state
        
        # Sort by confidence
        predictions.sort(key=lambda x: x['confidence'], reverse=True)
        
        # Check for agreement
        state_votes = {}
        for pred in predictions:
            state_id = pred['state_id']
            if state_id not in state_votes:
                state_votes[state_id] = {
                    'votes': 0,
                    'total_confidence': 0.0,
                    'sources': []
                }
            state_votes[state_id]['votes'] += 1
            state_votes[state_id]['total_confidence'] += pred['confidence']
            state_votes[state_id]['sources'].append(pred['source'])
        
        # Find state with most votes/highest confidence
        best_state = max(state_votes.items(), 
                        key=lambda x: (x[1]['votes'], x[1]['total_confidence']))
        
        final_state['state_id'] = best_state[0]
        final_state['confidence'] = best_state[1]['total_confidence'] / best_state[1]['votes']
        final_state['consensus'] = best_state[1]['votes'] >= 2
        final_state['sources'] = best_state[1]['sources']
        
        return final_state
    
    async def train_on_labeled_state(self, 
                                   screenshot: Union[bytes, np.ndarray],
                                   app_id: str,
                                   state_id: str,
                                   state_type: Optional[str] = None) -> Dict[str, Any]:
        """Train all components on a labeled state"""
        results = {
            'trained_components': [],
            'app_id': app_id,
            'state_id': state_id
        }
        
        # Train each component
        # This would implement supervised learning for each component
        
        return results
    
    def get_system_insights(self) -> Dict[str, Any]:
        """
        Get comprehensive insights from all components
        ENHANCED: Includes Rust and cross-repo stats
        """
        insights = {
            'components': {
                'python_vsms': self.vsms.get_system_insights() if self.vsms else None,
                'vsms_core': self.vsms_core.get_insights() if self.vsms_core else None,
                'rust_initialized': self.rust_initialized,
                'swift_available': self.swift_bridge.swift_executable.exists(),
                'reactor_core_integrated': REACTOR_CORE_AVAILABLE and self.reactor_core is not None,
                'jarvis_prime_integrated': Ironcliw_PRIME_AVAILABLE and self.jarvis_prime is not None
            },
            'performance': {
                'total_analyses': self.stats['total_analyses'],
                'rust_accelerated_count': self.stats['rust_accelerated'],
                'cross_repo_syncs': self.stats['cross_repo_syncs'],
                'avg_processing_time_ms': round(self.stats['avg_processing_time_ms'], 2),
                'rust_acceleration_rate': round(
                    (self.stats['rust_accelerated'] / self.stats['total_analyses'] * 100)
                    if self.stats['total_analyses'] > 0 else 0.0,
                    2
                )
            }
        }

        # Rust component insights
        if self.rust_initialized:
            insights['rust_intelligence'] = {
                'pattern_count': self.rust_pattern_matcher.pattern_count() if self.rust_pattern_matcher else 0,
                'state_count': self.rust_state_detector.state_count() if self.rust_state_detector else 0,
                'memory_pool_stats': self.rust_memory_pool.get_stats() if self.rust_memory_pool else "N/A"
            }

        # VSMS Core specific insights
        if self.vsms_core:
            vsms_insights = self.vsms_core.get_insights()
            insights['vsms_summary'] = {
                'tracked_applications': vsms_insights.get('tracked_applications', 0),
                'total_states': vsms_insights.get('total_states', 0),
                'personalization_score': vsms_insights.get('personalization_score', 0.0),
                'stuck_states': vsms_insights.get('stuck_states', []),
                'preferred_states': vsms_insights.get('preferred_states', [])
            }

        return insights
    
    def save_learned_states(self):
        """
        Save learned states from all components
        ENHANCED: Includes Rust state persistence
        """
        saved_components = []

        # Save Python VSMS
        if self.vsms:
            try:
                self.vsms.save_all_states()
                saved_components.append('python_vsms')
            except Exception as e:
                logger.error(f"Failed to save Python VSMS: {e}")

        # Save VSMS Core state
        if self.vsms_core:
            try:
                self.vsms_core.state_history.save_to_disk()
                self.vsms_core._save_state_definitions()
                if hasattr(self.vsms_core, 'state_intelligence'):
                    self.vsms_core.state_intelligence._save_intelligence_data()
                saved_components.append('vsms_core')
            except Exception as e:
                logger.error(f"Failed to save VSMS Core: {e}")

        # Save Rust learned patterns and states
        if self.rust_initialized:
            try:
                # Rust components maintain their state in memory
                # Pattern matcher and state detector automatically persist via references
                saved_components.append('rust_intelligence')
                logger.info(f"✅ Rust intelligence state preserved ({self.rust_pattern_matcher.pattern_count()} patterns, {self.rust_state_detector.state_count()} states)")
            except Exception as e:
                logger.error(f"Failed to save Rust state: {e}")

        logger.info(f"Saved states from components: {saved_components}")


# Convenience functions
_bridge_instance = None

def get_vision_intelligence_bridge() -> VisionIntelligenceBridge:
    """Get or create the global bridge instance"""
    global _bridge_instance
    if _bridge_instance is None:
        _bridge_instance = VisionIntelligenceBridge()
    return _bridge_instance

async def analyze_screenshot(screenshot: Union[bytes, np.ndarray], 
                           app_id: str,
                           metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """Convenience function to analyze screenshot"""
    bridge = get_vision_intelligence_bridge()
    return await bridge.analyze_visual_state(screenshot, app_id, metadata)