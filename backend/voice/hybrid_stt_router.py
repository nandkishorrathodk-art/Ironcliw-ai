"""
Ultra-Advanced Hybrid STT Router v3.0
=====================================
Zero hardcoding, fully async, RAM-aware, cost-optimized
Integrates with learning database for continuous improvement

PERFORMANCE OPTIMIZATIONS:
- Model prewarming during initialization (non-blocking)
- Whisper model caching with singleton pattern
- Speaker ID removed from transcription path (parallel, not serial)
- VAD/windowing pipeline caching
- Granular timeout protection at each stage
- Advanced circuit breaker pattern with half-open state
- Health monitoring with automatic recovery
- Adaptive timeouts based on system load
- Exponential backoff retry logic
- Connection pool management
"""

import asyncio
import logging
import os
import re
import time
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Callable, Dict, List, Optional, Tuple
from functools import wraps

import psutil

from .stt_config import ModelConfig, RoutingStrategy, STTEngine, get_stt_config

logger = logging.getLogger(__name__)


# =============================================================================
# DYNAMIC CONFIGURATION - Load from environment with sensible defaults
# =============================================================================
class DynamicTimeoutConfig:
    """
    Dynamic timeout configuration that adapts to system conditions.
    All values can be overridden via environment variables.
    """

    def __init__(self):
        self._base_config = {
            'model_prewarm': float(os.getenv('STT_PREWARM_TIMEOUT', '15.0')),
            'transcription': float(os.getenv('STT_TRANSCRIPTION_TIMEOUT', '10.0')),
            'fallback': float(os.getenv('STT_FALLBACK_TIMEOUT', '5.0')),
            'vad': float(os.getenv('STT_VAD_TIMEOUT', '2.0')),
            'speaker_id': float(os.getenv('STT_SPEAKER_ID_TIMEOUT', '3.0')),
            'fast_path': float(os.getenv('STT_FAST_PATH_TIMEOUT', '3.0')),
        }
        self._load_multiplier = 1.0
        self._last_calibration = 0.0
        self._calibration_interval = 30.0  # Recalibrate every 30 seconds

    def get_timeout(self, operation: str, urgency: str = 'normal') -> float:
        """
        Get adaptive timeout based on operation type, system load, and urgency.

        Args:
            operation: Type of operation (model_prewarm, transcription, etc.)
            urgency: 'critical' (0.5x), 'normal' (1x), 'relaxed' (2x)
        """
        base = self._base_config.get(operation, 5.0)

        # Apply load-based adjustment
        self._maybe_recalibrate()
        adjusted = base * self._load_multiplier

        # Apply urgency modifier
        urgency_multipliers = {'critical': 0.6, 'normal': 1.0, 'relaxed': 2.0}
        adjusted *= urgency_multipliers.get(urgency, 1.0)

        # Enforce reasonable bounds
        return max(1.0, min(adjusted, 60.0))

    def _maybe_recalibrate(self):
        """Recalibrate load multiplier if enough time has passed."""
        now = time.time()
        if now - self._last_calibration > self._calibration_interval:
            self._recalibrate_for_load()
            self._last_calibration = now

    def _recalibrate_for_load(self):
        """Adjust timeouts based on current system load."""
        try:
            cpu = psutil.cpu_percent(interval=0.1)
            mem = psutil.virtual_memory()

            # High CPU (>80%) or low memory (<20% available) = extend timeouts
            if cpu > 80 or mem.percent > 80:
                self._load_multiplier = 1.5
            elif cpu > 60 or mem.percent > 60:
                self._load_multiplier = 1.2
            else:
                self._load_multiplier = 1.0

            logger.debug(f"Timeout calibration: CPU={cpu:.0f}%, MEM={mem.percent:.0f}%, multiplier={self._load_multiplier}")
        except Exception:
            self._load_multiplier = 1.0


# Global dynamic config instance
_timeout_config = DynamicTimeoutConfig()


def get_timeout(operation: str, urgency: str = 'normal') -> float:
    """Get adaptive timeout for an operation."""
    return _timeout_config.get_timeout(operation, urgency)


# Legacy constants for backwards compatibility (use get_timeout() instead)
MODEL_PREWARM_TIMEOUT = 15.0
TRANSCRIPTION_TIMEOUT = 10.0
FALLBACK_TIMEOUT = 5.0
VAD_TIMEOUT = 2.0
SPEAKER_ID_TIMEOUT = 3.0


# =============================================================================
# ADVANCED CIRCUIT BREAKER WITH HALF-OPEN STATE
# =============================================================================
class CircuitState(Enum):
    """Circuit breaker states."""
    CLOSED = "closed"      # Normal operation
    OPEN = "open"          # Failing, reject requests
    HALF_OPEN = "half_open"  # Testing if recovered


@dataclass
class CircuitBreakerStats:
    """Statistics for a circuit breaker."""
    total_calls: int = 0
    successful_calls: int = 0
    failed_calls: int = 0
    rejected_calls: int = 0
    last_failure_time: float = 0.0
    last_success_time: float = 0.0
    consecutive_failures: int = 0
    consecutive_successes: int = 0
    state_changes: int = 0


class AdvancedCircuitBreaker:
    """
    Advanced circuit breaker with half-open state and adaptive thresholds.

    Features:
    - Three states: CLOSED (normal), OPEN (failing), HALF_OPEN (testing)
    - Adaptive failure threshold based on recent success rate
    - Exponential backoff for retry timing
    - Health score tracking for monitoring
    - Automatic recovery with gradual traffic increase
    """

    def __init__(
        self,
        name: str,
        failure_threshold: int = 3,
        recovery_timeout: float = 30.0,
        half_open_max_calls: int = 3,
        success_threshold: int = 2,
    ):
        self.name = name
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.half_open_max_calls = half_open_max_calls
        self.success_threshold = success_threshold

        self.state = CircuitState.CLOSED
        self.stats = CircuitBreakerStats()
        self._half_open_calls = 0
        self._lock = asyncio.Lock()

        # Exponential backoff
        self._backoff_multiplier = 1.0
        self._max_backoff_multiplier = 8.0

    @property
    def health_score(self) -> float:
        """Calculate health score (0.0 to 1.0) based on recent performance."""
        total = self.stats.successful_calls + self.stats.failed_calls
        if total == 0:
            return 1.0
        return self.stats.successful_calls / total

    @property
    def is_available(self) -> bool:
        """Check if circuit allows requests."""
        if self.state == CircuitState.CLOSED:
            return True
        elif self.state == CircuitState.OPEN:
            # Check if recovery timeout has passed
            elapsed = time.time() - self.stats.last_failure_time
            if elapsed >= self.recovery_timeout * self._backoff_multiplier:
                return True  # Allow transition to half-open
            return False
        else:  # HALF_OPEN
            return self._half_open_calls < self.half_open_max_calls

    async def call(self, func: Callable, *args, **kwargs) -> Any:
        """Execute function with circuit breaker protection."""
        async with self._lock:
            if not self.is_available:
                self.stats.rejected_calls += 1
                raise CircuitBreakerOpenError(f"Circuit {self.name} is OPEN")

            # Transition OPEN -> HALF_OPEN on first call after timeout
            if self.state == CircuitState.OPEN:
                self._transition_to_half_open()

        # Execute the call
        self.stats.total_calls += 1
        try:
            if asyncio.iscoroutinefunction(func):
                result = await func(*args, **kwargs)
            else:
                result = await asyncio.to_thread(func, *args, **kwargs)

            await self._record_success()
            return result

        except Exception as e:
            await self._record_failure()
            raise

    async def _record_success(self):
        """Record a successful call."""
        async with self._lock:
            self.stats.successful_calls += 1
            self.stats.last_success_time = time.time()
            self.stats.consecutive_successes += 1
            self.stats.consecutive_failures = 0

            if self.state == CircuitState.HALF_OPEN:
                self._half_open_calls += 1
                if self.stats.consecutive_successes >= self.success_threshold:
                    self._transition_to_closed()

    async def _record_failure(self):
        """Record a failed call."""
        async with self._lock:
            self.stats.failed_calls += 1
            self.stats.last_failure_time = time.time()
            self.stats.consecutive_failures += 1
            self.stats.consecutive_successes = 0

            if self.state == CircuitState.HALF_OPEN:
                # Immediate transition back to OPEN on failure during half-open
                self._transition_to_open()
            elif self.stats.consecutive_failures >= self.failure_threshold:
                self._transition_to_open()

    def _transition_to_open(self):
        """Transition to OPEN state."""
        if self.state != CircuitState.OPEN:
            logger.warning(f"ğŸ”´ Circuit breaker {self.name}: OPEN (failures: {self.stats.consecutive_failures})")
            self.state = CircuitState.OPEN
            self.stats.state_changes += 1
            self._half_open_calls = 0

            # Increase backoff for repeated failures
            self._backoff_multiplier = min(
                self._backoff_multiplier * 1.5,
                self._max_backoff_multiplier
            )

    def _transition_to_half_open(self):
        """Transition to HALF_OPEN state."""
        logger.info(f"ğŸŸ¡ Circuit breaker {self.name}: HALF_OPEN (testing recovery)")
        self.state = CircuitState.HALF_OPEN
        self.stats.state_changes += 1
        self._half_open_calls = 0

    def _transition_to_closed(self):
        """Transition to CLOSED state."""
        logger.info(f"ğŸŸ¢ Circuit breaker {self.name}: CLOSED (recovered)")
        self.state = CircuitState.CLOSED
        self.stats.state_changes += 1
        self._backoff_multiplier = 1.0  # Reset backoff
        self._half_open_calls = 0

    def reset(self):
        """Force reset the circuit breaker."""
        self.state = CircuitState.CLOSED
        self.stats = CircuitBreakerStats()
        self._half_open_calls = 0
        self._backoff_multiplier = 1.0
        logger.info(f"Circuit breaker {self.name} manually reset")

    def to_dict(self) -> Dict[str, Any]:
        """Export circuit breaker state for monitoring."""
        return {
            'name': self.name,
            'state': self.state.value,
            'health_score': self.health_score,
            'is_available': self.is_available,
            'stats': {
                'total_calls': self.stats.total_calls,
                'successful_calls': self.stats.successful_calls,
                'failed_calls': self.stats.failed_calls,
                'rejected_calls': self.stats.rejected_calls,
                'consecutive_failures': self.stats.consecutive_failures,
                'state_changes': self.stats.state_changes,
            },
            'backoff_multiplier': self._backoff_multiplier,
        }


class CircuitBreakerOpenError(Exception):
    """Raised when circuit breaker is open and rejects the call."""
    pass


# =============================================================================
# RETRY DECORATOR WITH EXPONENTIAL BACKOFF
# =============================================================================
def async_retry(
    max_attempts: int = 3,
    base_delay: float = 0.5,
    max_delay: float = 10.0,
    exponential_base: float = 2.0,
    exceptions: Tuple = (Exception,),
):
    """
    Async retry decorator with exponential backoff.

    Args:
        max_attempts: Maximum number of retry attempts
        base_delay: Initial delay between retries (seconds)
        max_delay: Maximum delay between retries (seconds)
        exponential_base: Base for exponential backoff
        exceptions: Tuple of exceptions to catch and retry
    """
    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            last_exception = None

            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e

                    if attempt < max_attempts - 1:
                        delay = min(base_delay * (exponential_base ** attempt), max_delay)
                        logger.warning(
                            f"Retry {attempt + 1}/{max_attempts} for {func.__name__} "
                            f"after {delay:.1f}s: {e}"
                        )
                        await asyncio.sleep(delay)
                    else:
                        logger.error(f"All {max_attempts} attempts failed for {func.__name__}: {e}")

            raise last_exception

        return wrapper
    return decorator


# =============================================================================
# HEALTH MONITORING
# =============================================================================
@dataclass
class HealthStatus:
    """Health status for the STT router."""
    healthy: bool
    score: float  # 0.0 to 1.0
    components: Dict[str, Dict[str, Any]]
    last_check: datetime
    message: str


@dataclass
class STTResult:
    """Result from STT engine"""

    text: str
    confidence: float
    engine: STTEngine
    model_name: str
    latency_ms: float
    audio_duration_ms: float
    metadata: Dict = field(default_factory=dict)
    audio_hash: Optional[str] = None
    speaker_identified: Optional[str] = None
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class SystemResources:
    """Current system resource availability"""

    total_ram_gb: float
    available_ram_gb: float
    ram_percent_used: float
    cpu_percent: float
    gpu_available: bool
    gpu_memory_gb: float = 0.0
    network_available: bool = True


class HybridSTTRouter:
    """
    Ultra-intelligent STT routing system v3.0.

    Features:
    - Zero hardcoding (all config-driven, environment overrideable)
    - Fully async (non-blocking with timeout protection everywhere)
    - RAM-aware (adapts to available resources dynamically)
    - Cost-optimized (prefers local, escalates smartly)
    - Learning-enabled (gets better over time via ML database)
    - Multi-engine (Wav2Vec, Vosk, Whisper local/GCP)
    - Speaker-aware (Derek gets priority routing)
    - Confidence-based escalation with adaptive thresholds
    - Advanced circuit breakers with half-open state
    - Health monitoring and automatic recovery
    - Retry logic with exponential backoff
    - Adaptive timeouts based on system load
    """

    def __init__(self, config=None):
        self.config = config or get_stt_config()
        self.engines = {}  # Lazy-loaded STT engines
        self.performance_stats = {}  # Track engine performance
        self.learning_db = None  # Lazy-loaded learning database

        # Performance tracking
        self.total_requests = 0
        self.cloud_requests = 0
        self.cache_hits = 0
        self._start_time = time.time()

        # Available engines (lazy-loaded)
        self.available_engines = {}
        self._initialized = False

        # Model prewarming state
        self._whisper_prewarmed = False
        self._whisper_handler = None  # Cached WhisperAudioHandler instance
        self._prewarm_lock = asyncio.Lock()  # Prevent concurrent prewarm attempts

        # Advanced circuit breakers (one per engine type)
        self._circuit_breakers: Dict[str, AdvancedCircuitBreaker] = {
            'whisper_local': AdvancedCircuitBreaker(
                name='whisper_local',
                failure_threshold=3,
                recovery_timeout=30.0,
            ),
            'whisper_fallback': AdvancedCircuitBreaker(
                name='whisper_fallback',
                failure_threshold=2,
                recovery_timeout=45.0,
            ),
            'vosk': AdvancedCircuitBreaker(
                name='vosk',
                failure_threshold=3,
                recovery_timeout=20.0,
            ),
            'google_cloud': AdvancedCircuitBreaker(
                name='google_cloud',
                failure_threshold=2,
                recovery_timeout=60.0,
            ),
            'speechbrain': AdvancedCircuitBreaker(
                name='speechbrain',
                failure_threshold=3,
                recovery_timeout=30.0,
            ),
        }

        # Legacy circuit breaker tracking (for backwards compatibility)
        self._circuit_breaker_failures = {}
        self._circuit_breaker_last_failure = {}
        self._circuit_breaker_threshold = 3
        self._circuit_breaker_timeout = 60

        # Health monitoring
        self._last_health_check: Optional[HealthStatus] = None
        self._health_check_interval = 60.0  # seconds
        self._last_health_check_time = 0.0

        # Request rate limiting
        self._request_times: List[float] = []
        self._max_requests_per_second = float(os.getenv('STT_MAX_RPS', '10'))

        logger.info("ğŸ¤ Hybrid STT Router v3.0 initialized")
        logger.info(f"   Strategy: {self.config.default_strategy.value}")
        logger.info(f"   Models configured: {len(self.config.models)}")
        logger.info(f"   Circuit breakers: {len(self._circuit_breakers)}")

    # =============================================================================
    # INTENT-AWARE CONSENSUS (Screen lock/unlock disambiguation)
    # =============================================================================
    @staticmethod
    def _tokenize_words(text: str) -> List[str]:
        """Tokenize into lowercase word tokens (avoids substring pitfalls like 'unlock' containing 'lock')."""
        if not text:
            return []
        return re.findall(r"[a-z']+", text.lower())

    @classmethod
    def _extract_screen_intent(cls, text: str) -> Optional[str]:
        """Return 'lock', 'unlock', or None based on token-level intent detection."""
        tokens = set(cls._tokenize_words(text))
        if "unlock" in tokens:
            return "unlock"
        if "lock" in tokens:
            return "lock"
        return None

    def _select_diverse_local_models(
        self,
        resources: "SystemResources",
        exclude_engine: Optional[STTEngine],
        max_models: int = 2,
    ) -> List[ModelConfig]:
        """
        Pick a small set of diverse *local* models for fast consensus.

        Config-driven (no hardcoded model names) and tries to avoid reusing the same engine
        as the primary model whenever possible.
        """
        candidates: List[ModelConfig] = []
        for model in self.config.models.values():
            if model.requires_internet:
                continue
            if exclude_engine and model.engine == exclude_engine:
                continue
            if resources.available_ram_gb < model.ram_required_gb:
                continue
            # Keep consensus fast: respect configured local latency budget when available
            if getattr(model, "avg_latency_ms", 0.0) and model.avg_latency_ms > self.config.max_local_latency_ms:
                continue
            candidates.append(model)

        def score(m: ModelConfig) -> float:
            # Prefer accuracy, lightly penalize latency
            return (m.expected_accuracy or 0.0) - (m.avg_latency_ms or 0.0) / 1000.0

        candidates.sort(key=score, reverse=True)
        return candidates[:max_models]

    async def _apply_screen_intent_consensus(
        self,
        audio_data: bytes,
        current: "STTResult",
        resources: "SystemResources",
        primary_model: Optional[ModelConfig],
    ) -> "STTResult":
        """
        If transcription indicates a screen lock/unlock intent, run a fast, parallel
        multi-engine consensus to reduce "lock" â†” "unlock" confusions.
        """
        intent = self._extract_screen_intent(current.text)
        if intent not in ("lock", "unlock"):
            return current

        consensus_enabled = os.getenv("JARVIS_STT_SCREEN_CONSENSUS", "true").lower() == "true"
        if not consensus_enabled:
            current.metadata = current.metadata or {}
            current.metadata["screen_intent"] = intent
            current.metadata["screen_intent_consensus"] = {"enabled": False}
            return current

        try:
            timeout_sec = float(os.getenv("JARVIS_STT_SCREEN_CONSENSUS_TIMEOUT_SEC", "1.8"))
        except ValueError:
            timeout_sec = 1.8

        exclude_engine = primary_model.engine if primary_model else current.engine
        extra_models = self._select_diverse_local_models(
            resources=resources, exclude_engine=exclude_engine, max_models=2
        )

        if not extra_models:
            current.metadata = current.metadata or {}
            current.metadata["screen_intent"] = intent
            current.metadata["screen_intent_consensus"] = {"enabled": True, "skipped": "no_diverse_models"}
            return current

        tasks = [
            self._transcribe_with_engine(audio_data, m, timeout_sec=timeout_sec) for m in extra_models
        ]
        gathered = await asyncio.gather(*tasks, return_exceptions=True)

        alternatives: List["STTResult"] = [current]
        for r in gathered:
            if isinstance(r, STTResult) and r.text:
                alternatives.append(r)

        votes: Dict[str, List["STTResult"]] = {"lock": [], "unlock": []}
        for r in alternatives:
            r_intent = self._extract_screen_intent(r.text)
            if r_intent in ("lock", "unlock"):
                votes[r_intent].append(r)

        chosen = current
        chosen_intent = intent

        lock_votes = len(votes["lock"])
        unlock_votes = len(votes["unlock"])
        if lock_votes or unlock_votes:
            if lock_votes != unlock_votes:
                majority_intent = "lock" if lock_votes > unlock_votes else "unlock"
                chosen = max(votes[majority_intent], key=lambda x: x.confidence)
                chosen_intent = majority_intent
            else:
                combined = votes["lock"] + votes["unlock"]
                chosen = max(combined, key=lambda x: x.confidence)
                chosen_intent = self._extract_screen_intent(chosen.text) or intent

        chosen.metadata = chosen.metadata or {}
        chosen.metadata["screen_intent"] = chosen_intent
        chosen.metadata["screen_intent_consensus"] = {
            "enabled": True,
            "timeout_sec": timeout_sec,
            "votes": {"lock": lock_votes, "unlock": unlock_votes},
            "candidates": [
                {
                    "engine": getattr(r.engine, "value", str(r.engine)),
                    "model": getattr(r, "model_name", None),
                    "text": r.text,
                    "confidence": r.confidence,
                    "intent": self._extract_screen_intent(r.text),
                }
                for r in alternatives
            ],
            "chosen": {
                "engine": getattr(chosen.engine, "value", str(chosen.engine)),
                "model": chosen.model_name,
                "text": chosen.text,
                "confidence": chosen.confidence,
                "intent": chosen_intent,
            },
        }

        return chosen

    async def initialize(self) -> bool:
        """
        Async initialization - loads engines and connects to learning DB.

        PERFORMANCE OPTIMIZATIONS:
        - Parallel initialization of database and engine discovery
        - Model prewarming (Whisper) in background to eliminate first-request latency
        - Graceful degradation if prewarm fails

        Returns:
            True if initialization succeeded, False otherwise.
        """
        if self._initialized:
            return True

        try:
            init_start = time.time()

            # PARALLEL INIT: Database connection + engine discovery + model prewarm
            await asyncio.gather(
                self._get_learning_db(),
                self._discover_engines(),
                self._prewarm_whisper_model(),  # Non-blocking prewarm
                return_exceptions=True  # Don't fail if one task fails
            )

            self._initialized = True
            init_time = (time.time() - init_start) * 1000
            logger.info(f"âœ… Hybrid STT Router fully initialized in {init_time:.0f}ms")
            logger.info(f"   Available engines: {list(self.available_engines.keys())}")
            logger.info(f"   Whisper prewarmed: {self._whisper_prewarmed}")
            return True
        except Exception as e:
            logger.error(f"âŒ Hybrid STT Router initialization failed: {e}")
            return False

    async def _prewarm_whisper_model(self):
        """
        Prewarm Whisper model to eliminate first-request latency.

        ROBUST ASYNC IMPLEMENTATION v4.0:
        - Integrates with advanced WhisperImportManager
        - Uses unified circuit breaker from import manager
        - Non-blocking with adaptive timeout based on system load
        - Graceful degradation on failure (service continues without prewarm)
        - Background completion handler for timeout cases
        - Cancellation-safe with proper cleanup
        - Never blocks the voice unlock flow
        - Parallel-safe with proper locking
        - Health status tracking
        """
        async with self._prewarm_lock:
            if self._whisper_prewarmed:
                return

            prewarm_start = time.time()
            prewarm_task = None

            # Get adaptive timeout based on current system load
            timeout = get_timeout('model_prewarm', urgency='relaxed')

            try:
                # Import the advanced import manager
                from .whisper_audio_fix import (
                    get_import_manager, get_whisper_config, _whisper_handler
                )

                import_manager = get_import_manager()
                config = get_whisper_config()

                logger.info(f"ğŸ”¥ Prewarming Whisper model (async, timeout={timeout:.1f}s)...")
                logger.info(f"   Model: {config.model_size}, Config: dynamic from env")

                # Check import manager circuit breaker FIRST
                if not import_manager.circuit_breaker.is_available:
                    logger.warning(
                        f"âš ï¸ Whisper import circuit breaker OPEN - skipping prewarm. "
                        f"Last error: {import_manager.circuit_breaker.metrics.last_error}"
                    )
                    return

                # Also check router-level circuit breaker
                cb = self._circuit_breakers.get('whisper_local')
                if cb and not cb.is_available:
                    logger.warning("âš ï¸ Whisper router circuit breaker OPEN - skipping prewarm")
                    return

                # Create a cancellable task for the prewarm operation
                async def _do_prewarm():
                    # This uses the advanced import manager internally
                    await _whisper_handler.load_model_async(timeout=timeout)
                    return _whisper_handler

                prewarm_task = asyncio.create_task(_do_prewarm())

                # Wait with strict timeout - shield prevents cancellation propagation
                self._whisper_handler = await asyncio.wait_for(
                    asyncio.shield(prewarm_task),
                    timeout=timeout
                )
                self._whisper_prewarmed = True

                prewarm_time = (time.time() - prewarm_start) * 1000

                # Log success with import manager status
                status = import_manager.get_health_status()
                logger.info(
                    f"âœ… Whisper model prewarmed in {prewarm_time:.0f}ms "
                    f"(import: {status['status'].get('import_time_ms', 0):.0f}ms, "
                    f"load: {status['status'].get('load_time_ms', 0):.0f}ms)"
                )

                # Record success in router circuit breaker
                if cb:
                    await cb._record_success()

            except asyncio.TimeoutError:
                elapsed = (time.time() - prewarm_start) * 1000
                logger.warning(
                    f"â±ï¸ Whisper prewarm timed out after {elapsed:.0f}ms "
                    f"(continuing without prewarm - will load on first use)"
                )
                # Let background task complete for future requests
                if prewarm_task and not prewarm_task.done():
                    prewarm_task.add_done_callback(self._handle_background_prewarm)

            except asyncio.CancelledError:
                logger.info("ğŸš« Whisper prewarm cancelled")
                if prewarm_task and not prewarm_task.done():
                    prewarm_task.cancel()
                raise

            except Exception as e:
                elapsed = (time.time() - prewarm_start) * 1000
                error_msg = str(e)

                # Check for circuit breaker errors
                if "circuit breaker" in error_msg.lower():
                    logger.warning(f"âš ï¸ Whisper prewarm blocked by circuit breaker after {elapsed:.0f}ms: {e}")
                # Check for known numba circular import issue
                elif "circular import" in error_msg or "numba" in error_msg.lower() or "get_hashable_key" in error_msg:
                    logger.warning(
                        f"âš ï¸ Whisper prewarm failed after {elapsed:.0f}ms due to numba issue: {e}. "
                        "Try: pip install --upgrade numba llvmlite"
                    )
                else:
                    logger.warning(f"âš ï¸ Whisper prewarm failed after {elapsed:.0f}ms: {e}")

                # Record failure in router circuit breaker
                cb = self._circuit_breakers.get('whisper_local')
                if cb:
                    await cb._record_failure()

    def _handle_background_prewarm(self, task: asyncio.Task):
        """Handle background prewarm completion after timeout."""
        try:
            if task.cancelled() or task.exception():
                return
            result = task.result()
            if result and not self._whisper_prewarmed:
                self._whisper_handler = result
                self._whisper_prewarmed = True
                logger.info("âœ… Whisper prewarmed (background completion)")
        except Exception:
            pass  # Silently ignore background failures

    def _check_circuit_breaker(self, engine_name: str) -> bool:
        """
        Check if circuit breaker allows operation for given engine.

        Returns:
            True if operation is allowed, False if circuit is open
        """
        current_time = time.time()

        if engine_name in self._circuit_breaker_failures:
            failures = self._circuit_breaker_failures[engine_name]
            last_failure = self._circuit_breaker_last_failure.get(engine_name, 0)

            if failures >= self._circuit_breaker_threshold:
                if current_time - last_failure < self._circuit_breaker_timeout:
                    logger.debug(f"ğŸ”´ Circuit breaker OPEN for {engine_name}")
                    return False
                else:
                    # Reset after timeout
                    self._circuit_breaker_failures[engine_name] = 0
                    logger.info(f"ğŸŸ¢ Circuit breaker RESET for {engine_name}")

        return True

    def _record_circuit_breaker_failure(self, engine_name: str):
        """Record a failure for circuit breaker"""
        self._circuit_breaker_failures[engine_name] = \
            self._circuit_breaker_failures.get(engine_name, 0) + 1
        self._circuit_breaker_last_failure[engine_name] = time.time()

    def _record_circuit_breaker_success(self, engine_name: str):
        """Record a success - reset failure count"""
        if engine_name in self._circuit_breaker_failures:
            self._circuit_breaker_failures[engine_name] = 0

    async def _discover_engines(self):
        """Discover and validate available STT engines."""
        discovered = {}

        # Check Vosk (local, fast, low resource)
        try:
            from vosk import Model
            discovered['vosk'] = {
                'type': 'local',
                'loaded': False,
                'ram_required_gb': 0.5
            }
            logger.info("   âœ“ Vosk engine available")
        except ImportError:
            logger.debug("   âœ— Vosk not available")

        # Check Whisper (local, accurate, medium resource)
        # Uses the advanced WhisperImportManager with circuit breaker and retry logic
        try:
            from .whisper_audio_fix import get_import_manager, get_whisper_config

            import_manager = get_import_manager()

            # Check if circuit breaker allows attempt
            if not import_manager.circuit_breaker.is_available:
                logger.warning(
                    f"   âš ï¸ Whisper circuit breaker OPEN - skipping discovery. "
                    f"Last error: {import_manager.circuit_breaker.metrics.last_error}"
                )
            else:
                # Use synchronous import (discovery runs at startup)
                whisper = import_manager.import_sync()

                # Get config for RAM estimation
                config = get_whisper_config()
                model_size = config.model_size
                ram_estimates = {
                    'tiny': 1.0, 'base': 1.5, 'small': 2.5,
                    'medium': 5.0, 'large': 10.0, 'large-v2': 10.0, 'large-v3': 10.0
                }
                ram_required = ram_estimates.get(model_size, 2.0)

                discovered['whisper_local'] = {
                    'type': 'local',
                    'loaded': False,
                    'ram_required_gb': ram_required,
                    'model_size': model_size,
                    'import_manager_status': import_manager.status.__dict__
                }
                logger.info(f"   âœ“ Whisper (local) engine available (model: {model_size}, RAM: {ram_required}GB)")

        except ImportError as e:
            error_msg = str(e)
            if "circuit breaker" in error_msg.lower():
                logger.warning(f"   âš ï¸ Whisper blocked by circuit breaker: {e}")
            elif "circular import" in error_msg or "numba" in error_msg.lower() or "get_hashable_key" in error_msg:
                logger.warning(
                    f"   âš ï¸ Whisper unavailable due to numba issue: {e}. "
                    "Try: pip install --upgrade numba llvmlite"
                )
            else:
                logger.debug(f"   âœ— Whisper local not available: {e}")
        except Exception as e:
            logger.warning(f"   âš ï¸ Whisper local discovery failed: {e}")

        # Check Google Cloud STT (cloud, high accuracy)
        try:
            from google.cloud import speech_v1
            discovered['google_cloud'] = {
                'type': 'cloud',
                'loaded': True,
                'ram_required_gb': 0.1
            }
            logger.info("   âœ“ Google Cloud STT available")
        except ImportError:
            logger.debug("   âœ— Google Cloud STT not available")

        # Check SpeechBrain (local, speaker-aware)
        try:
            from speechbrain.inference.interfaces import Pretrained
            discovered['speechbrain'] = {
                'type': 'local',
                'loaded': False,
                'ram_required_gb': 1.5
            }
            logger.info("   âœ“ SpeechBrain engine available")
        except ImportError:
            logger.debug("   âœ— SpeechBrain not available")

        self.available_engines = discovered

    async def _get_learning_db(self):
        """Lazy-load learning database"""
        if self.learning_db is None:
            try:
                from intelligence.learning_database import get_learning_database

                self.learning_db = await get_learning_database()
                logger.info("ğŸ“š Learning database connected to STT router")
            except Exception as e:
                logger.error(f"Failed to connect learning database: {e}")
                self.learning_db = None
        return self.learning_db

    def _get_system_resources(self) -> SystemResources:
        """Get current system resource availability"""
        mem = psutil.virtual_memory()
        cpu_percent = psutil.cpu_percent(interval=0.1)

        # Check for GPU (Metal on macOS)
        gpu_available = False
        gpu_memory_gb = 0.0
        try:
            import torch

            if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
                gpu_available = True
                # Estimate Metal shared memory (uses system RAM)
                gpu_memory_gb = mem.available / (1024**3) * 0.5  # Estimate 50% shareable
        except ImportError:
            pass

        # Check network
        network_available = True
        try:
            import socket

            socket.create_connection(("8.8.8.8", 53), timeout=1)
        except OSError:
            network_available = False

        return SystemResources(
            total_ram_gb=mem.total / (1024**3),
            available_ram_gb=mem.available / (1024**3),
            ram_percent_used=mem.percent,
            cpu_percent=cpu_percent,
            gpu_available=gpu_available,
            gpu_memory_gb=gpu_memory_gb,
            network_available=network_available,
        )

    def _select_optimal_model(
        self,
        resources: SystemResources,
        strategy: RoutingStrategy,
        speaker_name: Optional[str] = None,
    ) -> ModelConfig:
        """
        Intelligently select best model based on:
        - Available resources
        - Strategy
        - Speaker priority
        - Historical performance
        """
        available_ram = resources.available_ram_gb

        # WHISPER PRIORITY: Always try Whisper first if available
        # This ensures proper transcription instead of [transcription failed]
        whisper_models = ["whisper-base", "whisper-small", "whisper-tiny"]
        for whisper_name in whisper_models:
            whisper_model = self.config.models.get(whisper_name)
            if whisper_model and whisper_model.ram_required_gb <= available_ram:
                logger.info(f"ğŸ¯ Whisper priority: selected {whisper_name} for reliable transcription")
                return whisper_model

        if strategy == RoutingStrategy.SPEED:
            # Fastest model that fits
            model = self.config.get_fastest_model(available_ram)
            if model:
                logger.debug(f"ğŸƒ Speed strategy: selected {model.name}")
                return model

        elif strategy == RoutingStrategy.ACCURACY:
            # Best accuracy (may use cloud)
            if speaker_name in self.config.priority_speakers or resources.network_available:
                model = self.config.get_most_accurate_model(available_ram)
                logger.debug(f"ğŸ¯ Accuracy strategy: selected {model.name}")
                return model

        elif strategy == RoutingStrategy.COST:
            # Minimize cloud usage
            model = self.config.get_model_for_ram(available_ram)
            if model and not model.requires_internet:
                logger.debug(f"ğŸ’° Cost strategy: selected {model.name}")
                return model

        elif strategy == RoutingStrategy.BALANCED or strategy == RoutingStrategy.ADAPTIVE:
            # Smart selection based on context
            if available_ram >= self.config.min_ram_for_wav2vec:
                # Prefer Wav2Vec (fine-tunable on Derek)
                model = self.config.models.get("wav2vec2-base")
                if model and model.ram_required_gb <= available_ram:
                    logger.debug(f"âš–ï¸  Balanced strategy: selected {model.name}")
                    return model

            # Fallback to Vosk if RAM is tight
            model = self.config.models.get("vosk-small")
            if model:
                logger.debug(f"âš–ï¸  Balanced strategy (RAM constrained): selected {model.name}")
                return model

        # Ultimate fallback: smallest model
        return self.config.get_fastest_model(100.0)  # Get ANY model

    async def _load_engine(self, model: ModelConfig):
        """Lazy-load STT engine"""
        engine_key = f"{model.engine.value}:{model.name}"

        if engine_key in self.engines:
            return self.engines[engine_key]

        logger.info(f"ğŸ”§ Loading STT engine: {model.name} ({model.engine.value})")

        try:
            if model.engine == STTEngine.WAV2VEC:
                from .engines.wav2vec_engine import Wav2VecEngine

                engine = Wav2VecEngine(model)
                await engine.initialize()

            elif model.engine == STTEngine.VOSK:
                from .engines.vosk_engine import VoskEngine

                engine = VoskEngine(model)
                await engine.initialize()

            elif model.engine == STTEngine.WHISPER_LOCAL:
                from .engines.whisper_local_engine import WhisperLocalEngine

                engine = WhisperLocalEngine(model)
                await engine.initialize()

            elif model.engine == STTEngine.WHISPER_GCP:
                from .engines.whisper_gcp_engine import WhisperGCPEngine

                engine = WhisperGCPEngine(model)
                await engine.initialize()

            elif model.engine == STTEngine.SPEECHBRAIN:
                from .engines.speechbrain_engine import SpeechBrainEngine

                engine = SpeechBrainEngine(model)
                await engine.initialize()

            else:
                raise ValueError(f"Unknown engine: {model.engine}")

            self.engines[engine_key] = engine
            logger.info(f"âœ… Engine loaded: {model.name}")
            return engine

        except Exception as e:
            logger.error(f"Failed to load engine {model.name}: {e}")
            return None

    async def _transcribe_with_engine(
        self, audio_data: bytes, model: ModelConfig, timeout_sec: float = 10.0
    ) -> Optional[STTResult]:
        """Transcribe audio with specific engine (with timeout)"""
        start_time = time.time()

        try:
            engine = await self._load_engine(model)
            if engine is None:
                return None

            # Transcribe with timeout
            result = await asyncio.wait_for(engine.transcribe(audio_data), timeout=timeout_sec)

            latency_ms = (time.time() - start_time) * 1000

            # Update performance stats
            if model.name not in self.performance_stats:
                self.performance_stats[model.name] = {
                    "total_requests": 0,
                    "total_latency_ms": 0,
                    "avg_confidence": 0,
                }

            stats = self.performance_stats[model.name]
            stats["total_requests"] += 1
            stats["total_latency_ms"] += latency_ms
            stats["avg_latency_ms"] = stats["total_latency_ms"] / stats["total_requests"]

            logger.debug(
                f"ğŸ¤ {model.name}: '{result.text[:50]}...' (confidence={result.confidence:.2f}, latency={latency_ms:.0f}ms)"
            )

            return result

        except asyncio.TimeoutError:
            latency_ms = (time.time() - start_time) * 1000
            logger.warning(f"â±ï¸  {model.name} timed out after {latency_ms:.0f}ms")
            return None

        except Exception as e:
            logger.error(f"Error transcribing with {model.name}: {e}")
            return None

    async def _identify_speaker(self, audio_data: bytes) -> Optional[str]:
        """
        Identify speaker from voice using advanced speaker recognition.

        Returns speaker name if recognized, None if unknown.
        """
        try:
            from voice.speaker_recognition import get_speaker_recognition_engine

            speaker_engine = get_speaker_recognition_engine()
            await speaker_engine.initialize()

            # Identify speaker from audio
            speaker_name, confidence = await speaker_engine.identify_speaker(audio_data)

            if speaker_name:
                logger.info(f"ğŸ­ Speaker identified: {speaker_name} (confidence: {confidence:.2f})")

                # Check if this is the owner
                if speaker_engine.is_owner(speaker_name):
                    logger.info(f"ğŸ‘‘ Owner detected: {speaker_name}")

                return speaker_name
            else:
                logger.info(
                    f"ğŸ­ Unknown speaker (best confidence: {confidence:.2f}, threshold: {speaker_engine.recognition_threshold})"
                )
                return None

        except Exception as e:
            logger.error(f"Speaker identification failed: {e}")
            import traceback

            traceback.print_exc()
            return None

    async def _record_transcription(
        self, audio_data: bytes, result: STTResult, speaker_name: Optional[str] = None
    ) -> int:
        """Record transcription to learning database"""
        try:
            learning_db = await self._get_learning_db()
            if not learning_db:
                return -1

            # Calculate audio duration (estimate from bytes)
            audio_duration_ms = len(audio_data) / (16000 * 2) * 1000  # 16kHz, 16-bit

            transcription_id = await learning_db.record_voice_transcription(
                audio_data=audio_data,
                transcribed_text=result.text,
                confidence_score=result.confidence,
                audio_duration_ms=audio_duration_ms,
            )

            # Also record as voice sample for Derek if identified
            if speaker_name == "Derek J. Russell":
                await learning_db.record_voice_sample(
                    speaker_name=speaker_name,
                    audio_data=audio_data,
                    transcription=result.text,
                    audio_duration_ms=audio_duration_ms,
                    quality_score=result.confidence,
                )

            return transcription_id

        except Exception as e:
            logger.error(f"Failed to record transcription: {e}")
            return -1

    async def transcribe(
        self,
        audio_data: bytes,
        strategy: Optional[RoutingStrategy] = None,
        speaker_name: Optional[str] = None,
        context: Optional[Dict] = None,
        sample_rate: Optional[int] = None,
        mode: str = 'general',
        skip_speaker_id: bool = True,  # PERFORMANCE: Skip speaker ID by default (done separately)
        bypass_self_voice_check: bool = False,  # v8.0: Allow bypassing for known-clean audio
    ) -> STTResult:
        """
        Main transcription entry point with VAD/windowing mode support.

        PERFORMANCE OPTIMIZATIONS (v2.0):
        - Speaker identification REMOVED from critical path (done in parallel by voice unlock)
        - Uses prewarmed Whisper model when available
        - Circuit breaker prevents repeated failures from blocking
        - Granular timeout protection at each stage

        v8.0 SELF-VOICE SUPPRESSION:
        - Checks UnifiedSpeechStateManager BEFORE transcription
        - Rejects audio if JARVIS is speaking or in cooldown
        - Prevents hallucinations from JARVIS hearing its own voice

        Args:
            audio_data: Raw audio bytes
            strategy: Routing strategy (SPEED/ACCURACY/COST)
            speaker_name: Known speaker name (for priority routing)
            context: Additional context
            sample_rate: Optional sample rate from frontend
            mode: VAD/windowing mode ('general', 'unlock', 'command')
                  - 'general': 5s window, standard processing
                  - 'unlock': 2s window, ultra-fast
                  - 'command': 3s window, optimized for commands
            skip_speaker_id: Skip speaker identification for faster transcription (default: True)
                             Speaker ID should be done in parallel, not serial.
            bypass_self_voice_check: Skip self-voice check for pre-verified audio (default: False)

        Returns:
            STTResult with transcription text, confidence, and metadata
        """
        logger.info(f"ğŸ¤ Transcribe called: {len(audio_data)} bytes, mode={mode}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # v8.0: SELF-VOICE SUPPRESSION - CRITICAL CHECK
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # If JARVIS is currently speaking or in post-speech cooldown,
        # reject this audio to prevent transcribing JARVIS's own voice.
        # This is the FIRST LINE OF DEFENSE against self-voice hallucinations.
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if not bypass_self_voice_check:
            try:
                from core.unified_speech_state import get_speech_state_manager_sync
                speech_manager = get_speech_state_manager_sync()
                rejection = speech_manager.should_reject_audio()
                
                if rejection.reject:
                    logger.warning(
                        f"ğŸ”‡ [SELF-VOICE-STT] Rejecting transcription request - "
                        f"reason: {rejection.reason}, details: {rejection.details}"
                    )
                    # Return empty result with low confidence
                    return STTResult(
                        text="",
                        confidence=0.0,
                        engine="self_voice_suppression",
                        latency_ms=0,
                        metadata={
                            "rejected": True,
                            "rejection_reason": rejection.reason,
                            "rejection_details": rejection.details,
                        }
                    )
            except ImportError:
                # UnifiedSpeechStateManager not available - continue without check
                logger.debug("[SELF-VOICE-STT] Speech state manager not available")
            except Exception as e:
                # Non-fatal error - continue with transcription
                logger.debug(f"[SELF-VOICE-STT] Check error (non-fatal): {e}")

        self.total_requests += 1
        start_time = time.time()

        # Use configured strategy if not specified
        if strategy is None:
            strategy = self.config.default_strategy

        # Get current system resources (fast, ~100ms)
        resources = self._get_system_resources()
        logger.debug(
            f"ğŸ“Š Resources: RAM {resources.available_ram_gb:.1f}/{resources.total_ram_gb:.1f}GB, "
            f"CPU {resources.cpu_percent:.0f}%"
        )

        # PERFORMANCE FIX: Speaker identification is REMOVED from transcription path
        # It was adding 3-10+ seconds of latency on every transcription request.
        # Speaker ID is now done in PARALLEL by the voice unlock service, not in serial here.
        # If speaker_name is needed, the caller should provide it or do parallel speaker ID.
        if not skip_speaker_id and speaker_name is None:
            try:
                # Only do speaker ID if explicitly requested and with timeout
                speaker_name = await asyncio.wait_for(
                    self._identify_speaker(audio_data),
                    timeout=SPEAKER_ID_TIMEOUT
                )
                if speaker_name:
                    logger.info(f"ğŸ‘¤ Speaker identified: {speaker_name}")
            except asyncio.TimeoutError:
                logger.warning(f"â±ï¸ Speaker ID timed out after {SPEAKER_ID_TIMEOUT}s (skipping)")
            except Exception as e:
                logger.debug(f"Speaker ID failed: {e} (continuing without)")

        # Select primary model
        primary_model = self._select_optimal_model(resources, strategy, speaker_name)
        logger.debug(f"ğŸ¯ Primary model: {primary_model.name} ({primary_model.engine})")

        # Try primary model
        primary_result = await self._transcribe_with_engine(
            audio_data, primary_model, timeout_sec=self.config.max_local_latency_ms / 1000
        )

        # Decide if escalation is needed
        should_escalate = False
        if primary_result is None:
            logger.warning("âš ï¸  Primary model failed, escalating...")
            should_escalate = True
        elif primary_result.confidence < self.config.min_confidence_local:
            logger.info(
                f"ğŸ“‰ Low confidence ({primary_result.confidence:.2f}), escalating for validation..."
            )
            should_escalate = True
        elif (
            speaker_name in self.config.priority_speakers
            and primary_result.confidence < self.config.high_confidence_threshold
        ):
            logger.info(f"ğŸ‘‘ Priority speaker {speaker_name}, escalating for best accuracy...")
            should_escalate = True

        final_result = primary_result

        # Escalate to cloud if needed
        if should_escalate and resources.network_available:
            # Get most accurate model (likely GCP)
            cloud_model = self.config.get_most_accurate_model()

            if cloud_model.requires_internet:
                logger.info(f"â˜ï¸  Escalating to cloud model: {cloud_model.name}")
                self.cloud_requests += 1
                self.config.increment_cloud_usage()

                cloud_result = await self._transcribe_with_engine(
                    audio_data, cloud_model, timeout_sec=self.config.max_cloud_latency_ms / 1000
                )

                if cloud_result and cloud_result.confidence > (
                    primary_result.confidence if primary_result else 0
                ):
                    logger.info(
                        f"âœ… Cloud result better: {cloud_result.confidence:.2f} > {primary_result.confidence if primary_result else 0:.2f}"
                    )
                    final_result = cloud_result
                elif cloud_result:
                    logger.info(
                        f"âš–ï¸  Keeping primary result (confidence: {primary_result.confidence:.2f})"
                    )
                else:
                    logger.warning("â˜ï¸  Cloud transcription failed")

        # Fallback if everything failed
        if final_result is None:
            logger.error("âŒ All transcription attempts failed, using fallback")
            # Try smallest/fastest model as last resort
            fallback_model = self.config.models.get("vosk-small")
            if fallback_model:
                final_result = await self._transcribe_with_engine(
                    audio_data, fallback_model, timeout_sec=5.0
                )

        # Still no result? Try Whisper directly as last resort with timeout protection
        if final_result is None:
            logger.warning("âš ï¸  All engines failed, attempting robust Whisper transcription...")

            # Check circuit breaker for whisper fallback
            if not self._check_circuit_breaker("whisper_fallback"):
                logger.error("ğŸ”´ Whisper fallback circuit breaker OPEN - too many recent failures")
                final_result = STTResult(
                    text="[transcription unavailable]",
                    confidence=0.0,
                    engine=STTEngine.WHISPER_LOCAL,
                    model_name="fallback-circuit-open",
                    latency_ms=(time.time() - start_time) * 1000,
                    audio_duration_ms=0,
                    metadata={"error": "circuit_breaker_open", "reason": "too_many_failures"}
                )
            else:
                try:
                    # Use prewarmed handler if available, otherwise import fresh
                    if self._whisper_handler:
                        handler = self._whisper_handler
                        logger.debug("Using prewarmed Whisper handler")
                    else:
                        from .whisper_audio_fix import _whisper_handler as handler
                        logger.debug("Using fresh Whisper handler (not prewarmed)")

                    # Transcribe with timeout protection
                    text = await asyncio.wait_for(
                        handler.transcribe_any_format(
                            audio_data,
                            sample_rate=sample_rate,
                            mode=mode  # Pass mode for VAD + windowing
                        ),
                        timeout=FALLBACK_TIMEOUT
                    )

                    if text:
                        final_result = STTResult(
                            text=text,
                            confidence=0.85,  # Whisper doesn't provide confidence
                            engine=STTEngine.WHISPER_LOCAL,
                            model_name="whisper-robust-fallback",
                            latency_ms=(time.time() - start_time) * 1000,
                            audio_duration_ms=3000,  # Assume 3 seconds
                        )
                        self._record_circuit_breaker_success("whisper_fallback")
                        logger.info(f"âœ… Robust Whisper succeeded: '{final_result.text}'")
                    else:
                        logger.warning("âš ï¸ Robust Whisper returned None - no speech detected")
                        self._record_circuit_breaker_failure("whisper_fallback")
                        final_result = STTResult(
                            text="[no speech detected]",
                            confidence=0.0,
                            engine=STTEngine.WHISPER_LOCAL,
                            model_name="fallback",
                            latency_ms=(time.time() - start_time) * 1000,
                            audio_duration_ms=0,
                            metadata={"error": "no_speech", "reason": "whisper_returned_none"}
                        )

                except asyncio.TimeoutError:
                    logger.error(f"â±ï¸ Whisper fallback timed out after {FALLBACK_TIMEOUT}s")
                    self._record_circuit_breaker_failure("whisper_fallback")
                    final_result = STTResult(
                        text="[transcription timeout]",
                        confidence=0.0,
                        engine=STTEngine.WHISPER_LOCAL,
                        model_name="fallback-timeout",
                        latency_ms=(time.time() - start_time) * 1000,
                        audio_duration_ms=0,
                        metadata={"error": "timeout", "reason": "whisper_fallback_timeout"}
                    )

                except Exception as e:
                    logger.error(f"âŒ Robust Whisper fallback failed: {e}")
                    self._record_circuit_breaker_failure("whisper_fallback")
                    final_result = STTResult(
                        text="[transcription failed]",
                        confidence=0.0,
                        engine=STTEngine.WHISPER_LOCAL,
                        model_name="fallback",
                        latency_ms=(time.time() - start_time) * 1000,
                        audio_duration_ms=0,
                        metadata={"error": str(e), "reason": "audio_validation_failed"}
                    )

        # Intent-aware consensus for screen lock/unlock (reduces "lock" â†” "unlock" confusion)
        # Never blocks overall transcription correctness if consensus fails.
        try:
            if final_result and final_result.text and mode in ("command", "general", "unlock"):
                final_result = await self._apply_screen_intent_consensus(
                    audio_data=audio_data,
                    current=final_result,
                    resources=resources,
                    primary_model=primary_model,
                )
        except Exception as e:
            logger.debug(f"Screen intent consensus skipped due to error: {e}")

        # Calculate total latency
        total_latency_ms = (time.time() - start_time) * 1000
        final_result.latency_ms = total_latency_ms

        # Record to database for learning (async, don't block)
        asyncio.create_task(self._record_transcription(audio_data, final_result, speaker_name))

        # Log final result
        logger.info(
            f"ğŸ¯ Final transcription: '{final_result.text[:50]}...' "
            f"(model={final_result.model_name}, confidence={final_result.confidence:.2f}, "
            f"latency={total_latency_ms:.0f}ms)"
        )

        return final_result

    async def record_misheard(
        self, transcription_id: int, what_heard: str, what_meant: str
    ) -> bool:
        """Record when user corrects a misheard transcription"""
        try:
            learning_db = await self._get_learning_db()
            if not learning_db:
                return False

            await learning_db.record_misheard_query(
                transcription_id=transcription_id,
                what_jarvis_heard=what_heard,
                what_user_meant=what_meant,
                correction_method="user_correction",
            )

            logger.info(f"ğŸ“ Recorded misheard: '{what_heard}' -> '{what_meant}'")
            return True

        except Exception as e:
            logger.error(f"Failed to record misheard: {e}")
            return False

    async def transcribe_fast(
        self,
        audio_data: bytes,
        sample_rate: Optional[int] = None,
        mode: str = 'unlock',
    ) -> STTResult:
        """
        Fast-path transcription using prewarmed Whisper model.

        This method bypasses the complex routing logic and uses the prewarmed
        Whisper model directly for maximum speed. Best for unlock commands
        where latency is critical.

        PERFORMANCE:
        - Uses prewarmed model (no load time)
        - Skips speaker ID (done separately)
        - Skips model selection (uses Whisper directly)
        - Uses unlock mode (2s window) by default

        v8.0 SELF-VOICE SUPPRESSION:
        - Checks UnifiedSpeechStateManager BEFORE transcription
        - Rejects audio if JARVIS is speaking or in cooldown

        Args:
            audio_data: Raw audio bytes
            sample_rate: Optional sample rate from frontend
            mode: VAD/windowing mode (default: 'unlock' for 2s window)

        Returns:
            STTResult with transcription
        """
        start_time = time.time()
        self.total_requests += 1
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # v8.0: SELF-VOICE SUPPRESSION - FAST PATH CHECK
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        try:
            from core.unified_speech_state import get_speech_state_manager_sync
            speech_manager = get_speech_state_manager_sync()
            rejection = speech_manager.should_reject_audio()
            
            if rejection.reject:
                logger.warning(
                    f"ğŸ”‡ [SELF-VOICE-STT-FAST] Rejecting fast transcription - "
                    f"reason: {rejection.reason}"
                )
                return STTResult(
                    text="",
                    confidence=0.0,
                    engine="self_voice_suppression",
                    latency_ms=0,
                    metadata={
                        "rejected": True,
                        "rejection_reason": rejection.reason,
                    }
                )
        except Exception:
            pass  # Non-fatal - continue with transcription

        try:
            # Use prewarmed handler if available
            if self._whisper_handler:
                handler = self._whisper_handler
            else:
                # Fallback to import if not prewarmed
                from .whisper_audio_fix import _whisper_handler as handler

            # Transcribe with timeout
            text = await asyncio.wait_for(
                handler.transcribe_any_format(
                    audio_data,
                    sample_rate=sample_rate,
                    mode=mode
                ),
                timeout=TRANSCRIPTION_TIMEOUT
            )

            latency_ms = (time.time() - start_time) * 1000

            if text:
                return STTResult(
                    text=text,
                    confidence=0.85,
                    engine=STTEngine.WHISPER_LOCAL,
                    model_name="whisper-fast-path",
                    latency_ms=latency_ms,
                    audio_duration_ms=2000,  # 2s unlock window
                )
            else:
                return STTResult(
                    text="[no speech detected]",
                    confidence=0.0,
                    engine=STTEngine.WHISPER_LOCAL,
                    model_name="whisper-fast-path",
                    latency_ms=latency_ms,
                    audio_duration_ms=0,
                    metadata={"error": "no_speech"}
                )

        except asyncio.TimeoutError:
            return STTResult(
                text="[transcription timeout]",
                confidence=0.0,
                engine=STTEngine.WHISPER_LOCAL,
                model_name="whisper-fast-path-timeout",
                latency_ms=(time.time() - start_time) * 1000,
                audio_duration_ms=0,
                metadata={"error": "timeout"}
            )
        except Exception as e:
            logger.error(f"Fast transcription failed: {e}")
            return STTResult(
                text="[transcription failed]",
                confidence=0.0,
                engine=STTEngine.WHISPER_LOCAL,
                model_name="whisper-fast-path-error",
                latency_ms=(time.time() - start_time) * 1000,
                audio_duration_ms=0,
                metadata={"error": str(e)}
            )

    async def health_check(self, force: bool = False) -> HealthStatus:
        """
        Comprehensive health check of the STT router.

        Args:
            force: Force a new health check even if cached result is recent

        Returns:
            HealthStatus with overall health and component details
        """
        now = time.time()

        # Return cached result if recent (unless forced)
        if not force and self._last_health_check:
            if now - self._last_health_check_time < self._health_check_interval:
                return self._last_health_check

        components = {}
        issues = []

        # Check circuit breakers
        for name, cb in self._circuit_breakers.items():
            components[f'circuit_{name}'] = {
                'state': cb.state.value,
                'health_score': cb.health_score,
                'is_available': cb.is_available,
                'consecutive_failures': cb.stats.consecutive_failures,
            }
            if cb.state == CircuitState.OPEN:
                issues.append(f"Circuit breaker {name} is OPEN")

        # Check Whisper prewarm status
        components['whisper_prewarm'] = {
            'prewarmed': self._whisper_prewarmed,
            'handler_available': self._whisper_handler is not None,
        }
        if not self._whisper_prewarmed:
            issues.append("Whisper model not prewarmed")

        # Check available engines
        components['engines'] = {
            'available': list(self.available_engines.keys()),
            'loaded': list(self.engines.keys()),
            'count': len(self.available_engines),
        }
        if len(self.available_engines) == 0:
            issues.append("No STT engines available")

        # Check system resources
        try:
            resources = self._get_system_resources()
            components['resources'] = {
                'ram_available_gb': round(resources.available_ram_gb, 2),
                'ram_percent_used': round(resources.ram_percent_used, 1),
                'cpu_percent': round(resources.cpu_percent, 1),
                'network_available': resources.network_available,
            }
            if resources.available_ram_gb < 1.0:
                issues.append("Low available RAM")
            if resources.cpu_percent > 90:
                issues.append("High CPU usage")
        except Exception as e:
            components['resources'] = {'error': str(e)}
            issues.append(f"Resource check failed: {e}")

        # Check learning database connection
        components['learning_db'] = {
            'connected': self.learning_db is not None,
        }

        # Calculate overall health score
        cb_scores = [cb.health_score for cb in self._circuit_breakers.values()]
        avg_cb_score = sum(cb_scores) / len(cb_scores) if cb_scores else 1.0

        # Weight: circuit breakers (50%), prewarmed (20%), engines (30%)
        prewarm_score = 1.0 if self._whisper_prewarmed else 0.5
        engine_score = min(1.0, len(self.available_engines) / 3)  # At least 3 engines ideal

        overall_score = (avg_cb_score * 0.5) + (prewarm_score * 0.2) + (engine_score * 0.3)
        healthy = overall_score >= 0.7 and len(issues) == 0

        # Build status message
        if healthy:
            message = "All systems operational"
        elif overall_score >= 0.5:
            message = f"Degraded: {', '.join(issues[:2])}"
        else:
            message = f"Critical: {', '.join(issues[:3])}"

        status = HealthStatus(
            healthy=healthy,
            score=round(overall_score, 3),
            components=components,
            last_check=datetime.now(),
            message=message,
        )

        self._last_health_check = status
        self._last_health_check_time = now

        return status

    def get_circuit_breaker(self, name: str) -> Optional[AdvancedCircuitBreaker]:
        """Get a specific circuit breaker by name."""
        return self._circuit_breakers.get(name)

    def reset_circuit_breaker(self, name: str) -> bool:
        """Reset a specific circuit breaker."""
        cb = self._circuit_breakers.get(name)
        if cb:
            cb.reset()
            return True
        return False

    def reset_all_circuit_breakers(self):
        """Reset all circuit breakers to closed state."""
        for cb in self._circuit_breakers.values():
            cb.reset()
        logger.info("All circuit breakers reset")

    def get_stats(self) -> Dict:
        """Get comprehensive router performance statistics"""
        uptime = time.time() - self._start_time

        # Calculate requests per minute
        rpm = (self.total_requests / uptime * 60) if uptime > 0 else 0

        return {
            "total_requests": self.total_requests,
            "cloud_requests": self.cloud_requests,
            "cloud_usage_percent": (
                (self.cloud_requests / self.total_requests * 100) if self.total_requests > 0 else 0
            ),
            "cache_hits": self.cache_hits,
            "loaded_engines": list(self.engines.keys()),
            "performance_by_model": self.performance_stats,
            "config": self.config.to_dict(),
            # Prewarming status
            "whisper_prewarmed": self._whisper_prewarmed,
            # Advanced circuit breaker status
            "circuit_breakers": {
                name: cb.to_dict() for name, cb in self._circuit_breakers.items()
            },
            # Legacy circuit breaker (for backwards compatibility)
            "circuit_breaker_failures": dict(self._circuit_breaker_failures),
            # Performance metrics
            "uptime_seconds": round(uptime, 1),
            "requests_per_minute": round(rpm, 2),
            # Health summary
            "health": {
                "last_check": self._last_health_check.last_check.isoformat() if self._last_health_check else None,
                "score": self._last_health_check.score if self._last_health_check else None,
                "healthy": self._last_health_check.healthy if self._last_health_check else None,
            },
        }

    async def transcribe_stream(self, audio_bus=None):
        """
        Start streaming transcription from AudioBus mic input.

        Returns an async iterator of StreamingTranscriptEvent objects.
        Requires AudioBus to be running.

        Args:
            audio_bus: Optional AudioBus instance. If None, fetches singleton.

        Returns:
            AsyncIterator[StreamingTranscriptEvent]
        """
        from backend.voice.streaming_stt import StreamingSTTEngine

        engine = StreamingSTTEngine(sample_rate=16000)
        await engine.start()

        # Register as mic consumer on AudioBus
        if audio_bus is None:
            try:
                from backend.audio.audio_bus import get_audio_bus
                audio_bus = get_audio_bus()
            except ImportError:
                raise RuntimeError(
                    "AudioBus not available. Set JARVIS_AUDIO_BUS_ENABLED=true"
                )

        if audio_bus.is_running:
            audio_bus.register_mic_consumer(engine.on_audio_frame)

        try:
            async for event in engine.get_transcripts():
                yield event
        finally:
            if audio_bus.is_running:
                audio_bus.unregister_mic_consumer(engine.on_audio_frame)
            await engine.stop()


# Global singleton
_hybrid_router: Optional[HybridSTTRouter] = None


def get_hybrid_router() -> HybridSTTRouter:
    """Get global hybrid STT router instance"""
    global _hybrid_router
    if _hybrid_router is None:
        _hybrid_router = HybridSTTRouter()
    return _hybrid_router

