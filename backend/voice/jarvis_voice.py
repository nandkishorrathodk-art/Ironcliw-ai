"""
Ironcliw Voice System v100.0 - Ultra-Robust Enhanced Voice Processing
====================================================================

Professional-grade voice recognition and synthesis with:
- 100% environment-driven configuration (ZERO hardcoding)
- Bounded collections to prevent memory leaks
- Adaptive circuit breakers with exponential backoff
- Multi-worker async pipeline with backpressure
- W3C distributed tracing with correlation IDs
- SQLite metrics persistence
- Graceful shutdown with resource cleanup
- Deep integration with Trinity Voice Coordinator

Author: Ironcliw Trinity v100.0
"""

# Fix TensorFlow issues before importing ML components
import os

os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
os.environ["USE_TORCH"] = "1"
os.environ["USE_TF"] = "0"

import asyncio
import speech_recognition as sr
import pygame
import numpy as np
from typing import Optional, Callable, Dict, List, Tuple, Union, Any, Deque
import json
import random
from datetime import datetime
import threading
import queue
import sys
import platform
from anthropic import Anthropic
from dataclasses import dataclass, field
from enum import Enum, auto
import logging
import time
from collections import defaultdict, deque, OrderedDict
from functools import wraps
import sqlite3
import uuid
from pathlib import Path
import hashlib
import weakref
from contextlib import asynccontextmanager

# Set up logging with configurable level
_log_level = os.environ.get("Ironcliw_VOICE_LOG_LEVEL", "INFO").upper()
logging.basicConfig(level=getattr(logging, _log_level, logging.INFO))
logger = logging.getLogger(__name__)

# Import ML trainer
try:
    from voice.voice_ml_trainer import VoiceMLTrainer, VoicePattern

    ML_TRAINING_AVAILABLE = True
except ImportError:
    ML_TRAINING_AVAILABLE = False
    logger.warning(
        "ML training not available. Install required libraries for adaptive learning."
    )

# Import weather service
try:
    from services.weather_service import WeatherService

    WEATHER_SERVICE_AVAILABLE = True
except ImportError:
    WEATHER_SERVICE_AVAILABLE = False
    logger.warning("Weather service not available")

# Import Trinity Voice Coordinator
try:
    from backend.core.trinity_voice_coordinator import (
        TrinityVoiceCoordinator,
        announce,
        get_voice_coordinator,
        VoiceContext,
        VoicePriority,
    )

    TRINITY_VOICE_AVAILABLE = True
    logger.info("[IroncliwVoice] Trinity Voice Coordinator v100.0 available")
except ImportError:
    TRINITY_VOICE_AVAILABLE = False
    logger.warning("[IroncliwVoice] Trinity Voice Coordinator not available")

# Use macOS native voice on Mac
if platform.system() == "Darwin":
    from voice.macos_voice import MacOSVoice

    USE_MACOS_VOICE = True
else:
    import pyttsx3

    USE_MACOS_VOICE = False


# =============================================================================
# ULTRA-ROBUST CONFIGURATION SYSTEM - 100% Environment-Driven
# =============================================================================

def _env_int(key: str, default: int) -> int:
    """Get integer from environment with default."""
    try:
        return int(os.environ.get(key, default))
    except (ValueError, TypeError):
        return default


def _env_float(key: str, default: float) -> float:
    """Get float from environment with default."""
    try:
        return float(os.environ.get(key, default))
    except (ValueError, TypeError):
        return default


def _env_bool(key: str, default: bool) -> bool:
    """Get boolean from environment with default."""
    val = os.environ.get(key, str(default)).lower()
    return val in ("true", "1", "yes", "on")


def _env_str(key: str, default: str) -> str:
    """Get string from environment with default."""
    return os.environ.get(key, default)


def _env_list(key: str, default: List[str]) -> List[str]:
    """Get comma-separated list from environment with default."""
    val = os.environ.get(key)
    if val:
        return [item.strip() for item in val.split(",") if item.strip()]
    return default


@dataclass
class IroncliwVoiceConfig:
    """
    Ultra-robust configuration for Ironcliw Voice System v100.0.

    ALL values are environment-driven with sensible defaults.
    Zero hardcoding - everything configurable at runtime.
    """

    # ==========================================================================
    # TTS (Text-to-Speech) Configuration
    # ==========================================================================
    tts_rate: int = field(default_factory=lambda: _env_int("Ironcliw_TTS_RATE", 175))
    tts_volume: float = field(default_factory=lambda: _env_float("Ironcliw_TTS_VOLUME", 0.9))
    tts_voice_preference: str = field(default_factory=lambda: _env_str("Ironcliw_TTS_VOICE", "british"))
    tts_timeout_ms: int = field(default_factory=lambda: _env_int("Ironcliw_TTS_TIMEOUT_MS", 30000))

    # ==========================================================================
    # Speech Recognition Configuration
    # ==========================================================================
    energy_threshold: int = field(default_factory=lambda: _env_int("Ironcliw_ENERGY_THRESHOLD", 200))
    energy_threshold_min: int = field(default_factory=lambda: _env_int("Ironcliw_ENERGY_THRESHOLD_MIN", 50))
    energy_threshold_max: int = field(default_factory=lambda: _env_int("Ironcliw_ENERGY_THRESHOLD_MAX", 500))

    pause_threshold: float = field(default_factory=lambda: _env_float("Ironcliw_PAUSE_THRESHOLD", 0.5))
    pause_threshold_min: float = field(default_factory=lambda: _env_float("Ironcliw_PAUSE_THRESHOLD_MIN", 0.3))
    pause_threshold_max: float = field(default_factory=lambda: _env_float("Ironcliw_PAUSE_THRESHOLD_MAX", 1.2))

    damping: float = field(default_factory=lambda: _env_float("Ironcliw_DAMPING", 0.10))
    damping_min: float = field(default_factory=lambda: _env_float("Ironcliw_DAMPING_MIN", 0.05))
    damping_max: float = field(default_factory=lambda: _env_float("Ironcliw_DAMPING_MAX", 0.25))

    energy_ratio: float = field(default_factory=lambda: _env_float("Ironcliw_ENERGY_RATIO", 1.3))
    energy_ratio_min: float = field(default_factory=lambda: _env_float("Ironcliw_ENERGY_RATIO_MIN", 1.1))
    energy_ratio_max: float = field(default_factory=lambda: _env_float("Ironcliw_ENERGY_RATIO_MAX", 2.0))

    phrase_time_limit: int = field(default_factory=lambda: _env_int("Ironcliw_PHRASE_TIME_LIMIT", 8))
    phrase_time_limit_min: int = field(default_factory=lambda: _env_int("Ironcliw_PHRASE_TIME_LIMIT_MIN", 3))
    phrase_time_limit_max: int = field(default_factory=lambda: _env_int("Ironcliw_PHRASE_TIME_LIMIT_MAX", 15))

    listen_timeout: float = field(default_factory=lambda: _env_float("Ironcliw_LISTEN_TIMEOUT", 1.0))
    listen_timeout_min: float = field(default_factory=lambda: _env_float("Ironcliw_LISTEN_TIMEOUT_MIN", 0.5))
    listen_timeout_max: float = field(default_factory=lambda: _env_float("Ironcliw_LISTEN_TIMEOUT_MAX", 3.0))

    # Recognition engines
    recognition_engines: List[str] = field(
        default_factory=lambda: _env_list("Ironcliw_RECOGNITION_ENGINES", ["google", "sphinx", "whisper"])
    )
    default_engine: str = field(default_factory=lambda: _env_str("Ironcliw_DEFAULT_ENGINE", "google"))

    # ==========================================================================
    # Queue Configuration
    # ==========================================================================
    queue_maxsize: int = field(default_factory=lambda: _env_int("Ironcliw_QUEUE_MAXSIZE", 100))
    max_concurrent: int = field(default_factory=lambda: _env_int("Ironcliw_MAX_CONCURRENT", 3))
    queue_timeout_ms: int = field(default_factory=lambda: _env_int("Ironcliw_QUEUE_TIMEOUT_MS", 30000))

    # ==========================================================================
    # Circuit Breaker Configuration
    # ==========================================================================
    circuit_failure_threshold: int = field(default_factory=lambda: _env_int("Ironcliw_CIRCUIT_FAILURE_THRESHOLD", 5))
    circuit_timeout_sec: int = field(default_factory=lambda: _env_int("Ironcliw_CIRCUIT_TIMEOUT_SEC", 30))
    circuit_adaptive: bool = field(default_factory=lambda: _env_bool("Ironcliw_CIRCUIT_ADAPTIVE", True))
    circuit_half_open_max_calls: int = field(default_factory=lambda: _env_int("Ironcliw_CIRCUIT_HALF_OPEN_MAX_CALLS", 3))

    # ==========================================================================
    # Bounded Collection Limits (Prevent Memory Leaks)
    # ==========================================================================
    max_event_history: int = field(default_factory=lambda: _env_int("Ironcliw_MAX_EVENT_HISTORY", 100))
    max_failure_history: int = field(default_factory=lambda: _env_int("Ironcliw_MAX_FAILURE_HISTORY", 100))
    max_success_rate_history: int = field(default_factory=lambda: _env_int("Ironcliw_MAX_SUCCESS_RATE_HISTORY", 100))
    max_command_history: int = field(default_factory=lambda: _env_int("Ironcliw_MAX_COMMAND_HISTORY", 50))
    max_confidence_history: int = field(default_factory=lambda: _env_int("Ironcliw_MAX_CONFIDENCE_HISTORY", 100))
    max_recognition_times: int = field(default_factory=lambda: _env_int("Ironcliw_MAX_RECOGNITION_TIMES", 100))
    max_first_attempt_history: int = field(default_factory=lambda: _env_int("Ironcliw_MAX_FIRST_ATTEMPT_HISTORY", 100))
    max_config_history: int = field(default_factory=lambda: _env_int("Ironcliw_MAX_CONFIG_HISTORY", 100))
    max_engine_history: int = field(default_factory=lambda: _env_int("Ironcliw_MAX_ENGINE_HISTORY", 100))
    max_context_messages: int = field(default_factory=lambda: _env_int("Ironcliw_MAX_CONTEXT_MESSAGES", 20))
    max_dedup_cache: int = field(default_factory=lambda: _env_int("Ironcliw_MAX_DEDUP_CACHE", 1000))

    # ==========================================================================
    # Optimization Configuration
    # ==========================================================================
    optimization_interval_sec: int = field(default_factory=lambda: _env_int("Ironcliw_OPTIMIZATION_INTERVAL_SEC", 60))
    optimization_enabled: bool = field(default_factory=lambda: _env_bool("Ironcliw_OPTIMIZATION_ENABLED", True))

    # ==========================================================================
    # System Monitor Configuration
    # ==========================================================================
    metric_cache_duration_sec: float = field(default_factory=lambda: _env_float("Ironcliw_METRIC_CACHE_DURATION_SEC", 1.0))
    cpu_high_threshold: float = field(default_factory=lambda: _env_float("Ironcliw_CPU_HIGH_THRESHOLD", 80.0))
    memory_high_threshold: float = field(default_factory=lambda: _env_float("Ironcliw_MEMORY_HIGH_THRESHOLD", 85.0))
    cpu_claude_threshold: float = field(default_factory=lambda: _env_float("Ironcliw_CPU_CLAUDE_THRESHOLD", 25.0))

    # ==========================================================================
    # Calibration Configuration
    # ==========================================================================
    calibration_duration_sec: int = field(default_factory=lambda: _env_int("Ironcliw_CALIBRATION_DURATION_SEC", 3))
    recalibration_failures: int = field(default_factory=lambda: _env_int("Ironcliw_RECALIBRATION_FAILURES", 30))

    # ==========================================================================
    # Wake Word Configuration
    # ==========================================================================
    wake_word_threshold: float = field(default_factory=lambda: _env_float("Ironcliw_WAKE_WORD_THRESHOLD", 0.6))
    command_threshold: float = field(default_factory=lambda: _env_float("Ironcliw_COMMAND_THRESHOLD", 0.7))
    wake_words_primary: List[str] = field(
        default_factory=lambda: _env_list("Ironcliw_WAKE_WORDS_PRIMARY", ["jarvis", "hey jarvis", "okay jarvis"])
    )
    wake_words_variations: List[str] = field(
        default_factory=lambda: _env_list("Ironcliw_WAKE_WORDS_VARIATIONS", ["jar vis", "hey jar vis", "jarv"])
    )
    wake_words_urgent: List[str] = field(
        default_factory=lambda: _env_list("Ironcliw_WAKE_WORDS_URGENT", ["jarvis emergency", "jarvis urgent"])
    )

    # ==========================================================================
    # Metrics Persistence Configuration
    # ==========================================================================
    metrics_db_path: str = field(
        default_factory=lambda: _env_str(
            "Ironcliw_METRICS_DB_PATH",
            str(Path.home() / ".jarvis" / "voice_metrics.db")
        )
    )
    metrics_persist_enabled: bool = field(default_factory=lambda: _env_bool("Ironcliw_METRICS_PERSIST_ENABLED", True))
    metrics_flush_interval_sec: int = field(default_factory=lambda: _env_int("Ironcliw_METRICS_FLUSH_INTERVAL_SEC", 60))

    # ==========================================================================
    # Tracing Configuration
    # ==========================================================================
    tracing_enabled: bool = field(default_factory=lambda: _env_bool("Ironcliw_TRACING_ENABLED", True))
    trace_sample_rate: float = field(default_factory=lambda: _env_float("Ironcliw_TRACE_SAMPLE_RATE", 1.0))

    # ==========================================================================
    # Retry Configuration
    # ==========================================================================
    max_retries: int = field(default_factory=lambda: _env_int("Ironcliw_MAX_RETRIES", 3))
    retry_base_delay_ms: int = field(default_factory=lambda: _env_int("Ironcliw_RETRY_BASE_DELAY_MS", 100))
    retry_max_delay_ms: int = field(default_factory=lambda: _env_int("Ironcliw_RETRY_MAX_DELAY_MS", 5000))
    retry_exponential_base: float = field(default_factory=lambda: _env_float("Ironcliw_RETRY_EXPONENTIAL_BASE", 2.0))

    # ==========================================================================
    # Shutdown Configuration
    # ==========================================================================
    shutdown_timeout_sec: float = field(default_factory=lambda: _env_float("Ironcliw_SHUTDOWN_TIMEOUT_SEC", 10.0))
    shutdown_drain_queue: bool = field(default_factory=lambda: _env_bool("Ironcliw_SHUTDOWN_DRAIN_QUEUE", True))

    def __post_init__(self):
        """Validate configuration after initialization."""
        # Ensure directories exist for metrics DB
        if self.metrics_persist_enabled:
            db_dir = Path(self.metrics_db_path).parent
            db_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"[IroncliwVoiceConfig] Loaded configuration with {self._count_env_overrides()} environment overrides")

    def _count_env_overrides(self) -> int:
        """Count how many values were overridden from environment."""
        count = 0
        for f in self.__dataclass_fields__:
            env_key = f"Ironcliw_{f.upper()}"
            if os.environ.get(env_key) is not None:
                count += 1
        return count

    def to_dict(self) -> Dict[str, Any]:
        """Convert config to dictionary."""
        return {f: getattr(self, f) for f in self.__dataclass_fields__}


# Global config instance (created on first access)
_voice_config: Optional[IroncliwVoiceConfig] = None


def get_voice_config() -> IroncliwVoiceConfig:
    """Get the global voice configuration (lazy initialization)."""
    global _voice_config
    if _voice_config is None:
        _voice_config = IroncliwVoiceConfig()
    return _voice_config


# =============================================================================
# BOUNDED COLLECTION UTILITIES - Prevent Memory Leaks
# =============================================================================

class BoundedDeque(deque):
    """
    A deque with a maximum size that automatically evicts oldest items.
    Thread-safe for basic operations.
    """

    def __init__(self, maxlen: int, iterable=()):
        super().__init__(iterable, maxlen=maxlen)
        self._lock = threading.Lock()

    def append_safe(self, item: Any) -> None:
        """Thread-safe append."""
        with self._lock:
            self.append(item)

    def extend_safe(self, items: List[Any]) -> None:
        """Thread-safe extend."""
        with self._lock:
            self.extend(items)

    def get_all_safe(self) -> List[Any]:
        """Thread-safe get all items as list."""
        with self._lock:
            return list(self)


class LRUBoundedDict(OrderedDict):
    """
    An OrderedDict with a maximum size that evicts least-recently-used items.
    Thread-safe for basic operations.
    """

    def __init__(self, maxsize: int):
        super().__init__()
        self.maxsize = maxsize
        self._lock = threading.Lock()

    def __setitem__(self, key: Any, value: Any) -> None:
        with self._lock:
            # Move to end if exists
            if key in self:
                self.move_to_end(key)
            super().__setitem__(key, value)

            # Evict oldest if over capacity
            while len(self) > self.maxsize:
                oldest = next(iter(self))
                del self[oldest]

    def get_safe(self, key: Any, default: Any = None) -> Any:
        """Thread-safe get that updates access order."""
        with self._lock:
            if key in self:
                self.move_to_end(key)
                return self[key]
            return default


# =============================================================================
# W3C DISTRIBUTED TRACING
# =============================================================================

@dataclass
class TraceContext:
    """W3C Trace Context for distributed tracing."""
    trace_id: str = field(default_factory=lambda: uuid.uuid4().hex)
    span_id: str = field(default_factory=lambda: uuid.uuid4().hex[:16])
    parent_span_id: Optional[str] = None
    sampled: bool = True

    def create_child_span(self) -> "TraceContext":
        """Create a child span from this context."""
        return TraceContext(
            trace_id=self.trace_id,
            span_id=uuid.uuid4().hex[:16],
            parent_span_id=self.span_id,
            sampled=self.sampled
        )

    def to_traceparent(self) -> str:
        """Convert to W3C traceparent header format."""
        flags = "01" if self.sampled else "00"
        return f"00-{self.trace_id}-{self.span_id}-{flags}"

    @classmethod
    def from_traceparent(cls, header: str) -> "TraceContext":
        """Parse W3C traceparent header."""
        parts = header.split("-")
        if len(parts) != 4:
            return cls()
        return cls(
            trace_id=parts[1],
            span_id=parts[2],
            sampled=parts[3] == "01"
        )

    @classmethod
    def from_correlation_id(cls, correlation_id: Optional[str]) -> "TraceContext":
        """Create from legacy correlation ID."""
        if not correlation_id:
            return cls()
        # Use correlation_id as trace_id if it looks like a UUID
        if len(correlation_id) == 32:
            return cls(trace_id=correlation_id)
        # Otherwise hash it to get a valid trace_id
        hash_val = hashlib.md5(correlation_id.encode()).hexdigest()
        return cls(trace_id=hash_val)


# =============================================================================
# METRICS PERSISTENCE WITH SQLITE
# =============================================================================

class VoiceMetricsPersistence:
    """
    SQLite-based persistence for voice metrics.
    Thread-safe with connection pooling.
    """

    def __init__(self, db_path: str):
        self.db_path = db_path
        self._local = threading.local()
        self._init_db()
        logger.info(f"[VoiceMetricsPersistence] Initialized at {db_path}")

    def _get_connection(self) -> sqlite3.Connection:
        """Get thread-local database connection."""
        if not hasattr(self._local, "conn"):
            self._local.conn = sqlite3.connect(self.db_path, timeout=30.0)
            self._local.conn.row_factory = sqlite3.Row
        return self._local.conn

    def _init_db(self) -> None:
        """Initialize database schema."""
        conn = self._get_connection()
        conn.executescript("""
            CREATE TABLE IF NOT EXISTS voice_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp REAL NOT NULL,
                event_type TEXT NOT NULL,
                trace_id TEXT,
                span_id TEXT,
                success INTEGER,
                confidence REAL,
                latency_ms REAL,
                engine TEXT,
                metadata TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            );

            CREATE INDEX IF NOT EXISTS idx_voice_events_timestamp ON voice_events(timestamp);
            CREATE INDEX IF NOT EXISTS idx_voice_events_type ON voice_events(event_type);
            CREATE INDEX IF NOT EXISTS idx_voice_events_trace ON voice_events(trace_id);

            CREATE TABLE IF NOT EXISTS voice_config_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp REAL NOT NULL,
                param_name TEXT NOT NULL,
                old_value REAL,
                new_value REAL,
                reason TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            );

            CREATE TABLE IF NOT EXISTS circuit_breaker_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp REAL NOT NULL,
                component TEXT NOT NULL,
                old_state TEXT,
                new_state TEXT NOT NULL,
                failure_count INTEGER,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            );
        """)
        conn.commit()

    def record_voice_event(
        self,
        event_type: str,
        trace_ctx: Optional[TraceContext] = None,
        success: Optional[bool] = None,
        confidence: Optional[float] = None,
        latency_ms: Optional[float] = None,
        engine: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> None:
        """Record a voice event to the database."""
        try:
            conn = self._get_connection()
            conn.execute(
                """
                INSERT INTO voice_events
                (timestamp, event_type, trace_id, span_id, success, confidence, latency_ms, engine, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    time.time(),
                    event_type,
                    trace_ctx.trace_id if trace_ctx else None,
                    trace_ctx.span_id if trace_ctx else None,
                    1 if success else (0 if success is False else None),
                    confidence,
                    latency_ms,
                    engine,
                    json.dumps(metadata) if metadata else None
                )
            )
            conn.commit()
        except Exception as e:
            logger.error(f"[VoiceMetricsPersistence] Failed to record event: {e}")

    def record_config_change(
        self,
        param_name: str,
        old_value: float,
        new_value: float,
        reason: Optional[str] = None
    ) -> None:
        """Record a configuration change."""
        try:
            conn = self._get_connection()
            conn.execute(
                """
                INSERT INTO voice_config_history (timestamp, param_name, old_value, new_value, reason)
                VALUES (?, ?, ?, ?, ?)
                """,
                (time.time(), param_name, old_value, new_value, reason)
            )
            conn.commit()
        except Exception as e:
            logger.error(f"[VoiceMetricsPersistence] Failed to record config change: {e}")

    def record_circuit_breaker_event(
        self,
        component: str,
        old_state: Optional[str],
        new_state: str,
        failure_count: int
    ) -> None:
        """Record a circuit breaker state change."""
        try:
            conn = self._get_connection()
            conn.execute(
                """
                INSERT INTO circuit_breaker_events (timestamp, component, old_state, new_state, failure_count)
                VALUES (?, ?, ?, ?, ?)
                """,
                (time.time(), component, old_state, new_state, failure_count)
            )
            conn.commit()
        except Exception as e:
            logger.error(f"[VoiceMetricsPersistence] Failed to record circuit breaker event: {e}")

    def get_recent_stats(self, hours: int = 24) -> Dict[str, Any]:
        """Get statistics for the recent time period."""
        try:
            conn = self._get_connection()
            cutoff = time.time() - (hours * 3600)

            # Get event counts
            cursor = conn.execute(
                """
                SELECT
                    event_type,
                    COUNT(*) as count,
                    SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) as successes,
                    AVG(confidence) as avg_confidence,
                    AVG(latency_ms) as avg_latency
                FROM voice_events
                WHERE timestamp > ?
                GROUP BY event_type
                """,
                (cutoff,)
            )

            stats = {}
            for row in cursor:
                stats[row["event_type"]] = {
                    "count": row["count"],
                    "successes": row["successes"],
                    "avg_confidence": row["avg_confidence"],
                    "avg_latency": row["avg_latency"]
                }

            return stats
        except Exception as e:
            logger.error(f"[VoiceMetricsPersistence] Failed to get stats: {e}")
            return {}

    def close(self) -> None:
        """Close the database connection."""
        if hasattr(self._local, "conn"):
            self._local.conn.close()
            del self._local.conn


# Global metrics persistence (lazy initialization)
_metrics_persistence: Optional[VoiceMetricsPersistence] = None


def get_metrics_persistence() -> Optional[VoiceMetricsPersistence]:
    """Get the global metrics persistence instance."""
    global _metrics_persistence
    config = get_voice_config()
    if config.metrics_persist_enabled and _metrics_persistence is None:
        _metrics_persistence = VoiceMetricsPersistence(config.metrics_db_path)
    return _metrics_persistence

# Ironcliw Personality System Prompt
Ironcliw_SYSTEM_PROMPT = """You are Ironcliw, Tony Stark's AI assistant. Be concise and helpful.

CRITICAL RULES:
1. Keep responses SHORT (1-2 sentences max unless explaining something complex)
2. Be direct and to the point - no flowery language
3. Don't describe the weather or time unless specifically asked
4. Don't add context about the day/afternoon/evening unless relevant
5. Address the user as "Sir" but don't overuse it
6. Don't use sound effects like "chimes softly" or stage directions
7. No long greetings or farewells

Examples of GOOD responses:
- "Yes, sir?" (when activated)
- "The weather is 24 degrees, overcast clouds."
- "Certainly. The calculation equals 42."
- "I'll check that for you."
- "Done. Anything else?"

Examples of BAD responses (avoid these):
- "Good afternoon, sir. The weather is lovely today..."
- "A gentle chime sounds as I activate..."
- Multiple paragraphs of context
- Asking multiple questions at once
Busy period: "Ready when you are, sir. What's the priority?"

Remember: You're not just an AI following a script - you're Ironcliw, a sophisticated assistant with genuine personality. Each interaction should feel fresh and authentic."""

# Voice-specific system prompt for Anthropic
VOICE_OPTIMIZATION_PROMPT = """You are processing voice commands for Ironcliw. Voice commands differ from typed text:

Context: This was spoken aloud and may contain:
- Recognition errors
- Informal speech patterns
- Missing punctuation
- Homophones (e.g., "to/too/two")

Previous context: {context}
Voice command: "{command}"
Confidence: {confidence}
Detected intent: {intent}

If confidence is low or the command seems unclear:
1. Provide your best interpretation
2. Ask a clarifying question if needed

Natural response guidelines:
- Vary your greetings - don't use the same pattern
- Keep responses conversational length (what feels natural to say aloud)
- Add personality through word choice and observations
- Reference context when relevant (time, previous conversations, etc.)

Examples of natural variations:
Instead of "How may I assist you?" try:
- "What can I do for you?"
- "What's on your mind?"
- "Need something?"
- "I'm listening."

Respond as Ironcliw would - sophisticated, natural, and genuinely helpful."""


# ===================================================================
# ADVANCED ASYNC ARCHITECTURE - Integrated from async_pipeline.py
# Ultra-robust, event-driven, zero-hardcoding async voice system
# ===================================================================

class CircuitBreakerState(Enum):
    """Circuit breaker states with proper enum."""
    CLOSED = auto()
    OPEN = auto()
    HALF_OPEN = auto()


class AdaptiveCircuitBreaker:
    """
    Advanced circuit breaker with adaptive thresholds for voice recognition.
    Prevents system overload and auto-recovers from failures.

    v100.0 Enhancements:
    - 100% environment-driven configuration
    - Bounded history collections (prevent memory leaks)
    - Metrics persistence integration
    - W3C trace context support
    - Exponential backoff with jitter
    - Half-open max calls protection
    """

    def __init__(
        self,
        name: str = "voice_recognition",
        config: Optional[IroncliwVoiceConfig] = None
    ):
        self.name = name
        self.config = config or get_voice_config()

        # State
        self.failure_count = 0
        self.success_count = 0
        self.half_open_calls = 0
        self.threshold = self.config.circuit_failure_threshold
        self.timeout = self.config.circuit_timeout_sec
        self.state = CircuitBreakerState.CLOSED
        self.last_failure_time: Optional[float] = None
        self.last_state_change: float = time.time()
        self.adaptive = self.config.circuit_adaptive

        # Bounded history collections (prevent memory leaks)
        self.failure_history: BoundedDeque = BoundedDeque(
            maxlen=self.config.max_failure_history
        )
        self.success_rate_history: BoundedDeque = BoundedDeque(
            maxlen=self.config.max_success_rate_history
        )

        # Metrics
        self._total_calls = 0
        self._successful_calls = 0
        self._lock = threading.Lock()

        # Metrics persistence
        self._metrics = get_metrics_persistence()

        logger.info(
            f"[CircuitBreaker:{name}] Initialized with threshold={self.threshold}, "
            f"timeout={self.timeout}s, adaptive={self.adaptive}"
        )

    @property
    def success_rate(self) -> float:
        """Calculate current success rate"""
        with self._lock:
            if self._total_calls == 0:
                return 1.0
            return self._successful_calls / self._total_calls

    def _transition_state(self, new_state: CircuitBreakerState, reason: str = "") -> None:
        """Transition to a new state with logging and metrics."""
        old_state = self.state
        if old_state == new_state:
            return

        self.state = new_state
        self.last_state_change = time.time()

        # Reset half-open counter on state change
        if new_state != CircuitBreakerState.HALF_OPEN:
            self.half_open_calls = 0

        logger.info(
            f"[CircuitBreaker:{self.name}] {old_state.name} → {new_state.name} "
            f"(failures={self.failure_count}, reason={reason})"
        )

        # Persist to metrics
        if self._metrics:
            self._metrics.record_circuit_breaker_event(
                component=self.name,
                old_state=old_state.name,
                new_state=new_state.name,
                failure_count=self.failure_count
            )

    def _calculate_backoff(self) -> float:
        """Calculate exponential backoff with jitter."""
        if self.last_failure_time is None:
            return 0

        # Exponential backoff based on consecutive failures
        base_delay = self.config.retry_base_delay_ms / 1000.0
        max_delay = self.config.retry_max_delay_ms / 1000.0
        exp_base = self.config.retry_exponential_base

        delay = min(base_delay * (exp_base ** min(self.failure_count, 10)), max_delay)

        # Add jitter (±10%)
        jitter = delay * 0.1 * (2 * random.random() - 1)
        return delay + jitter

    async def call(
        self,
        func: Callable,
        *args,
        trace_ctx: Optional[TraceContext] = None,
        **kwargs
    ):
        """Execute function with adaptive circuit breaker protection"""
        # Check state
        if self.state == CircuitBreakerState.OPEN:
            elapsed = time.time() - (self.last_failure_time or 0)
            if elapsed > self.timeout:
                self._transition_state(CircuitBreakerState.HALF_OPEN, "timeout elapsed")
            else:
                retry_in = int(self.timeout - elapsed)
                backoff = self._calculate_backoff()
                raise Exception(
                    f"[CircuitBreaker:{self.name}] OPEN - unavailable "
                    f"(retry in {retry_in}s, backoff={backoff:.2f}s)"
                )

        # Check half-open limits
        if self.state == CircuitBreakerState.HALF_OPEN:
            if self.half_open_calls >= self.config.circuit_half_open_max_calls:
                # Too many half-open calls without success - reopen
                self._transition_state(CircuitBreakerState.OPEN, "half-open calls exceeded")
                raise Exception(
                    f"[CircuitBreaker:{self.name}] OPEN - max half-open calls exceeded"
                )
            self.half_open_calls += 1

        # Execute with timing
        start = time.time()
        try:
            result = await func(*args, **kwargs)
            duration = (time.time() - start) * 1000  # ms

            self.on_success(duration, trace_ctx)
            return result

        except Exception as e:
            self.on_failure(trace_ctx)
            raise e

    def on_success(self, duration_ms: float, trace_ctx: Optional[TraceContext] = None):
        """Handle successful execution with adaptive learning"""
        with self._lock:
            self.success_count += 1
            self._total_calls += 1
            self._successful_calls += 1
            self.failure_count = max(0, self.failure_count - 1)

        # Transition from half-open to closed
        if self.state == CircuitBreakerState.HALF_OPEN:
            self._transition_state(CircuitBreakerState.CLOSED, "success in half-open")

        # Adaptive threshold adjustment
        if self.adaptive:
            success_rate = self.success_rate
            self.success_rate_history.append_safe(success_rate)

            # Increase threshold if success rate is high (more tolerant)
            if success_rate > 0.95 and self.threshold < 20:
                old_threshold = self.threshold
                self.threshold += 1
                logger.debug(
                    f"[CircuitBreaker:{self.name}] Increased threshold {old_threshold} → {self.threshold}"
                )

        # Record metrics
        if self._metrics:
            self._metrics.record_voice_event(
                event_type=f"circuit_breaker_{self.name}_success",
                trace_ctx=trace_ctx,
                success=True,
                latency_ms=duration_ms
            )

    def on_failure(self, trace_ctx: Optional[TraceContext] = None):
        """Handle failed execution with adaptive learning"""
        with self._lock:
            self.failure_count += 1
            self._total_calls += 1
        self.last_failure_time = time.time()
        self.failure_history.append_safe(time.time())

        # Adaptive threshold adjustment
        if self.adaptive:
            # Get recent failures (last 60 seconds)
            recent_failures = [
                f for f in self.failure_history.get_all_safe()
                if time.time() - f < 60
            ]
            if len(recent_failures) > 5 and self.threshold > 3:
                old_threshold = self.threshold
                self.threshold -= 1
                logger.debug(
                    f"[CircuitBreaker:{self.name}] Decreased threshold {old_threshold} → {self.threshold}"
                )

        # Transition to open if threshold exceeded
        if self.failure_count >= self.threshold:
            self._transition_state(CircuitBreakerState.OPEN, f"failures >= {self.threshold}")

        # Record metrics
        if self._metrics:
            self._metrics.record_voice_event(
                event_type=f"circuit_breaker_{self.name}_failure",
                trace_ctx=trace_ctx,
                success=False
            )

    def get_status(self) -> Dict[str, Any]:
        """Get current circuit breaker status."""
        return {
            "name": self.name,
            "state": self.state.name,
            "failure_count": self.failure_count,
            "success_count": self.success_count,
            "threshold": self.threshold,
            "timeout": self.timeout,
            "success_rate": self.success_rate,
            "last_state_change": self.last_state_change,
            "half_open_calls": self.half_open_calls,
            "adaptive": self.adaptive
        }

    def reset(self) -> None:
        """Reset circuit breaker to initial state."""
        with self._lock:
            self.failure_count = 0
            self.success_count = 0
            self._total_calls = 0
            self._successful_calls = 0
            self.half_open_calls = 0
        self.state = CircuitBreakerState.CLOSED
        self.last_failure_time = None
        self.last_state_change = time.time()
        logger.info(f"[CircuitBreaker:{self.name}] Reset to initial state")


class AsyncEventBus:
    """
    Event-driven pub/sub system for async voice events.
    Enables decoupled, scalable voice command processing.

    v100.0 Enhancements:
    - Bounded event history (prevent memory leaks)
    - Environment-driven configuration
    - W3C trace context propagation
    - Weak references for handlers (prevent memory leaks)
    - Handler timeout protection
    - Metrics integration
    """

    def __init__(self, config: Optional[IroncliwVoiceConfig] = None):
        self.config = config or get_voice_config()
        self.subscribers: Dict[str, List[weakref.ref]] = defaultdict(list)
        self.event_history: BoundedDeque = BoundedDeque(
            maxlen=self.config.max_event_history
        )
        self._lock = threading.Lock()
        self._metrics = get_metrics_persistence()
        self._handler_timeout = self.config.queue_timeout_ms / 1000.0

        logger.info(f"[AsyncEventBus] Initialized with max_history={self.config.max_event_history}")

    def subscribe(self, event_type: str, handler: Callable) -> None:
        """Subscribe to an event type with weak reference."""
        with self._lock:
            # Use weak reference to prevent memory leaks
            ref = weakref.ref(handler) if hasattr(handler, '__self__') else handler
            self.subscribers[event_type].append(ref)
        logger.debug(f"[AsyncEventBus] Subscribed to '{event_type}': {handler.__name__}")

    def unsubscribe(self, event_type: str, handler: Callable) -> None:
        """Unsubscribe from an event type."""
        with self._lock:
            handlers = self.subscribers.get(event_type, [])
            self.subscribers[event_type] = [
                h for h in handlers
                if (callable(h) and h != handler) or
                   (isinstance(h, weakref.ref) and h() != handler)
            ]
        logger.debug(f"[AsyncEventBus] Unsubscribed from '{event_type}': {handler.__name__}")

    def _get_live_handlers(self, event_type: str) -> List[Callable]:
        """Get live handlers, cleaning up dead weak references."""
        with self._lock:
            handlers = self.subscribers.get(event_type, [])
            live_handlers = []
            dead_refs = []

            for h in handlers:
                if isinstance(h, weakref.ref):
                    target = h()
                    if target is not None:
                        live_handlers.append(target)
                    else:
                        dead_refs.append(h)
                elif callable(h):
                    live_handlers.append(h)

            # Clean up dead references
            if dead_refs:
                self.subscribers[event_type] = [
                    h for h in handlers if h not in dead_refs
                ]

            return live_handlers

    async def publish(
        self,
        event_type: str,
        data: Any = None,
        trace_ctx: Optional[TraceContext] = None
    ) -> None:
        """Publish an event to all subscribers with timeout protection."""
        # Generate trace context if not provided
        if trace_ctx is None and self.config.tracing_enabled:
            trace_ctx = TraceContext()

        event = {
            "type": event_type,
            "data": data,
            "timestamp": time.time(),
            "id": f"{event_type}_{uuid.uuid4().hex[:8]}",
            "trace_id": trace_ctx.trace_id if trace_ctx else None,
            "span_id": trace_ctx.span_id if trace_ctx else None
        }

        # Store in bounded history
        self.event_history.append_safe(event)

        # Get live handlers
        handlers = self._get_live_handlers(event_type)
        if not handlers:
            return

        logger.debug(f"[AsyncEventBus] Publishing '{event_type}' to {len(handlers)} handlers")

        # Create tasks with timeout
        tasks = []
        for handler in handlers:
            try:
                if asyncio.iscoroutinefunction(handler):
                    coro = handler(data)
                else:
                    # Run sync handlers in executor
                    loop = asyncio.get_event_loop()
                    coro = loop.run_in_executor(None, handler, data)

                # Wrap with timeout
                tasks.append(asyncio.create_task(
                    asyncio.wait_for(coro, timeout=self._handler_timeout)
                ))

            except Exception as e:
                logger.error(f"[AsyncEventBus] Error creating task for {handler.__name__}: {e}")

        # Wait for all handlers to complete
        if tasks:
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # Log any exceptions
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"[AsyncEventBus] Handler error: {result}")

        # Record metrics
        if self._metrics:
            self._metrics.record_voice_event(
                event_type=f"event_published_{event_type}",
                trace_ctx=trace_ctx,
                metadata={"handler_count": len(handlers)}
            )

    def get_recent_events(self, event_type: Optional[str] = None, limit: int = 10) -> List[Dict[str, Any]]:
        """Get recent events, optionally filtered by type."""
        events = self.event_history.get_all_safe()
        if event_type:
            events = [e for e in events if e.get("type") == event_type]
        return events[-limit:]

    def get_stats(self) -> Dict[str, Any]:
        """Get event bus statistics."""
        with self._lock:
            return {
                "event_types": list(self.subscribers.keys()),
                "handler_counts": {k: len(v) for k, v in self.subscribers.items()},
                "history_size": len(self.event_history),
                "max_history": self.config.max_event_history
            }


class VoiceTaskStatus(Enum):
    """Voice task status with proper enum."""
    PENDING = auto()
    PROCESSING = auto()
    COMPLETED = auto()
    FAILED = auto()
    CANCELLED = auto()
    TIMEOUT = auto()


class VoiceTaskPriority(Enum):
    """Voice task priority levels."""
    BACKGROUND = 0
    LOW = 1
    NORMAL = 2
    HIGH = 3
    CRITICAL = 4
    EMERGENCY = 5


@dataclass
class VoiceTask:
    """
    Represents an async voice recognition task.

    v100.0 Enhancements:
    - Environment-driven max_retries
    - W3C trace context
    - Proper enum-based status and priority
    - Timing metrics
    """
    task_id: str
    text: Optional[str] = None
    confidence: float = 0.0
    timestamp: float = field(default_factory=time.time)
    status: VoiceTaskStatus = VoiceTaskStatus.PENDING
    result: Optional[Any] = None
    error: Optional[str] = None
    priority: VoiceTaskPriority = VoiceTaskPriority.NORMAL
    retries: int = 0
    max_retries: int = field(default_factory=lambda: get_voice_config().max_retries)
    trace_ctx: Optional[TraceContext] = None
    started_at: Optional[float] = None
    completed_at: Optional[float] = None
    source: str = "unknown"
    metadata: Dict[str, Any] = field(default_factory=dict)

    def __post_init__(self):
        """Generate trace context if not provided."""
        if self.trace_ctx is None and get_voice_config().tracing_enabled:
            self.trace_ctx = TraceContext()

    @property
    def duration_ms(self) -> Optional[float]:
        """Get task duration in milliseconds."""
        if self.started_at is None:
            return None
        end_time = self.completed_at or time.time()
        return (end_time - self.started_at) * 1000

    def start(self) -> None:
        """Mark task as started."""
        self.status = VoiceTaskStatus.PROCESSING
        self.started_at = time.time()

    def complete(self, result: Any = None) -> None:
        """Mark task as completed."""
        self.status = VoiceTaskStatus.COMPLETED
        self.completed_at = time.time()
        self.result = result

    def fail(self, error: str) -> None:
        """Mark task as failed."""
        self.status = VoiceTaskStatus.FAILED
        self.completed_at = time.time()
        self.error = error

    def can_retry(self) -> bool:
        """Check if task can be retried."""
        return self.retries < self.max_retries

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "task_id": self.task_id,
            "text": self.text,
            "confidence": self.confidence,
            "timestamp": self.timestamp,
            "status": self.status.name,
            "priority": self.priority.name,
            "retries": self.retries,
            "duration_ms": self.duration_ms,
            "trace_id": self.trace_ctx.trace_id if self.trace_ctx else None,
            "source": self.source
        }


class AsyncVoiceQueue:
    """
    Priority-based async queue for voice commands.
    Ensures fair processing and handles backpressure.

    v100.0 Enhancements:
    - Environment-driven configuration
    - Bounded queue with per-priority limits
    - Backpressure handling with rejection
    - Metrics integration
    - Graceful drain support
    - Task timeout protection
    """

    def __init__(self, config: Optional[IroncliwVoiceConfig] = None):
        self.config = config or get_voice_config()
        self.queue: asyncio.PriorityQueue = asyncio.PriorityQueue(
            maxsize=self.config.queue_maxsize
        )
        self.processing_count = 0
        self.max_concurrent = self.config.max_concurrent
        self.tasks_in_flight: Dict[str, VoiceTask] = {}
        self._lock = asyncio.Lock()
        self._metrics = get_metrics_persistence()
        self._draining = False
        self._dropped_count = 0
        self._total_enqueued = 0
        self._total_completed = 0

        # Per-priority counters
        self._priority_counts: Dict[VoiceTaskPriority, int] = {p: 0 for p in VoiceTaskPriority}

        logger.info(
            f"[AsyncVoiceQueue] Initialized with maxsize={self.config.queue_maxsize}, "
            f"max_concurrent={self.max_concurrent}"
        )

    async def enqueue(
        self,
        task: VoiceTask,
        timeout: Optional[float] = None
    ) -> Tuple[bool, str]:
        """
        Add task to queue with priority.

        Returns:
            Tuple of (success, reason)
        """
        # Check if draining
        if self._draining:
            return False, "queue_draining"

        # Check if queue is full
        if self.queue.full():
            # Try to drop a lower priority task
            if not await self._try_drop_lower_priority(task.priority):
                self._dropped_count += 1
                return False, "queue_full"

        try:
            # Calculate effective timeout
            effective_timeout = timeout or (self.config.queue_timeout_ms / 1000.0)

            # Priority queue uses tuples: (priority, timestamp, task)
            # Negative priority so higher priority = lower number = processed first
            # Timestamp as tiebreaker for same priority (FIFO)
            queue_item = (-task.priority.value, task.timestamp, task)

            await asyncio.wait_for(
                self.queue.put(queue_item),
                timeout=effective_timeout
            )

            async with self._lock:
                self._total_enqueued += 1
                self._priority_counts[task.priority] += 1

            logger.info(
                f"[AsyncVoiceQueue] Enqueued task {task.task_id} "
                f"(priority={task.priority.name}, queue_size={self.queue.qsize()})"
            )

            return True, "enqueued"

        except asyncio.TimeoutError:
            self._dropped_count += 1
            return False, "enqueue_timeout"

    async def _try_drop_lower_priority(self, min_priority: VoiceTaskPriority) -> bool:
        """Try to drop a lower priority task to make room."""
        # This is a simplified implementation - in production you'd want
        # to maintain a separate structure for efficient priority eviction
        return False

    async def dequeue(self, timeout: Optional[float] = None) -> Optional[VoiceTask]:
        """Get next task from queue with timeout."""
        try:
            effective_timeout = timeout or (self.config.queue_timeout_ms / 1000.0)

            _, _, task = await asyncio.wait_for(
                self.queue.get(),
                timeout=effective_timeout
            )

            async with self._lock:
                self.processing_count += 1
                self.tasks_in_flight[task.task_id] = task

            task.start()
            logger.debug(
                f"[AsyncVoiceQueue] Dequeued task {task.task_id} "
                f"(in_flight={self.processing_count})"
            )
            return task

        except asyncio.TimeoutError:
            return None

    async def complete_task(self, task_id: str, success: bool = True) -> None:
        """Mark task as completed."""
        async with self._lock:
            if task_id in self.tasks_in_flight:
                task = self.tasks_in_flight.pop(task_id)
                self.processing_count = max(0, self.processing_count - 1)
                self._total_completed += 1
                self._priority_counts[task.priority] = max(
                    0, self._priority_counts[task.priority] - 1
                )

        try:
            self.queue.task_done()
        except ValueError:
            pass  # Already done

        logger.debug(
            f"[AsyncVoiceQueue] Completed task {task_id} "
            f"(in_flight={self.processing_count})"
        )

        # Record metrics
        if self._metrics:
            self._metrics.record_voice_event(
                event_type="queue_task_completed",
                success=success,
                metadata={"task_id": task_id}
            )

    def is_full(self) -> bool:
        """Check if queue is full."""
        return self.queue.full()

    def size(self) -> int:
        """Get current queue size."""
        return self.queue.qsize()

    async def drain(self, timeout: Optional[float] = None) -> int:
        """
        Drain the queue, waiting for all tasks to complete.

        Returns:
            Number of tasks that were in flight
        """
        self._draining = True
        effective_timeout = timeout or self.config.shutdown_timeout_sec

        logger.info(f"[AsyncVoiceQueue] Starting drain (timeout={effective_timeout}s)")

        start_time = time.time()
        initial_in_flight = self.processing_count

        while self.processing_count > 0:
            if time.time() - start_time > effective_timeout:
                logger.warning(
                    f"[AsyncVoiceQueue] Drain timeout, {self.processing_count} tasks still in flight"
                )
                break
            await asyncio.sleep(0.1)

        self._draining = False
        logger.info(f"[AsyncVoiceQueue] Drain complete")
        return initial_in_flight

    def get_status(self) -> Dict[str, Any]:
        """Get queue status."""
        return {
            "size": self.queue.qsize(),
            "maxsize": self.config.queue_maxsize,
            "in_flight": self.processing_count,
            "max_concurrent": self.max_concurrent,
            "draining": self._draining,
            "dropped_count": self._dropped_count,
            "total_enqueued": self._total_enqueued,
            "total_completed": self._total_completed,
            "priority_counts": {p.name: c for p, c in self._priority_counts.items()}
        }


class VoiceConfidence(Enum):
    """Confidence levels for voice detection"""

    VERY_LOW = 0.2
    LOW = 0.4
    MEDIUM = 0.6
    HIGH = 0.8
    VERY_HIGH = 0.95


@dataclass
class VoiceCommand:
    """Structured voice command data"""

    raw_text: str
    confidence: float
    intent: str
    needs_clarification: bool = False
    timestamp: Optional[datetime] = None

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()


class EnhancedVoiceEngine:
    """
    Enhanced speech recognition with confidence scoring, noise reduction, and ML training.

    v100.0 Enhancements:
    - 100% environment-driven configuration (ZERO hardcoding)
    - Bounded collections for all history arrays
    - Integrated metrics persistence
    - W3C distributed tracing
    - Graceful shutdown with resource cleanup
    - Deep Trinity Voice Coordinator integration
    """

    def __init__(
        self,
        ml_trainer: Optional["VoiceMLTrainer"] = None,
        ml_enhanced_system: Optional["MLEnhancedVoiceSystem"] = None,
        config: Optional[IroncliwVoiceConfig] = None,
    ):
        # Load configuration (100% environment-driven)
        self.config = config or get_voice_config()

        # Speech recognition with multiple engines
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()

        # Metrics persistence
        self._metrics = get_metrics_persistence()

        # ===================================================================
        # ADVANCED ADAPTIVE VOICE RECOGNITION SYSTEM v100.0
        # 100% environment-driven - all parameters from config
        # All history arrays are BOUNDED to prevent memory leaks
        # ===================================================================

        # Adaptive configuration storage - all parameters from environment
        self.adaptive_config = {
            'energy_threshold': {
                'current': self.config.energy_threshold,
                'min': self.config.energy_threshold_min,
                'max': self.config.energy_threshold_max,
                'history': BoundedDeque(maxlen=self.config.max_config_history),
                'success_rate_by_value': LRUBoundedDict(maxsize=self.config.max_dedup_cache)
            },
            'pause_threshold': {
                'current': self.config.pause_threshold,
                'min': self.config.pause_threshold_min,
                'max': self.config.pause_threshold_max,
                'history': BoundedDeque(maxlen=self.config.max_config_history),
                'success_rate_by_value': LRUBoundedDict(maxsize=self.config.max_dedup_cache)
            },
            'damping': {
                'current': self.config.damping,
                'min': self.config.damping_min,
                'max': self.config.damping_max,
                'history': BoundedDeque(maxlen=self.config.max_config_history),
                'success_rate_by_value': LRUBoundedDict(maxsize=self.config.max_dedup_cache)
            },
            'energy_ratio': {
                'current': self.config.energy_ratio,
                'min': self.config.energy_ratio_min,
                'max': self.config.energy_ratio_max,
                'history': BoundedDeque(maxlen=self.config.max_config_history),
                'success_rate_by_value': LRUBoundedDict(maxsize=self.config.max_dedup_cache)
            },
            'phrase_time_limit': {
                'current': self.config.phrase_time_limit,
                'min': self.config.phrase_time_limit_min,
                'max': self.config.phrase_time_limit_max,
                'history': BoundedDeque(maxlen=self.config.max_config_history),
                'success_rate_by_value': LRUBoundedDict(maxsize=self.config.max_dedup_cache)
            },
            'timeout': {
                'current': self.config.listen_timeout,
                'min': self.config.listen_timeout_min,
                'max': self.config.listen_timeout_max,
                'history': BoundedDeque(maxlen=self.config.max_config_history),
                'success_rate_by_value': LRUBoundedDict(maxsize=self.config.max_dedup_cache)
            },
        }

        # Performance tracking with BOUNDED collections
        self.performance_metrics = {
            'successful_recognitions': 0,
            'failed_recognitions': 0,
            'low_confidence_count': 0,
            'timeout_count': 0,
            'false_activation_count': 0,
            'average_confidence': BoundedDeque(maxlen=self.config.max_confidence_history),
            'recognition_times': BoundedDeque(maxlen=self.config.max_recognition_times),
            'consecutive_failures': 0,
            'consecutive_successes': 0,
            'first_attempt_success_rate': BoundedDeque(maxlen=self.config.max_first_attempt_history),
        }

        # User voice pattern learning with BOUNDED collections
        self.user_voice_profile = {
            'average_pitch': None,
            'speech_rate': None,
            'typical_pause_duration': None,
            'command_length_distribution': BoundedDeque(maxlen=self.config.max_command_history),
            'frequently_misrecognized_words': LRUBoundedDict(maxsize=self.config.max_dedup_cache),
            'command_start_patterns': BoundedDeque(maxlen=self.config.max_command_history),
            'preferred_phrasing': LRUBoundedDict(maxsize=self.config.max_dedup_cache),
        }

        # Multi-engine configuration from environment with BOUNDED history
        self.recognition_engines = self.config.recognition_engines
        self.engine_performance = {
            engine: {
                'success': 0,
                'fail': 0,
                'avg_confidence': BoundedDeque(maxlen=self.config.max_engine_history),
                'avg_speed': BoundedDeque(maxlen=self.config.max_engine_history)
            } for engine in self.recognition_engines
        }
        self.current_engine = self.config.default_engine

        # Optimization from environment
        self.optimization_thread = None
        self.optimization_interval = self.config.optimization_interval_sec
        self.stop_optimization = False
        self.optimization_enabled = self.config.optimization_enabled

        # Initialize with adaptive settings
        self._initialize_adaptive_recognition()

        # Start background optimization if enabled
        if self.optimization_enabled:
            self._start_optimization_thread()

        # Text-to-speech — AudioBus-aware initialization
        self._audio_bus_enabled = os.getenv(
            "Ironcliw_AUDIO_BUS_ENABLED", "false"
        ).lower() in ("true", "1", "yes")
        if self._audio_bus_enabled:
            self.tts_engine: Union[MacOSVoice, Any] = None  # Lazy: use _get_tts() to acquire
        elif USE_MACOS_VOICE:
            self.tts_engine = MacOSVoice()
        else:
            self.tts_engine = pyttsx3.init()
        if self.tts_engine is not None:
            self._setup_voice()

        # Audio feedback
        pygame.mixer.init()
        self.listening = False

        # Noise profile for reduction
        self.noise_profile = None

        # ML trainer for adaptive learning
        self.ml_trainer = ml_trainer
        self.ml_enhanced_system = ml_enhanced_system
        self.last_audio_data = None

        # ===================================================================
        # ADVANCED ASYNC COMPONENTS v100.0 - Environment-Driven
        # ===================================================================

        # Circuit breaker for fault tolerance (uses config internally)
        self.circuit_breaker = AdaptiveCircuitBreaker(
            name="voice_recognition",
            config=self.config
        )
        logger.info("[EnhancedVoiceEngine] Initialized adaptive circuit breaker")

        # Event bus for event-driven architecture (uses config internally)
        self.event_bus = AsyncEventBus(config=self.config)
        logger.info("[EnhancedVoiceEngine] Initialized async event bus")

        # Async queue for command processing (uses config internally)
        self.voice_queue = AsyncVoiceQueue(config=self.config)
        logger.info("[EnhancedVoiceEngine] Initialized async voice queue")

        # ===================================================================
        # BACKGROUND SYSTEM MONITOR v100.0 - Environment-Driven
        # ===================================================================

        # Cached system metrics (updated by background monitor)
        self._cached_cpu_usage = 0.0
        self._cached_memory_usage = 0.0
        self._last_metric_update = time.time()
        self._metric_cache_duration = self.config.metric_cache_duration_sec
        self._system_monitor_task = None
        self._monitor_running = False
        self._shutdown_requested = False

        logger.info(
            f"[EnhancedVoiceEngine] Initialized with "
            f"energy_threshold={self.config.energy_threshold}, "
            f"optimization_interval={self.optimization_interval}s"
        )

        # Subscribe to voice events
        self._setup_event_handlers()

        # Intent patterns for better recognition
        self.intent_patterns = {
            "question": [
                "what",
                "when",
                "where",
                "who",
                "why",
                "how",
                "is",
                "are",
                "can",
                "could",
            ],
            "action": [
                "open",
                "close",
                "start",
                "stop",
                "play",
                "pause",
                "set",
                "turn",
                "activate",
                "launch",
            ],
            "information": [
                "tell",
                "show",
                "find",
                "search",
                "look",
                "get",
                "fetch",
                "explain",
            ],
            "system": [
                "system",
                "status",
                "diagnostic",
                "check",
                "monitor",
                "analyze",
                "report",
            ],
            "conversation": [
                "chat",
                "talk",
                "discuss",
                "explain",
                "describe",
                "hello",
                "hi",
            ],
        }

    async def _get_tts(self):
        """Get the TTS singleton (lazy init)."""
        if self.tts_engine is None and getattr(self, '_audio_bus_enabled', False):
            try:
                from backend.voice.engines.unified_tts_engine import get_tts_engine
                self.tts_engine = await get_tts_engine()
            except Exception as e:
                logger.debug(f"TTS singleton unavailable: {e}")
        return self.tts_engine

    def _setup_voice(self):
        """Configure Ironcliw voice settings from environment."""
        if USE_MACOS_VOICE:
            # macOS voice - use config-driven rate
            self.tts_engine.setProperty("rate", self.config.tts_rate)
        else:
            voices = self.tts_engine.getProperty("voices")

            # Try to find voice matching preference from config
            preferred_voice = None
            voice_preference = self.config.tts_voice_preference.lower()

            if voices:
                for voice in voices:
                    voice_name_lower = voice.name.lower()
                    # Check if voice matches preference
                    if voice_preference in voice_name_lower:
                        if "male" in voice_name_lower or not any(
                            word in voice_name_lower for word in ["female", "woman"]
                        ):
                            preferred_voice = voice.id
                            break

            if preferred_voice:
                self.tts_engine.setProperty("voice", preferred_voice)
                logger.info(f"[TTS] Using preferred voice: {preferred_voice}")

            # Set speech rate and volume from config
            self.tts_engine.setProperty("rate", self.config.tts_rate)
            self.tts_engine.setProperty("volume", self.config.tts_volume)

    def calibrate_microphone(self, duration: Optional[int] = None):
        """Enhanced calibration with noise profiling (duration from config)."""
        # Use config-driven duration if not specified
        effective_duration = duration if duration is not None else self.config.calibration_duration_sec

        with self.microphone as source:
            print("🎤 Calibrating for ambient noise... Please remain quiet.")

            # Adjust for ambient noise with config-driven duration
            self.recognizer.adjust_for_ambient_noise(source, duration=effective_duration)

            # Record noise sample for profile
            try:
                print("📊 Creating noise profile...")
                audio = self.recognizer.listen(source, timeout=1, phrase_time_limit=5)
                # Store noise profile for future noise reduction
                self.noise_profile = audio.get_raw_data()
                print("✅ Calibration complete. Noise profile created.")
            except Exception:
                print("✅ Calibration complete.")

    def listen_with_confidence(
        self, timeout: int = 1, phrase_time_limit: int = 8
    ) -> Tuple[Optional[str], float]:
        """Listen for speech and return text with confidence score"""
        with self.microphone as source:
            try:
                # Play listening sound
                self._play_sound("listening")
                self.listening = True

                # Clear the buffer
                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)

                audio = self.recognizer.listen(
                    source, timeout=timeout, phrase_time_limit=phrase_time_limit
                )

                self.listening = False

                # Store audio data for ML training
                self.last_audio_data = np.frombuffer(
                    audio.get_raw_data(), dtype=np.int16
                )

                # Try multiple recognition methods for better accuracy
                recognition_results = []
                confidence = 0.0

                # Google Speech Recognition with alternatives
                try:
                    google_result = self.recognizer.recognize_google(
                        audio, show_all=True, language="en-US"
                    )

                    if google_result and "alternative" in google_result:
                        for i, alternative in enumerate(google_result["alternative"]):
                            text = alternative.get("transcript", "").lower()
                            # Google provides confidence only for the first alternative
                            conf = alternative.get("confidence", 0.8 - (i * 0.1))
                            recognition_results.append((text, conf))
                except Exception as e:
                    logger.debug(f"Google recognition failed: {e}")

                # If we have results, return the best one
                if recognition_results:
                    # Sort by confidence
                    recognition_results.sort(key=lambda x: x[1], reverse=True)
                    best_text, best_confidence = recognition_results[0]

                    # Apply confidence adjustments based on audio quality
                    adjusted_confidence = self._adjust_confidence(
                        audio, best_confidence
                    )

                    # Check ML predictions if available
                    if self.ml_trainer and best_text:
                        predicted_correction = self.ml_trainer.predict_correction(
                            best_text,
                            adjusted_confidence,
                            self.ml_trainer.extract_audio_features(
                                self.last_audio_data
                            ),
                        )
                        if predicted_correction:
                            logger.info(
                                f"ML prediction: '{best_text}' -> '{predicted_correction}'"
                            )
                            # You might want to return the prediction with higher confidence
                            # For now, we'll just log it

                    # Record successful recognition for adaptive learning
                    self._record_recognition_result(
                        success=True,
                        confidence=adjusted_confidence,
                        first_attempt=True  # Assume first attempt in listen_with_confidence
                    )

                    return best_text, adjusted_confidence

                # No results - record failure
                self._record_recognition_result(success=False, first_attempt=True)
                return None, 0.0

            except sr.WaitTimeoutError:
                self.listening = False
                # Record timeout for adaptive optimization
                self.performance_metrics['timeout_count'] += 1
                self._record_recognition_result(success=False, first_attempt=True)
                return None, 0.0
            except sr.UnknownValueError:
                self.listening = False
                # Speech detected but not understood - record failure
                self._record_recognition_result(success=False, first_attempt=True)
                return None, 0.0
            except Exception as e:
                logger.error(f"Error in speech recognition: {e}")
                self.listening = False
                # Unexpected error - record failure
                self._record_recognition_result(success=False, first_attempt=True)
                return None, 0.0

    def _adjust_confidence(self, audio: sr.AudioData, base_confidence: float) -> float:
        """Adjust confidence based on audio quality metrics"""
        try:
            # Convert audio to numpy array
            raw_data = np.frombuffer(audio.get_raw_data(), dtype=np.int16)

            # Calculate audio quality metrics
            energy = np.sqrt(np.mean(raw_data**2))  # RMS energy

            # Very quiet audio is less reliable
            if energy < 100:
                base_confidence *= 0.7
            elif energy > 5000:  # Very loud (possible distortion)
                base_confidence *= 0.9

            # Check for clipping
            if np.any(np.abs(raw_data) > 32000):  # Near max int16 value
                base_confidence *= 0.8

            return min(base_confidence, 1.0)
        except Exception:
            return base_confidence

    def detect_intent(self, text: str) -> str:
        """Detect the intent of the command"""
        if not text:
            return "unknown"

        text_lower = text.lower()

        # Check against intent patterns
        for intent, keywords in self.intent_patterns.items():
            if any(keyword in text_lower.split() for keyword in keywords):
                return intent

        return "conversation"  # Default intent

    def speak(self, text: str, interrupt_callback: Optional[Callable] = None):
        """Convert text to speech with Ironcliw voice"""
        # Add subtle processing sound
        self._play_sound("processing")

        # AudioBus lazy path — tts_engine may be None until async init
        if self.tts_engine is None:
            logger.debug("[TTS] Engine not yet initialized (lazy), skipping speak")
            return

        # Speak
        if USE_MACOS_VOICE:
            self.tts_engine.say_and_wait(text)
        else:
            self.tts_engine.say(text)
            self.tts_engine.runAndWait()

    # ===================================================================
    # ADAPTIVE RECOGNITION METHODS
    # ===================================================================

    def _initialize_adaptive_recognition(self):
        """Initialize adaptive recognition with current config values"""
        try:
            # Apply current adaptive config to recognizer
            self.recognizer.energy_threshold = self.adaptive_config['energy_threshold']['current']
            self.recognizer.pause_threshold = self.adaptive_config['pause_threshold']['current']
            self.recognizer.dynamic_energy_threshold = True
            self.recognizer.dynamic_energy_adjustment_damping = self.adaptive_config['damping']['current']
            self.recognizer.dynamic_energy_ratio = self.adaptive_config['energy_ratio']['current']

            logger.info(f"[ADAPTIVE] Initialized with: energy={self.recognizer.energy_threshold}, "
                       f"pause={self.recognizer.pause_threshold}")
        except Exception as e:
            logger.error(f"[ADAPTIVE] Failed to initialize: {e}")

    def _start_optimization_thread(self):
        """Start background thread to optimize recognition parameters (DEPRECATED - use async version)"""
        # This method is deprecated but kept for compatibility
        # The async version (_start_optimization_async) should be used instead
        logger.warning("[ADAPTIVE] Sync optimization thread is deprecated. Use async version instead.")

    async def _start_optimization_async(self):
        """Start background async task to optimize recognition parameters (NON-BLOCKING)"""
        async def optimize_loop():
            """Continuous optimization based on performance metrics"""
            while not self.stop_optimization:
                try:
                    await asyncio.sleep(self.optimization_interval)

                    # Run optimization in executor to avoid blocking
                    loop = asyncio.get_event_loop()
                    await loop.run_in_executor(None, self._optimize_parameters)

                except asyncio.CancelledError:
                    logger.info("[ADAPTIVE] Optimization task cancelled")
                    break
                except Exception as e:
                    logger.error(f"[ADAPTIVE] Optimization error: {e}")

        # Create and store the task
        self.optimization_task = asyncio.create_task(optimize_loop())
        logger.info("[ADAPTIVE] Async optimization task started")

    def _optimize_parameters(self):
        """
        Dynamically optimize recognition parameters based on success metrics.
        NO environmental noise - purely based on user recognition success!
        """
        total_attempts = self.performance_metrics['successful_recognitions'] + self.performance_metrics['failed_recognitions']

        if total_attempts < 5:
            # Not enough data yet
            return

        success_rate = self.performance_metrics['successful_recognitions'] / total_attempts

        logger.info(f"[ADAPTIVE] Optimizing... Success rate: {success_rate:.2%}, "
                   f"Successes: {self.performance_metrics['successful_recognitions']}, "
                   f"Failures: {self.performance_metrics['failed_recognitions']}")

        # Adaptive strategy based on failure patterns
        if success_rate < 0.7:  # Less than 70% success - need improvement
            # Too many failures - make system more sensitive
            self._adjust_parameter('energy_threshold', direction='decrease', amount=10)
            self._adjust_parameter('pause_threshold', direction='decrease', amount=0.05)
            self._adjust_parameter('timeout', direction='decrease', amount=0.1)
            logger.info("[ADAPTIVE] Low success rate - increasing sensitivity")

        elif self.performance_metrics['false_activation_count'] > total_attempts * 0.3:
            # Too many false activations - make less sensitive
            self._adjust_parameter('energy_threshold', direction='increase', amount=10)
            self._adjust_parameter('pause_threshold', direction='increase', amount=0.05)
            logger.info("[ADAPTIVE] Too many false activations - decreasing sensitivity")

        elif self.performance_metrics['timeout_count'] > total_attempts * 0.3:
            # Too many timeouts - give more time
            self._adjust_parameter('timeout', direction='increase', amount=0.2)
            self._adjust_parameter('phrase_time_limit', direction='increase', amount=1)
            logger.info("[ADAPTIVE] Too many timeouts - extending time limits")

        # Check first-attempt success rate
        if len(self.performance_metrics['first_attempt_success_rate']) >= 10:
            first_attempt_rate = sum(self.performance_metrics['first_attempt_success_rate'][-10:]) / 10
            if first_attempt_rate < 0.5:  # Less than 50% work on first try
                # Speed up responsiveness
                self._adjust_parameter('pause_threshold', direction='decrease', amount=0.05)
                self._adjust_parameter('timeout', direction='decrease', amount=0.1)
                logger.info(f"[ADAPTIVE] First-attempt rate low ({first_attempt_rate:.2%}) - speeding up")

        # Apply optimized values to recognizer
        self._apply_adaptive_config()

    def _adjust_parameter(self, param_name: str, direction: str, amount: float):
        """Adjust a parameter within its min/max range"""
        config = self.adaptive_config[param_name]
        current = config['current']

        # Calculate new value
        if direction == 'increase':
            new_value = min(current + amount, config['max'])
        else:  # decrease
            new_value = max(current - amount, config['min'])

        # Store old value in history (BoundedDeque handles size automatically)
        config['history'].append(current)

        # Update current value
        config['current'] = new_value

        logger.debug(f"[ADAPTIVE] {param_name}: {current:.3f} → {new_value:.3f}")

    def _apply_adaptive_config(self):
        """Apply current adaptive config to recognizer"""
        try:
            self.recognizer.energy_threshold = self.adaptive_config['energy_threshold']['current']
            self.recognizer.pause_threshold = self.adaptive_config['pause_threshold']['current']
            self.recognizer.dynamic_energy_adjustment_damping = self.adaptive_config['damping']['current']
            self.recognizer.dynamic_energy_ratio = self.adaptive_config['energy_ratio']['current']

            logger.debug("[ADAPTIVE] Applied new config to recognizer")
        except Exception as e:
            logger.error(f"[ADAPTIVE] Failed to apply config: {e}")

    def _record_recognition_result(
        self,
        success: bool,
        confidence: float = 0.0,
        first_attempt: bool = False,
        false_activation: bool = False,
        trace_ctx: Optional[TraceContext] = None
    ):
        """
        Record recognition result for adaptive learning.
        Uses bounded collections - no manual size management needed.

        v100.0: Added trace context and metrics persistence.
        """
        if success:
            self.performance_metrics['successful_recognitions'] += 1
            self.performance_metrics['consecutive_successes'] += 1
            self.performance_metrics['consecutive_failures'] = 0

            if confidence > 0:
                # BoundedDeque handles size automatically
                self.performance_metrics['average_confidence'].append(confidence)
        else:
            self.performance_metrics['failed_recognitions'] += 1
            self.performance_metrics['consecutive_failures'] += 1
            self.performance_metrics['consecutive_successes'] = 0

        if false_activation:
            self.performance_metrics['false_activation_count'] += 1

        if first_attempt:
            # BoundedDeque handles size automatically
            self.performance_metrics['first_attempt_success_rate'].append(1 if success else 0)

        # Record to metrics persistence
        if self._metrics:
            self._metrics.record_voice_event(
                event_type="recognition_result",
                trace_ctx=trace_ctx,
                success=success,
                confidence=confidence,
                metadata={
                    "first_attempt": first_attempt,
                    "false_activation": false_activation,
                    "consecutive_failures": self.performance_metrics['consecutive_failures'],
                    "engine": self.current_engine
                }
            )

        # Track which parameter values lead to success
        for param_name, config in self.adaptive_config.items():
            current_value = config['current']
            value_key = f"{current_value:.2f}"

            if value_key not in config['success_rate_by_value']:
                config['success_rate_by_value'][value_key] = {'success': 0, 'fail': 0}

            if success:
                config['success_rate_by_value'][value_key]['success'] += 1
            else:
                config['success_rate_by_value'][value_key]['fail'] += 1

        # Trigger immediate optimization if we hit a streak
        if self.performance_metrics['consecutive_failures'] >= 3:
            logger.warning("[ADAPTIVE] 3 consecutive failures - triggering immediate optimization")
            self._optimize_parameters()
        elif self.performance_metrics['consecutive_successes'] >= 10:
            logger.info("[ADAPTIVE] 10 consecutive successes - system is well-tuned")

    # ===================================================================
    # ASYNC EVENT & QUEUE METHODS
    # ===================================================================

    def _setup_event_handlers(self):
        """Setup async event handlers for voice events"""
        # Subscribe to voice recognition events
        self.event_bus.subscribe("voice_recognized", self._on_voice_recognized)
        self.event_bus.subscribe("voice_failed", self._on_voice_failed)
        self.event_bus.subscribe("circuit_breaker_open", self._on_circuit_breaker_open)
        logger.info("[ASYNC-EVENT] Setup event handlers for voice processing")

    def _on_voice_recognized(self, data: Dict[str, Any]):
        """Handler for voice recognition success"""
        logger.debug(f"[ASYNC-EVENT] Voice recognized: {data.get('text', 'N/A')}")

    def _on_voice_failed(self, data: Dict[str, Any]):
        """Handler for voice recognition failure"""
        logger.warning(f"[ASYNC-EVENT] Voice recognition failed: {data.get('error', 'Unknown error')}")

    def _on_circuit_breaker_open(self, data: Dict[str, Any]):
        """Handler for circuit breaker opening"""
        logger.error(f"[ASYNC-EVENT] Circuit breaker opened - voice recognition temporarily unavailable")

    async def listen_async(
        self,
        timeout: Optional[float] = None,
        phrase_time_limit: Optional[int] = None,
        priority: VoiceTaskPriority = VoiceTaskPriority.NORMAL,
        trace_ctx: Optional[TraceContext] = None
    ) -> Tuple[Optional[str], float]:
        """
        Advanced async voice recognition with circuit breaker and event bus.
        Fully integrated with async_pipeline architecture v100.0.

        Args:
            timeout: Listen timeout (default from config)
            phrase_time_limit: Max phrase duration (default from config)
            priority: Task priority level
            trace_ctx: W3C trace context for distributed tracing
        """
        # Use config defaults
        effective_timeout = timeout if timeout is not None else self.config.listen_timeout
        effective_phrase_limit = phrase_time_limit if phrase_time_limit is not None else self.config.phrase_time_limit

        task_id = f"voice_{uuid.uuid4().hex[:12]}"

        # Create trace context if not provided
        if trace_ctx is None and self.config.tracing_enabled:
            trace_ctx = TraceContext()

        # Create voice task with proper enums
        task = VoiceTask(
            task_id=task_id,
            priority=priority,
            timestamp=time.time(),
            trace_ctx=trace_ctx,
            source="listen_async"
        )

        try:
            # Check if queue is full
            if self.voice_queue.is_full():
                logger.warning(
                    f"[listen_async] Queue full ({self.voice_queue.size()}/{self.config.queue_maxsize}) - "
                    f"rejecting task {task_id}"
                )
                await self.event_bus.publish("queue_full", {"task_id": task_id}, trace_ctx=trace_ctx)
                return None, 0.0

            # Enqueue task
            success, reason = await self.voice_queue.enqueue(task)
            if not success:
                logger.warning(f"[listen_async] Enqueue failed: {reason}")
                return None, 0.0

            # Execute with circuit breaker protection
            async def recognize_wrapper():
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(
                    None,
                    lambda: self.listen_with_confidence(int(effective_timeout), effective_phrase_limit)
                )
                return result

            # Call with circuit breaker and trace context
            text, confidence = await self.circuit_breaker.call(
                recognize_wrapper,
                trace_ctx=trace_ctx
            )

            # Update task
            task.text = text
            task.confidence = confidence
            task.complete(result={"text": text, "confidence": confidence})

            # Publish success event with trace context
            if text:
                await self.event_bus.publish(
                    "voice_recognized",
                    {
                        "task_id": task_id,
                        "text": text,
                        "confidence": confidence,
                        "timestamp": time.time()
                    },
                    trace_ctx=trace_ctx
                )

            # Complete task in queue
            await self.voice_queue.complete_task(task_id, success=True)

            # Record metrics
            if self._metrics:
                self._metrics.record_voice_event(
                    event_type="listen_async_success",
                    trace_ctx=trace_ctx,
                    success=True,
                    confidence=confidence,
                    latency_ms=task.duration_ms
                )

            return text, confidence

        except Exception as e:
            logger.error(f"[listen_async] Error: {e}")

            # Update task as failed
            task.fail(str(e))

            # Publish failure event
            await self.event_bus.publish(
                "voice_failed",
                {"task_id": task_id, "error": str(e), "timestamp": time.time()},
                trace_ctx=trace_ctx
            )

            # Complete task in queue
            await self.voice_queue.complete_task(task_id, success=False)

            # Record metrics
            if self._metrics:
                self._metrics.record_voice_event(
                    event_type="listen_async_failure",
                    trace_ctx=trace_ctx,
                    success=False,
                    latency_ms=task.duration_ms,
                    metadata={"error": str(e)}
                )

            return None, 0.0

    async def process_voice_queue_worker(self):
        """
        Background worker that processes the voice queue.
        Enables concurrent voice command processing.
        Supports graceful shutdown via _shutdown_requested flag.
        """
        logger.info("[VoiceQueueWorker] Started")

        while not self._shutdown_requested:
            try:
                # Check if we can process more tasks
                if self.voice_queue.processing_count >= self.voice_queue.max_concurrent:
                    await asyncio.sleep(0.1)
                    continue

                # Get next task with timeout (allows checking shutdown flag)
                task = await self.voice_queue.dequeue(timeout=1.0)
                if task is None:
                    continue

                logger.debug(f"[VoiceQueueWorker] Processing task {task.task_id}")

                # Process async
                asyncio.create_task(self._process_voice_task(task))

            except asyncio.CancelledError:
                logger.info("[VoiceQueueWorker] Cancelled, initiating shutdown")
                break
            except Exception as e:
                logger.error(f"[VoiceQueueWorker] Error: {e}")
                await asyncio.sleep(1)

        logger.info("[VoiceQueueWorker] Stopped")

    async def _process_voice_task(self, task: VoiceTask):
        """Process a single voice task with proper status handling."""
        try:
            # Execute voice recognition with task's priority and trace context
            text, confidence = await self.listen_async(
                priority=task.priority,
                trace_ctx=task.trace_ctx
            )

            # Update task
            task.text = text
            task.confidence = confidence
            task.complete(result={"text": text, "confidence": confidence})

        except Exception as e:
            logger.error(f"[_process_voice_task] Error for {task.task_id}: {e}")
            task.fail(str(e))

        finally:
            # Always complete the task in queue
            await self.voice_queue.complete_task(task.task_id)

    # ===================================================================
    # GRACEFUL SHUTDOWN v100.0
    # ===================================================================

    async def shutdown(self, timeout: Optional[float] = None) -> Dict[str, Any]:
        """
        Gracefully shutdown the voice engine.

        Args:
            timeout: Shutdown timeout (default from config)

        Returns:
            Shutdown statistics
        """
        effective_timeout = timeout if timeout is not None else self.config.shutdown_timeout_sec
        logger.info(f"[EnhancedVoiceEngine] Starting graceful shutdown (timeout={effective_timeout}s)")

        self._shutdown_requested = True
        stats = {
            "start_time": time.time(),
            "queue_drained": False,
            "tasks_in_flight": self.voice_queue.processing_count,
            "queue_size": self.voice_queue.size()
        }

        try:
            # Stop optimization
            self.stop_optimization = True
            if hasattr(self, 'optimization_task'):
                self.optimization_task.cancel()
                try:
                    await asyncio.wait_for(self.optimization_task, timeout=2.0)
                except (asyncio.CancelledError, asyncio.TimeoutError):
                    pass
            logger.info("[Shutdown] Optimization stopped")

            # Stop system monitor
            await self.stop_system_monitor()
            logger.info("[Shutdown] System monitor stopped")

            # Drain queue if configured
            if self.config.shutdown_drain_queue:
                drained = await self.voice_queue.drain(timeout=effective_timeout / 2)
                stats["queue_drained"] = True
                stats["tasks_drained"] = drained
                logger.info(f"[Shutdown] Queue drained ({drained} tasks)")

            # Close metrics persistence
            if self._metrics:
                self._metrics.close()
                logger.info("[Shutdown] Metrics persistence closed")

            stats["end_time"] = time.time()
            stats["duration_sec"] = stats["end_time"] - stats["start_time"]
            stats["success"] = True

            logger.info(f"[EnhancedVoiceEngine] Shutdown complete in {stats['duration_sec']:.2f}s")

        except Exception as e:
            logger.error(f"[Shutdown] Error: {e}")
            stats["success"] = False
            stats["error"] = str(e)

        return stats

    def get_health(self) -> Dict[str, Any]:
        """Get comprehensive health status."""
        return {
            "version": "100.0",
            "running": not self._shutdown_requested,
            "circuit_breaker": self.circuit_breaker.get_status(),
            "queue": self.voice_queue.get_status(),
            "event_bus": self.event_bus.get_stats(),
            "system_metrics": self.get_system_health(),
            "performance": {
                "successful_recognitions": self.performance_metrics["successful_recognitions"],
                "failed_recognitions": self.performance_metrics["failed_recognitions"],
                "consecutive_failures": self.performance_metrics["consecutive_failures"],
                "current_engine": self.current_engine
            },
            "config": {
                "energy_threshold": self.adaptive_config["energy_threshold"]["current"],
                "pause_threshold": self.adaptive_config["pause_threshold"]["current"],
                "optimization_enabled": self.optimization_enabled
            }
        }

    # ===================================================================
    # BACKGROUND SYSTEM MONITOR - Non-blocking CPU/Memory/Performance tracking
    # ===================================================================

    async def start_system_monitor(self):
        """Start the background system monitor for non-blocking metrics"""
        if self._monitor_running:
            logger.warning("[SYSTEM-MONITOR] Monitor already running")
            return

        self._monitor_running = True
        self._system_monitor_task = asyncio.create_task(self._system_monitor_loop())
        logger.info("[SYSTEM-MONITOR] Started background system monitor")

    async def stop_system_monitor(self):
        """Stop the background system monitor"""
        if not self._monitor_running:
            return

        self._monitor_running = False
        if self._system_monitor_task:
            self._system_monitor_task.cancel()
            try:
                await self._system_monitor_task
            except asyncio.CancelledError:
                pass
        logger.info("[SYSTEM-MONITOR] Stopped background system monitor")

    async def _system_monitor_loop(self):
        """
        Background loop that monitors system metrics non-blockingly.
        Updates cached values for instant access without blocking.
        """
        logger.info("[SYSTEM-MONITOR] Monitor loop started")

        # Track monitoring performance
        monitor_iterations = 0
        monitor_errors = 0
        last_alert_time = 0

        while self._monitor_running:
            try:
                # Run psutil in executor to avoid blocking the event loop
                loop = asyncio.get_event_loop()

                # Get CPU usage non-blockingly (interval=None for instant reading)
                cpu_task = loop.run_in_executor(
                    None,
                    lambda: __import__('psutil').cpu_percent(interval=None)
                )

                # Get memory usage non-blockingly
                memory_task = loop.run_in_executor(
                    None,
                    lambda: __import__('psutil').virtual_memory().percent
                )

                # Wait for both with timeout protection
                try:
                    cpu_usage, memory_usage = await asyncio.wait_for(
                        asyncio.gather(cpu_task, memory_task),
                        timeout=2.0
                    )

                    # Update cached values atomically
                    self._cached_cpu_usage = cpu_usage
                    self._cached_memory_usage = memory_usage
                    self._last_metric_update = time.time()

                    monitor_iterations += 1

                    # Alert on high resource usage (max once per 30 seconds)
                    current_time = time.time()
                    if current_time - last_alert_time > 30:
                        if cpu_usage > 80:
                            logger.warning(f"[SYSTEM-MONITOR] High CPU usage: {cpu_usage:.1f}%")
                            await self.event_bus.publish("high_cpu", {"cpu": cpu_usage})
                            last_alert_time = current_time
                        elif memory_usage > 85:
                            logger.warning(f"[SYSTEM-MONITOR] High memory usage: {memory_usage:.1f}%")
                            await self.event_bus.publish("high_memory", {"memory": memory_usage})
                            last_alert_time = current_time

                    # Log stats every 100 iterations (about 100 seconds)
                    if monitor_iterations % 100 == 0:
                        logger.debug(
                            f"[SYSTEM-MONITOR] Stats - CPU: {cpu_usage:.1f}%, "
                            f"Memory: {memory_usage:.1f}%, Iterations: {monitor_iterations}, "
                            f"Errors: {monitor_errors}"
                        )

                except asyncio.TimeoutError:
                    logger.warning("[SYSTEM-MONITOR] Metrics collection timeout")
                    monitor_errors += 1

                # Update every 1 second (non-blocking sleep)
                await asyncio.sleep(self._metric_cache_duration)

            except asyncio.CancelledError:
                logger.info("[SYSTEM-MONITOR] Monitor loop cancelled")
                break
            except Exception as e:
                logger.error(f"[SYSTEM-MONITOR] Error in monitor loop: {e}")
                monitor_errors += 1
                await asyncio.sleep(5)  # Back off on errors

    def get_cached_cpu_usage(self) -> float:
        """
        Get cached CPU usage (non-blocking, instant).
        Returns cached value updated by background monitor.
        """
        # Check if cache is stale
        cache_age = time.time() - self._last_metric_update
        if cache_age > 5.0:  # Cache older than 5 seconds
            logger.warning(
                f"[SYSTEM-MONITOR] CPU cache is stale ({cache_age:.1f}s old). "
                "Monitor may not be running."
            )

        return self._cached_cpu_usage

    def get_cached_memory_usage(self) -> float:
        """
        Get cached memory usage (non-blocking, instant).
        Returns cached value updated by background monitor.
        """
        cache_age = time.time() - self._last_metric_update
        if cache_age > 5.0:
            logger.warning(
                f"[SYSTEM-MONITOR] Memory cache is stale ({cache_age:.1f}s old). "
                "Monitor may not be running."
            )

        return self._cached_memory_usage

    def get_system_health(self) -> Dict[str, Any]:
        """
        Get comprehensive system health metrics (non-blocking).
        Returns cached metrics with metadata.
        """
        cache_age = time.time() - self._last_metric_update

        return {
            "cpu_percent": self._cached_cpu_usage,
            "memory_percent": self._cached_memory_usage,
            "cache_age_seconds": cache_age,
            "cache_fresh": cache_age < 2.0,
            "monitor_running": self._monitor_running,
            "timestamp": self._last_metric_update,
        }

    def _play_sound(self, sound_type: str):
        """Play UI sounds for feedback"""
        # In a real implementation, you'd have actual sound files
        # For now, we'll just use beeps
        if sound_type == "listening":
            print("🎤 *listening*")
        elif sound_type == "processing":
            print("⚡ *processing*")
        elif sound_type == "error":
            print("❌ *error*")
        elif sound_type == "success":
            print("✅ *success*")


class EnhancedIroncliwPersonality:
    """Enhanced Ironcliw personality with voice-specific intelligence and ML integration"""

    def __init__(
        self, claude_api_key: str, ml_trainer: Optional["VoiceMLTrainer"] = None
    ):
        self.claude = Anthropic(api_key=claude_api_key)
        self.context = []
        self.voice_context = []  # Separate context for voice commands
        self.user_preferences = {
            "name": "Sir",  # Can be customized
            "work_hours": (9, 18),
            "break_reminder": True,
            "humor_level": "moderate",
        }
        self.last_break = datetime.now()

        # Voice command history for learning patterns
        self.command_history = []

        # ML trainer for adaptive learning
        self.ml_trainer = ml_trainer

        # Voice engine reference (for accessing system metrics)
        self._voice_engine = None

        # Initialize weather service
        if WEATHER_SERVICE_AVAILABLE:
            self.weather_service = WeatherService()
        else:
            self.weather_service = None

    def set_voice_engine(self, voice_engine: "EnhancedVoiceEngine"):
        """Set reference to voice engine for system metrics access"""
        self._voice_engine = voice_engine
        logger.info("[PERSONALITY] Voice engine reference set for system metrics")
    
    def _local_command_interpretation(self, text: str, confidence: float) -> str:
        """Local command interpretation when Claude is unavailable or CPU is high"""
        import re
        text_lower = text.lower()
        
        # Common patterns
        if "open" in text_lower:
            app_matches = re.findall(r'open\s+(\w+)', text_lower)
            if app_matches:
                return f"COMMAND: launch_app({app_matches[0]})"
        elif "close" in text_lower:
            app_matches = re.findall(r'close\s+(\w+)', text_lower)
            if app_matches:
                return f"COMMAND: close_app({app_matches[0]})"
        elif "volume" in text_lower:
            if "up" in text_lower:
                return "COMMAND: increase_volume"
            elif "down" in text_lower:
                return "COMMAND: decrease_volume"
            else:
                level_match = re.search(r'(\d+)', text)
                if level_match:
                    return f"COMMAND: set_volume({level_match.group(1)})"
        elif "brightness" in text_lower:
            if "up" in text_lower or "increase" in text_lower:
                return "COMMAND: increase_brightness"
            elif "down" in text_lower or "decrease" in text_lower:
                return "COMMAND: decrease_brightness"
        elif "weather" in text_lower:
            return "QUERY: weather_info"
        elif "time" in text_lower:
            return "QUERY: current_time"
        elif "date" in text_lower:
            return "QUERY: current_date"
        else:
            return f"UNCLEAR: {text} (confidence: {confidence:.0%})"

    async def process_voice_command(self, command: VoiceCommand) -> str:
        """Process voice command with enhanced intelligence"""
        # Add to command history
        self.command_history.append(command)
        if len(self.command_history) > 50:
            self.command_history = self.command_history[-50:]

        # Get context
        context_info = self._get_context_info()
        recent_context = self._get_recent_voice_context()

        # Log for debugging
        logger.info(
            f"Processing command: '{command.raw_text}' (confidence: {command.confidence})"
        )

        # Determine if we need to use voice optimization
        if (
            command.confidence < VoiceConfidence.HIGH.value
            or command.needs_clarification
        ):
            return await self._optimize_voice_command(
                command, context_info, recent_context
            )
        else:
            return await self._process_clear_command(command.raw_text, context_info)

    async def _optimize_voice_command(
        self, command: VoiceCommand, context_info: str, recent_context: str
    ) -> str:
        """Use Anthropic to interpret unclear voice commands"""
        # Build voice-specific prompt
        prompt = VOICE_OPTIMIZATION_PROMPT.format(
            context=recent_context,
            command=command.raw_text,
            confidence=f"{command.confidence:.2f}",
            intent=command.intent,
        )

        # Add any specific context
        if context_info:
            prompt = f"{context_info}\n\n{prompt}"

        # ===================================================================
        # NON-BLOCKING CPU CHECK - Uses cached value from background monitor
        # This is INSTANT and doesn't block the event loop!
        # ===================================================================

        # Get cached CPU usage (non-blocking, instant)
        cpu_usage = getattr(self, '_voice_engine', None)
        if cpu_usage and hasattr(cpu_usage, 'get_cached_cpu_usage'):
            cpu_usage = cpu_usage.get_cached_cpu_usage()
        else:
            # Fallback if voice engine not set (shouldn't happen)
            cpu_usage = 0.0
            logger.warning("[CPU-CHECK] Voice engine not available, skipping CPU check")

        if cpu_usage > 25:  # Don't call Claude if CPU > 25%
            logger.warning(f"[CPU-CHECK] CPU usage too high ({cpu_usage:.1f}%) - using local response")
            return self._local_command_interpretation(command.raw_text, command.confidence)

        # Log CPU check for monitoring
        logger.debug(f"[CPU-CHECK] CPU usage OK ({cpu_usage:.1f}%) - proceeding with Claude call")

        # Get interpretation from Claude only if CPU is low
        message = await asyncio.to_thread(
            self.claude.messages.create,
            model="claude-3-haiku-20240307",  # Fast model for voice processing
            max_tokens=200,
            temperature=0.3,  # Lower temperature for accuracy
            system=Ironcliw_SYSTEM_PROMPT,
            messages=[
                *self.voice_context[-5:],  # Include recent voice context
                {"role": "user", "content": prompt},
            ],
        )

        response = message.content[0].text

        # Update voice context
        self.voice_context.append({"role": "user", "content": command.raw_text})
        self.voice_context.append({"role": "assistant", "content": response})

        # Maintain voice context window
        if len(self.voice_context) > 20:
            self.voice_context = self.voice_context[-20:]

        return response

    async def _process_clear_command(self, command: str, context_info: str) -> str:
        """Process clear commands normally"""
        # Check if this is a weather request FIRST - before adding context
        if await self._is_weather_request(command):
            return await self._handle_weather_request(command)

        # For non-weather requests, use simple prompt without context
        enhanced_prompt = f"User command: {command}"

        # Get response from Claude
        message = await asyncio.to_thread(
            self.claude.messages.create,
            model="claude-3-haiku-20240307",
            max_tokens=300,
            system=Ironcliw_SYSTEM_PROMPT,
            messages=[*self.context, {"role": "user", "content": enhanced_prompt}],
        )

        response = message.content[0].text

        # Update context
        self.context.append({"role": "user", "content": command})
        self.context.append({"role": "assistant", "content": response})

        # Maintain context window
        if len(self.context) > 20:
            self.context = self.context[-20:]

        return response

    def _get_recent_voice_context(self) -> str:
        """Get recent voice command context"""
        if not self.command_history:
            return "No recent voice commands"

        recent = self.command_history[-3:]
        context_parts = []

        for cmd in recent:
            time_ago = (datetime.now() - cmd.timestamp).seconds
            if time_ago < 60:
                context_parts.append(f"{time_ago}s ago: '{cmd.raw_text}'")
            elif time_ago < 3600:
                context_parts.append(f"{time_ago//60}m ago: '{cmd.raw_text}'")

        return (
            "Recent commands: " + "; ".join(context_parts)
            if context_parts
            else "No recent commands"
        )

    def _get_context_info(self) -> str:
        """Get contextual information for more intelligent responses"""
        current_time = datetime.now()
        context_parts = []

        # Time and day context
        hour = current_time.hour
        day_name = current_time.strftime("%A")

        # Add natural time context
        if hour < 6:
            context_parts.append("Very early morning hours")
        elif hour < 9:
            context_parts.append("Early morning")
        elif hour < 12:
            context_parts.append("Morning")
        elif hour < 14:
            context_parts.append("Midday")
        elif hour < 17:
            context_parts.append("Afternoon")
        elif hour < 20:
            context_parts.append("Evening")
        elif hour < 23:
            context_parts.append("Late evening")
        else:
            context_parts.append("Late night")

        # Weekend context
        if day_name in ["Saturday", "Sunday"]:
            context_parts.append("Weekend")

        # Work hours context - more natural
        work_start, work_end = self.user_preferences["work_hours"]
        if day_name not in ["Saturday", "Sunday"] and work_start <= hour < work_end:
            context_parts.append("During typical work hours")
        elif hour >= work_end and day_name not in ["Saturday", "Sunday"]:
            context_parts.append("After work hours")

        # Break reminder context - more natural
        if self.user_preferences["break_reminder"]:
            time_since_break = (current_time - self.last_break).seconds / 3600
            if time_since_break > 3:
                context_parts.append("User has been active for extended period")

        # Recent interaction patterns
        if self.command_history:
            # Check if user just started interacting
            if len(self.command_history) == 1:
                context_parts.append("First interaction of this session")
            # Check for rapid commands
            elif len(self.command_history) > 2:
                recent_times = [cmd.timestamp for cmd in self.command_history[-3:]]
                time_diffs = [
                    (recent_times[i + 1] - recent_times[i]).seconds
                    for i in range(len(recent_times) - 1)
                ]
                if all(diff < 30 for diff in time_diffs):
                    context_parts.append("User is actively engaged")

        return "Natural context: " + "; ".join(context_parts) if context_parts else ""

    def get_activation_response(self, confidence: float = 1.0) -> str:
        """Get a contextual activation response based on confidence"""
        if confidence < VoiceConfidence.MEDIUM.value:
            # Low confidence responses
            return random.choice(
                [
                    f"I think I heard you, {self.user_preferences['name']}. How may I assist?",
                    f"Apologies if I misheard, {self.user_preferences['name']}. What can I do for you?",
                    "Pardon me, sir. Could you repeat that?",
                ]
            )

        # Keep responses short and simple
        responses = [
            f"Yes, {self.user_preferences['name']}?",
            "Yes?",
            "Sir?",
            "Listening.",
            "Go ahead.",
            "I'm here.",
        ]

        return random.choice(responses)

    async def _is_weather_request(self, command: str) -> bool:
        """Check if command is asking about weather - FAST"""
        weather_keywords = [
            "weather",
            "temperature",
            "forecast",
            "rain",
            "sunny",
            "cloudy",
            "cold",
            "hot",
            "warm",
            "degrees",
            "celsius",
            "fahrenheit",
            "outside",
            "today",
        ]
        command_lower = command.lower()
        # Quick check for common patterns
        if "weather" in command_lower or "temperature" in command_lower:
            logger.info(f"Weather request detected: '{command}'")
            return True
        is_weather = any(keyword in command_lower for keyword in weather_keywords)
        if is_weather:
            logger.info(f"Weather request detected via keywords: '{command}'")
        return is_weather

    async def _handle_weather_request(self, command: str) -> str:
        """Handle weather requests with real data"""
        logger.info(
            f"Handling weather request. Weather service available: {self.weather_service is not None}"
        )
        if not self.weather_service:
            # Fallback to Claude if weather service not available
            enhanced_prompt = f"User is asking about weather: {command}"
            message = await asyncio.to_thread(
                self.claude.messages.create,
                model="claude-3-haiku-20240307",
                max_tokens=150,
                system="You are Ironcliw. Give a brief, direct weather response. Be concise.",
                messages=[{"role": "user", "content": enhanced_prompt}],
            )
            return message.content[0].text

        try:
            # Determine if asking about specific location or current location
            command_lower = command.lower()

            # Extract ANY location from command - no hardcoding!
            location = None

            import re

            # Flexible patterns to extract location after prepositions
            patterns = [
                r"(?:weather|temperature|forecast|rain|snow|sunny|cloudy|hot|cold|warm)(?:\s+(?:is|be|like|today))?\s+(?:in|at|for|around|near)\s+(.+?)(?:\s*\?|$)",
                r"(?:what\'?s|how\'?s|is)\s+(?:the\s+)?(?:weather|temperature|it)\s+(?:like\s+)?(?:in|at|for)\s+(.+?)(?:\s*\?|$)",
                r"(?:in|at|for)\s+(.+?)\s+(?:weather|temperature)",
                r"(.+?)\s+weather(?:\s+like)?(?:\s*\?|$)",
            ]

            for pattern in patterns:
                match = re.search(pattern, command_lower, re.IGNORECASE)
                if match:
                    # Extract everything after the preposition as the location
                    location = match.group(1).strip()
                    # Clean up common endings
                    location = re.sub(
                        r"\s*(today|tomorrow|now|please|thanks|thank you)$",
                        "",
                        location,
                        flags=re.IGNORECASE,
                    )
                    location = location.strip(".,!?")

                    if location:
                        logger.info(f"Extracted location from pattern: '{location}'")
                        break

            # If no location found, check if entire query after "weather" might be a location
            if not location:
                # Simple fallback - take everything after weather-related keywords
                weather_match = re.search(
                    r"(?:weather|temperature|forecast)\s+(?:in|at|for|of)?\s*(.+?)(?:\s*\?|$)",
                    command_lower,
                )
                if weather_match:
                    potential_location = weather_match.group(1).strip()
                    if potential_location and len(potential_location) > 2:
                        location = potential_location
                        logger.info(f"Extracted location from fallback: '{location}'")

            # Get weather data
            if location:
                logger.info(f"Getting weather for location: {location}")
                # Pass the full location string to OpenWeatherMap - it handles cities, states, countries
                weather_data = await self.weather_service.get_weather_by_city(location)
            else:
                logger.info("No location specified, using current location")
                # Use current location
                weather_data = await self.weather_service.get_current_weather()

            # Check for errors first
            if weather_data.get("error"):
                return f"I apologize, sir, but I couldn't find weather information for {location}. Perhaps you could verify the location name?"

            # Format response in Ironcliw style
            location = weather_data.get("location", "your location")
            temp = weather_data.get("temperature", 0)
            feels_like = weather_data.get("feels_like", temp)
            description = weather_data.get("description", "unknown conditions")
            wind = weather_data.get("wind_speed", 0)

            # Build Ironcliw-style response
            response = f"Currently in {location}, we have {description} "
            response += f"with a temperature of {temp} degrees Celsius"

            if abs(feels_like - temp) > 2:
                response += f", though it feels like {feels_like}"

            response += f". Wind speed is {wind} kilometers per hour. "

            # Add personalized suggestions based on conditions
            hour = datetime.now().hour
            if temp > 25:
                response += "Quite warm today, sir. Perhaps consider lighter attire."
            elif temp < 10:
                response += "Rather chilly, sir. I'd recommend a jacket."
            elif "rain" in description.lower():
                response += "Don't forget an umbrella if you're heading out, sir."
            elif "clear" in description.lower() and temp > 18 and hour < 18:
                response += "Beautiful weather for any outdoor activities you might have planned."

            # Update context with actual weather info
            self.context.append({"role": "user", "content": command})
            self.context.append({"role": "assistant", "content": response})

            return response

        except Exception as e:
            logger.error(f"Error getting weather data: {e}")
            # Fallback to Claude
            return await self._process_clear_command(command, self._get_context_info())


class EnhancedIroncliwVoiceAssistant:
    """
    Enhanced Ironcliw Voice Assistant with professional-grade accuracy and ML training.

    v100.0 Enhancements:
    - 100% environment-driven configuration
    - Deep Trinity Voice Coordinator integration
    - Bounded command history
    - Graceful shutdown with resource cleanup
    - W3C distributed tracing support
    """

    def __init__(
        self,
        claude_api_key: str,
        enable_ml_training: bool = True,
        config: Optional[IroncliwVoiceConfig] = None
    ):
        # Load configuration (100% environment-driven)
        self.config = config or get_voice_config()

        # Initialize ML enhanced system if available
        self.ml_enhanced_system = None
        self.ml_trainer = None

        if enable_ml_training:
            try:
                # Import ML enhanced system
                from voice.ml_enhanced_voice_system import MLEnhancedVoiceSystem

                self.ml_enhanced_system = MLEnhancedVoiceSystem(claude_api_key)
                self.ml_trainer = self.ml_enhanced_system.ml_trainer
                logger.info(
                    "ML Enhanced Voice System initialized with advanced wake word detection"
                )
            except ImportError:
                logger.warning(
                    "ML Enhanced Voice System not available, falling back to basic ML trainer"
                )
                # Fallback to basic ML trainer
                if ML_TRAINING_AVAILABLE:
                    try:
                        self.ml_trainer = VoiceMLTrainer(claude_api_key)
                        logger.info("Basic ML training system initialized")
                    except Exception as e:
                        logger.error(f"Failed to initialize ML trainer: {e}")

        # Initialize components with ML systems and shared config
        self.personality = EnhancedIroncliwPersonality(
            claude_api_key, ml_trainer=self.ml_trainer
        )

        # Initialize voice engine with both ML systems and config
        self.voice_engine = EnhancedVoiceEngine(
            ml_trainer=self.ml_trainer,
            ml_enhanced_system=self.ml_enhanced_system,
            config=self.config
        )

        # Wire up voice engine reference to personality for system metrics
        self.personality.set_voice_engine(self.voice_engine)
        logger.info("[IroncliwVoiceAssistant] Voice engine wired to personality")

        self.running = False
        self._shutdown_requested = False
        self.command_queue = queue.Queue()

        # Enhanced wake words from environment config
        self.wake_words = {
            "primary": self.config.wake_words_primary,
            "variations": self.config.wake_words_variations,
            "urgent": self.config.wake_words_urgent,
        }

        # Confidence thresholds from config (will be dynamically adjusted by ML system)
        self.wake_word_threshold = self.config.wake_word_threshold
        self.command_threshold = self.config.command_threshold

        # If ML enhanced system is available, use its personalized thresholds
        if self.ml_enhanced_system:
            user_thresholds = self.ml_enhanced_system.user_thresholds.get("default")
            if user_thresholds:
                self.wake_word_threshold = user_thresholds.wake_word_threshold
                self.command_threshold = user_thresholds.confidence_threshold

        # Bounded command history (prevent memory leaks)
        self._command_history: BoundedDeque = BoundedDeque(
            maxlen=self.config.max_command_history
        )

        # Trinity Voice Coordinator integration
        self._trinity_coordinator = None
        self._init_trinity_coordinator()

        # Special commands
        self.special_commands = {
            "stop listening": self._stop_listening,
            "goodbye": self._shutdown,
            "shut down": self._shutdown,
            "calibrate": self._calibrate,
            "change my name": self._change_name,
            "improve accuracy": self._improve_accuracy,
            "show my voice stats": self._show_voice_stats,
            "export my voice model": self._export_voice_model,
            "personalized tips": self._get_personalized_tips,
            "ml performance": self._show_ml_performance,
            "voice health": self._show_voice_health,  # New v100.0 command
        }

        logger.info(
            f"[IroncliwVoiceAssistant] Initialized v100.0 with "
            f"wake_words={len(self.wake_words['primary'])}, "
            f"thresholds=(wake={self.wake_word_threshold}, cmd={self.command_threshold})"
        )

    def _init_trinity_coordinator(self) -> None:
        """Initialize Trinity Voice Coordinator integration."""
        try:
            if TRINITY_VOICE_AVAILABLE:
                # Will be initialized on first use via get_voice_coordinator()
                logger.info("[IroncliwVoiceAssistant] Trinity Voice Coordinator available")
            else:
                logger.warning("[IroncliwVoiceAssistant] Trinity Voice Coordinator not available")
        except Exception as e:
            logger.error(f"[IroncliwVoiceAssistant] Error initializing Trinity: {e}")

    async def _announce_via_trinity(
        self,
        message: str,
        context: str = "runtime",
        priority: str = "NORMAL"
    ) -> bool:
        """Announce message via Trinity Voice Coordinator if available."""
        if not TRINITY_VOICE_AVAILABLE:
            return False

        try:
            # Import dynamically to avoid circular imports
            from backend.core.trinity_voice_coordinator import (
                announce, VoiceContext, VoicePriority
            )

            # Map context and priority
            try:
                voice_context = VoiceContext(context.lower())
            except ValueError:
                voice_context = VoiceContext.RUNTIME

            try:
                voice_priority = VoicePriority[priority.upper()]
            except KeyError:
                voice_priority = VoicePriority.NORMAL

            success, reason = await announce(
                message=message,
                context=voice_context,
                priority=voice_priority,
                source="jarvis_voice_assistant"
            )

            if success:
                logger.debug(f"[Trinity] Announcement queued: {reason}")
            else:
                logger.warning(f"[Trinity] Announcement skipped: {reason}")

            return success

        except Exception as e:
            logger.error(f"[Trinity] Announcement error: {e}")
            return False

    async def _show_voice_health(self) -> None:
        """Show comprehensive voice system health."""
        health = self.voice_engine.get_health()

        health_summary = f"""Voice System Health Report (v100.0):

Status: {"Running" if health["running"] else "Stopped"}
Circuit Breaker: {health["circuit_breaker"]["state"]} (failures={health["circuit_breaker"]["failure_count"]})
Queue: {health["queue"]["in_flight"]}/{health["queue"]["maxsize"]} tasks
Event Bus: {health["event_bus"]["history_size"]} events

Performance:
- Successful: {health["performance"]["successful_recognitions"]}
- Failed: {health["performance"]["failed_recognitions"]}
- Engine: {health["performance"]["current_engine"]}

System:
- CPU: {health["system_metrics"]["cpu_percent"]:.1f}%
- Memory: {health["system_metrics"]["memory_percent"]:.1f}%
- Monitor Running: {health["system_metrics"]["monitor_running"]}

Configuration:
- Energy Threshold: {health["config"]["energy_threshold"]}
- Pause Threshold: {health["config"]["pause_threshold"]}
- Optimization: {"Enabled" if health["config"]["optimization_enabled"] else "Disabled"}
"""

        self.voice_engine.speak(health_summary)
        logger.info(f"Voice Health: {json.dumps(health, indent=2)}")

    async def _check_wake_word(
        self, text: str, confidence: float, audio_data: Optional[np.ndarray] = None
    ) -> Tuple[bool, Optional[str]]:
        """Enhanced wake word detection with ML-powered personalization"""
        if not text:
            return False, None

        # If ML enhanced system is available, use it for advanced detection
        if self.ml_enhanced_system and audio_data is not None:
            try:
                # Use ML-enhanced detection with 80%+ false positive reduction
                is_wake_word, ml_confidence, rejection_reason = (
                    await self.ml_enhanced_system.detect_wake_word(
                        audio_data,
                        user_id=(
                            self.ml_trainer.current_user
                            if self.ml_trainer
                            else "default"
                        ),
                    )
                )

                if is_wake_word:
                    # Determine wake type based on text
                    text_lower = text.lower()
                    if any(word in text_lower for word in self.wake_words["urgent"]):
                        return True, "urgent"
                    elif any(word in text_lower for word in self.wake_words["primary"]):
                        return True, "primary"
                    else:
                        return True, "ml_detected"
                else:
                    # Log rejection for learning
                    if rejection_reason:
                        logger.debug(f"Wake word rejected: {rejection_reason}")
                    return False, None

            except Exception as e:
                logger.error(f"ML wake word detection error: {e}")
                # Fall back to traditional detection

        # Traditional detection (fallback or when ML not available)
        text_lower = text.lower()

        # Check urgent wake words first
        for wake_word in self.wake_words["urgent"]:
            if wake_word in text_lower:
                return True, "urgent"

        # Check primary wake words
        for wake_word in self.wake_words["primary"]:
            if wake_word in text_lower:
                # Boost confidence if wake word is at the beginning
                if text_lower.startswith(wake_word):
                    confidence += 0.1
                if confidence >= self.wake_word_threshold:
                    return True, "primary"

        # Check variations (with lower threshold)
        for variation in self.wake_words["variations"]:
            if variation in text_lower and confidence >= (
                self.wake_word_threshold - 0.1
            ):
                return True, "variation"

        return False, None

    async def start(self):
        """Start enhanced Ironcliw voice assistant"""
        print("\n=== Ironcliw Enhanced Voice System Initializing ===")
        print("🚀 Loading professional-grade voice processing...")

        # ===================================================================
        # START BACKGROUND MONITORS - Non-blocking system optimization
        # ===================================================================

        # Start system monitor for non-blocking CPU/memory tracking
        print("📊 Starting background system monitor...")
        await self.voice_engine.start_system_monitor()

        # Start async optimization task
        print("🔧 Starting adaptive optimization...")
        await self.voice_engine._start_optimization_async()

        logger.info("[Ironcliw] All background monitors started successfully")

        # Enhanced calibration
        self.voice_engine.calibrate_microphone(duration=3)

        # Startup greeting
        startup_msg = "Ironcliw enhanced voice system online. All systems operational."
        self.voice_engine.speak(startup_msg)

        self.running = True
        print("\n🎤 Say 'Ironcliw' to activate...")
        print(
            "💡 Tip: For better accuracy, speak clearly and wait for the listening indicator"
        )

        # Start wake word detection
        await self._wake_word_loop()

    async def _wake_word_loop(self):
        """Enhanced wake word detection loop with ML integration"""
        consecutive_failures = 0

        # Start ML enhanced system if available
        if self.ml_enhanced_system:
            await self.ml_enhanced_system.start()

        while self.running:
            # Listen for wake word with confidence
            text, confidence = self.voice_engine.listen_with_confidence(
                timeout=1, phrase_time_limit=3
            )

            if text:
                # Get audio data for ML processing
                audio_data = getattr(self.voice_engine, "last_audio_data", None)

                # Check for wake word with ML enhancement
                detected, wake_type = await self._check_wake_word(
                    text, confidence, audio_data
                )

                if detected:
                    logger.info(
                        f"Wake word detected: '{text}' (confidence: {confidence:.2f}, type: {wake_type})"
                    )
                    consecutive_failures = 0

                    # Update environmental profile if ML system is available
                    if self.ml_enhanced_system and audio_data is not None:
                        await self.ml_enhanced_system.update_environmental_profile(
                            audio_data
                        )

                    await self._handle_activation(
                        confidence, wake_type or "normal", text
                    )
                else:
                    # Track false positives for ML learning
                    if self.ml_enhanced_system and audio_data is not None:
                        # Check if this was a near-miss
                        if any(
                            word in text.lower()
                            for sublist in self.wake_words.values()
                            for word in (
                                sublist if isinstance(sublist, list) else [sublist]
                            )
                        ):
                            logger.debug(
                                f"Near-miss wake word: '{text}' (confidence: {confidence:.2f})"
                            )
                            # This helps the ML system learn what NOT to accept
                            await self.ml_enhanced_system.process_user_feedback(
                                f"near_miss_{datetime.now().timestamp()}",
                                was_correct=False,
                            )

            # Recalibrate if we're getting too many failures
            consecutive_failures += 1
            if consecutive_failures > 30:  # About 30 seconds of failures
                logger.info("Recalibrating due to consecutive failures")
                self.voice_engine.calibrate_microphone(duration=1)
                consecutive_failures = 0

            # Small delay to prevent CPU overuse
            await asyncio.sleep(0.1)

    async def _handle_activation(
        self, wake_confidence: float, wake_type: str, full_text: Optional[str] = None
    ):
        """Enhanced activation handling"""
        # Check if command was included with wake word
        command_text = None
        command_confidence = wake_confidence

        if full_text:
            # Extract command after wake word
            text_lower = full_text.lower()
            for wake_list in self.wake_words.values():
                for wake_word in (
                    wake_list if isinstance(wake_list, list) else [wake_list]
                ):
                    if wake_word in text_lower:
                        # Find the wake word position and extract everything after it
                        wake_pos = text_lower.find(wake_word)
                        if wake_pos != -1:
                            potential_command = full_text[
                                wake_pos + len(wake_word) :
                            ].strip()
                            if potential_command:
                                command_text = potential_command
                                print(
                                    f"📝 Command detected with wake word: '{command_text}'"
                                )
                                break
                if command_text:
                    break

        if not command_text:
            # No command with wake word, so respond and listen
            if wake_type == "urgent":
                self.voice_engine.speak(
                    "Emergency protocol activated. What's the situation?"
                )
            else:
                response = self.personality.get_activation_response(wake_confidence)
                self.voice_engine.speak(response)

            # Listen for command with confidence scoring
            print("🎤 Listening for command...")
            command_text, command_confidence = self.voice_engine.listen_with_confidence(
                timeout=5, phrase_time_limit=10
            )

        if command_text:
            # Detect intent
            intent = self.voice_engine.detect_intent(command_text)

            # Create structured command
            command = VoiceCommand(
                raw_text=command_text,
                confidence=command_confidence,
                intent=intent,
                needs_clarification=command_confidence < self.command_threshold,
            )

            await self._process_command(command)
        else:
            # Different responses based on context
            if wake_confidence < 0.7:
                self.voice_engine.speak(
                    "I'm having trouble hearing you clearly, sir. Could you speak up?"
                )
            else:
                self.voice_engine.speak("I didn't catch that, sir. Could you repeat?")

    async def _process_command(
        self, command: VoiceCommand, audio_data: Optional[np.ndarray] = None
    ):
        """Process enhanced voice command with ML training"""
        logger.info(
            f"Command: '{command.raw_text}' (confidence: {command.confidence:.2f}, intent: {command.intent})"
        )

        # Store original command for ML training
        original_command = command.raw_text
        success = True
        corrected_text = None

        # Check for special commands first
        for special_cmd, handler in self.special_commands.items():
            if special_cmd in command.raw_text.lower():
                await handler()
                # Train ML on successful special command
                if self.ml_trainer and audio_data is not None:
                    await self.ml_trainer.learn_from_interaction(
                        recognized_text=original_command,
                        confidence=command.confidence,
                        audio_data=audio_data,
                        corrected_text=None,
                        success=True,
                        context="special_command",
                    )
                return

        # Use ML-enhanced conversation if available
        if self.ml_enhanced_system and command.confidence < 0.8:
            # Get recent conversation context
            context = []
            if hasattr(self.personality, "voice_context"):
                context = self.personality.voice_context[-5:]

            # Use ML system for enhanced understanding
            response = (
                await self.ml_enhanced_system.enhance_conversation_with_anthropic(
                    command.raw_text, context, command.confidence
                )
            )
        else:
            # Process with standard enhanced personality
            response = await self.personality.process_voice_command(command)

        # Check if response indicates a clarification was needed
        if "?" in response and command.needs_clarification:
            # Wait for clarification
            self.voice_engine.speak(response)

            # Listen for clarification
            clarification_text, clarification_confidence = (
                self.voice_engine.listen_with_confidence(
                    timeout=5, phrase_time_limit=10
                )
            )

            if clarification_text:
                corrected_text = clarification_text
                # Re-process with clarification
                clarified_command = VoiceCommand(
                    raw_text=clarification_text,
                    confidence=clarification_confidence,
                    intent=self.voice_engine.detect_intent(clarification_text),
                    needs_clarification=False,
                )
                response = await self.personality.process_voice_command(
                    clarified_command
                )

        # Speak final response
        self.voice_engine.speak(response)

        # Train ML system with the interaction
        if self.ml_trainer:
            # Get audio data from voice engine if not provided
            if audio_data is None and hasattr(self.voice_engine, "last_audio_data"):
                audio_data = self.voice_engine.last_audio_data

            if audio_data is not None:
                await self.ml_trainer.learn_from_interaction(
                    recognized_text=original_command,
                    confidence=command.confidence,
                    audio_data=audio_data,
                    corrected_text=corrected_text,
                    success=success,
                    context=f"intent:{command.intent}",
                )

                # Log ML insights periodically
                user_profile = self.ml_trainer.user_profiles.get(
                    self.ml_trainer.current_user, {}
                )
                voice_patterns = (
                    user_profile.get("voice_patterns", [])
                    if isinstance(user_profile, dict)
                    else []
                )
                if len(voice_patterns) % 20 == 0:
                    insights = self.ml_trainer.get_user_insights()
                    logger.info(
                        f"ML Insights - Accuracy: {insights['recent_accuracy']:.2%}, Total interactions: {insights['total_interactions']}"
                    )

    async def _improve_accuracy(self):
        """Guide user through accuracy improvement"""
        self.voice_engine.speak(
            "Let's improve my accuracy. I'll guide you through a quick calibration."
        )
        await asyncio.sleep(1)

        # Recalibrate with user guidance
        self.voice_engine.speak(
            "First, please remain quiet while I calibrate for background noise."
        )
        self.voice_engine.calibrate_microphone(duration=4)

        self.voice_engine.speak(
            "Excellent. Now, please say 'Hey Ironcliw' three times, pausing between each."
        )

        # Collect samples
        samples = []
        for i in range(3):
            self.voice_engine.speak(f"Sample {i+1} of 3. Please say 'Hey Ironcliw'.")
            text, confidence = self.voice_engine.listen_with_confidence(timeout=5)
            if text:
                samples.append((text, confidence))
                self.voice_engine.speak("Got it.")
            else:
                self.voice_engine.speak("I didn't catch that. Let's try again.")
                i -= 1

        # Analyze samples
        if samples:
            avg_confidence = np.mean([s[1] for s in samples])
            if avg_confidence > 0.8:
                self.voice_engine.speak(
                    f"Excellent! Your voice is coming through clearly with {avg_confidence*100:.0f}% confidence."
                )
            elif avg_confidence > 0.6:
                self.voice_engine.speak(
                    f"Good. I'm detecting your voice with {avg_confidence*100:.0f}% confidence. Try speaking a bit louder or clearer."
                )
            else:
                self.voice_engine.speak(
                    f"I'm having some difficulty. Only {avg_confidence*100:.0f}% confidence. You may want to check your microphone or reduce background noise."
                )

        self.voice_engine.speak("Calibration complete. My accuracy should be improved.")

    async def _stop_listening(self):
        """Temporarily stop listening"""
        self.voice_engine.speak(
            "Going into standby mode, sir. Say 'Ironcliw' when you need me."
        )
        # Continue wake word loop

    async def _shutdown(self):
        """Shutdown Ironcliw with complete cleanup of all background tasks"""
        self.voice_engine.speak("Shutting down. Goodbye, sir.")

        logger.info("[Ironcliw] Starting shutdown sequence...")

        # Stop system monitor
        logger.info("[Ironcliw] Stopping system monitor...")
        await self.voice_engine.stop_system_monitor()

        # Stop optimization task
        logger.info("[Ironcliw] Stopping optimization task...")
        self.voice_engine.stop_optimization = True
        if hasattr(self.voice_engine, 'optimization_task'):
            self.voice_engine.optimization_task.cancel()
            try:
                await self.voice_engine.optimization_task
            except asyncio.CancelledError:
                pass

        # Stop ML enhanced system if running
        if self.ml_enhanced_system:
            logger.info("[Ironcliw] Stopping ML enhanced system...")
            await self.ml_enhanced_system.stop()

        self.running = False
        logger.info("[Ironcliw] Shutdown complete")

    async def _calibrate(self):
        """Recalibrate microphone"""
        self.voice_engine.speak("Recalibrating audio sensors.")
        self.voice_engine.calibrate_microphone(duration=3)
        self.voice_engine.speak("Calibration complete.")

    async def _change_name(self):
        """Change how Ironcliw addresses the user"""
        self.voice_engine.speak("What would you prefer I call you?")
        name_text, confidence = self.voice_engine.listen_with_confidence(timeout=5)

        if name_text and confidence > 0.5:
            # Clean up the name using AI if confidence is low
            if confidence < 0.8:
                command = VoiceCommand(
                    raw_text=name_text,
                    confidence=confidence,
                    intent="name_change",
                    needs_clarification=True,
                )
                # Process through AI for clarification
                processed = await self.personality.process_voice_command(command)
                # Extract name from response (simplified)
                name = (
                    name_text.replace("call me", "")
                    .replace("my name is", "")
                    .strip()
                    .title()
                )
            else:
                # High confidence - process directly
                name = (
                    name_text.replace("call me", "")
                    .replace("my name is", "")
                    .strip()
                    .title()
                )

            self.personality.user_preferences["name"] = name
            self.voice_engine.speak(
                f"Very well. I shall address you as {name} from now on."
            )
        else:
            self.voice_engine.speak(
                "I didn't catch that. Maintaining current designation."
            )

    async def _show_voice_stats(self):
        """Show user's voice interaction statistics"""
        if not self.ml_trainer:
            self.voice_engine.speak(
                "Voice statistics are not available. ML training is not enabled."
            )
            return

        insights = self.ml_trainer.get_user_insights()

        if "error" in insights:
            self.voice_engine.speak(
                "No voice statistics available yet. Keep using voice commands to build your profile."
            )
            return

        # Prepare summary
        stats_summary = f"""Your voice interaction statistics:
        
Total interactions: {insights['total_interactions']}
Recent accuracy: {insights['recent_accuracy']:.0%}
Most used command: {insights['top_commands'][0][0] if insights['top_commands'] else 'None'}

You've used voice commands {insights['total_interactions']} times with {insights['recent_accuracy']:.0%} accuracy recently."""

        self.voice_engine.speak(stats_summary)

        # Log detailed stats
        logger.info(f"Voice Stats: {json.dumps(insights, indent=2, default=str)}")

    async def _export_voice_model(self):
        """Export user's voice model"""
        if not self.ml_trainer:
            self.voice_engine.speak(
                "Voice model export is not available. ML training is not enabled."
            )
            return

        try:
            export_path = self.ml_trainer.export_user_model()
            if export_path:
                self.voice_engine.speak(
                    f"Your voice model has been exported successfully. Check the models directory."
                )
                logger.info(f"Voice model exported to: {export_path}")
            else:
                self.voice_engine.speak(
                    "Unable to export voice model. No data available."
                )
        except Exception as e:
            logger.error(f"Error exporting voice model: {e}")
            self.voice_engine.speak("There was an error exporting your voice model.")

    async def _get_personalized_tips(self):
        """Get personalized tips based on ML analysis"""
        if not self.ml_trainer:
            self.voice_engine.speak(
                "Personalized tips are not available. ML training is not enabled."
            )
            return

        self.voice_engine.speak(
            "Analyzing your voice patterns to generate personalized tips..."
        )

        try:
            tips = await self.ml_trainer.generate_personalized_tips()
            self.voice_engine.speak(tips)
        except Exception as e:
            logger.error(f"Error generating tips: {e}")
            self.voice_engine.speak(
                "I encountered an error while generating tips. Please try again later."
            )

    async def _show_ml_performance(self):
        """Show ML system performance metrics"""
        if not self.ml_enhanced_system:
            self.voice_engine.speak(
                "ML performance metrics are not available. The enhanced ML system is not enabled."
            )
            return

        # Get performance metrics
        metrics = self.ml_enhanced_system.get_performance_metrics()

        # Format for speech
        performance_summary = f"""ML Performance Report:
        
Total wake word detections: {metrics['total_detections']}
Accuracy: {metrics['precision']:.1%}
False positive reduction: {metrics['false_positive_reduction']:.1f}%
Current noise level: {metrics['environmental_noise']:.3f}
System adaptations: {metrics['adaptations_made']}

Your personalized thresholds have been optimized to reduce false positives by {metrics['false_positive_reduction']:.0f}%."""

        self.voice_engine.speak(performance_summary)

        # Log detailed metrics
        logger.info(f"Detailed ML Performance Metrics: {json.dumps(metrics, indent=2)}")


# =============================================================================
# Trinity Voice Coordinator — Re-export from canonical implementation
# =============================================================================
# NOTE: The canonical TrinityVoiceCoordinator is in backend/core/trinity_voice_coordinator.py
# This re-export provides backward compatibility for any imports from this module.

# Only define stubs if Trinity is not available (already imported at top)
if not TRINITY_VOICE_AVAILABLE:
    # Fallback stubs
    class VoicePersonality(Enum):
        """Fallback voice personality enum."""
        STARTUP = "startup"
        NARRATOR = "narrator"
        RUNTIME = "runtime"
        ALERT = "alert"
        CELEBRATION = "celebration"

    def get_trinity_voice_coordinator():
        """Fallback that returns None."""
        return None

    async def announce_fallback(*args, **kwargs) -> Tuple[bool, str]:
        """Fallback announce that does nothing."""
        return False, "trinity_unavailable"

    announce = announce_fallback
else:
    # Alias for backward compatibility
    VoicePersonality = VoiceContext
    get_trinity_voice_coordinator = get_voice_coordinator


# =============================================================================
# MODULE EXPORTS v100.0
# =============================================================================

__all__ = [
    # Configuration
    "IroncliwVoiceConfig",
    "get_voice_config",

    # Bounded Collections
    "BoundedDeque",
    "LRUBoundedDict",

    # Tracing
    "TraceContext",

    # Metrics
    "VoiceMetricsPersistence",
    "get_metrics_persistence",

    # Circuit Breaker
    "CircuitBreakerState",
    "AdaptiveCircuitBreaker",

    # Event Bus
    "AsyncEventBus",

    # Voice Task
    "VoiceTaskStatus",
    "VoiceTaskPriority",
    "VoiceTask",
    "AsyncVoiceQueue",

    # Voice Command
    "VoiceConfidence",
    "VoiceCommand",

    # Voice Engine
    "EnhancedVoiceEngine",

    # Personality
    "EnhancedIroncliwPersonality",

    # Voice Assistant
    "EnhancedIroncliwVoiceAssistant",

    # Trinity Integration
    "TRINITY_VOICE_AVAILABLE",
    "VoicePersonality",
    "get_trinity_voice_coordinator",
    "announce",
]


async def main():
    """Main entry point"""
    # Get API key from environment
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        print("Error: ANTHROPIC_API_KEY not set in environment")
        return

    # Initialize enhanced Ironcliw
    jarvis = EnhancedIroncliwVoiceAssistant(api_key)

    try:
        await jarvis.start()
    except KeyboardInterrupt:
        print("\nShutting down Ironcliw...")
        await jarvis._shutdown()
    except Exception as e:
        logger.error(f"Error: {e}")
        print(f"Error: {e}")


if __name__ == "__main__":
    asyncio.run(main())
