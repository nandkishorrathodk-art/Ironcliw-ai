# 2026-02-08 — Session Notes

## Roadmap READMEs Updated (All Three Repos)

Updated READMEs across all three Ironcliw ecosystem repos with detailed, in-depth roadmaps:

### Ironcliw-AI-Agent (Body)
Added `### Roadmap — Next Phases` section with:
- **v241.2** — 14B Model Tier (DeepSeek-R1-14B, Phi-4, Qwen-Coder-14B) + disk budget
- **v242.0** — Training Data Pipeline Activation (telemetry → Reactor Core → DPO → deploy)
- **v243.0** — Ouroboros: Ironcliw Self-Programming (architect/implementer/verifier two-model pipeline)
- **v244.0** — LLaVA Vision Integration (self-hosted multimodal)

### jarvis-prime (Mind)
Expanded `## 🗺️ Roadmap` with planned phases above the existing completed versions:
- **v243.0** — Ouroboros with detailed two-model pipeline (R1-14B architect + Coder-14B implementer)
- **v242.0** — Training Data Pipeline Activation with broken link analysis (ReactorCoreBridge.upload_training_data() not implemented, JSONL schema misalignment)
- **v241.2** — 14B Model Tier with specific model configs and routing updates
- **v244.0** — LLaVA Vision Integration

### reactor-core (Nerves)
Added `## 🗺️ Roadmap — Next Phases` section + updated Table of Contents:
- **v242.0** — Training Data Pipeline Activation (most detailed — 5 numbered steps with specific broken links and fixes needed, full pipeline diagram)
- **v243.0** — Ouroboros Training Support (code quality eval, self-programming telemetry, Constitutional AI for code)
- **v244.0** — Continuous Learning Loop (Night Shift, concept drift, A/B testing, curriculum learning)
- **v245.0** — Distributed Training on GCP (multi-VM, spot resilience, cost-aware scheduling)

### Key insight documented across all three
Multi-model routing (v241.1) is simultaneously a quality improvement AND a training data generation mechanism. Model divergence on the same query type creates automatic DPO preference pairs with no human labeling.
