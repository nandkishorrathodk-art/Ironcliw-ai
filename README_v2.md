# Ironcliw AI System v101.0
## The World's Most Advanced Autonomous AI Operating System

> **"Just Another Rather Very Intelligent System"** - A fully autonomous, cross-repository AI ecosystem with self-evolution capabilities, production-grade resilience, and AGI-level cognitive architecture.

[![Version](https://img.shields.io/badge/version-101.0-blue.svg)](https://github.com/yourusername/Ironcliw-AI-Agent)
[![Python](https://img.shields.io/badge/python-3.9+-green.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-orange.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-Production-brightgreen.svg)](https://github.com/yourusername/Ironcliw-AI-Agent)

---

## 🎯 What is Ironcliw?

Ironcliw is a **production-grade autonomous AI operating system** that orchestrates multiple AI agents, models, and services across distributed repositories. It's not just an assistant—it's a self-aware, self-healing, self-evolving cognitive architecture.

### Core Philosophy
- **Zero Human Intervention**: Autonomous operation with self-healing and auto-recovery
- **Cross-Repository Intelligence**: Seamlessly coordinates Ironcliw, Ironcliw-Prime, and Reactor-Core
- **Production Hardened**: Circuit breakers, graceful degradation, timeout recovery
- **Cost Optimized**: Intelligent routing between local, cloud, and API-based models
- **Voice Native**: Full voice biometric authentication with multi-factor security
- **Self-Evolving**: Coding Council enables the system to improve itself

---

## 🚀 Quick Start

```bash
# Clone the repository
git clone https://github.com/yourusername/Ironcliw-AI-Agent.git
cd Ironcliw-AI-Agent

# Single command startup - orchestrates everything
python3 run_supervisor.py
```

That's it. One command starts:
- ✅ Ironcliw Core (main intelligence)
- ✅ Ironcliw-Prime (local LLM brain)
- ✅ Reactor-Core (training pipeline)
- ✅ Neural Mesh (60+ coordinated agents)
- ✅ Google Workspace Chief of Staff
- ✅ Voice biometric authentication
- ✅ Cross-repo state synchronization
- ✅ All with graceful degradation if components are unavailable

---

## 📋 Table of Contents

- [Architecture Overview](#architecture-overview)
- [Trinity Systems (v100-101)](#trinity-systems-v100-101)
- [Intelligent LLM Routing](#intelligent-llm-routing)
- [Voice Biometric Intelligence (VBIA v6.3)](#voice-biometric-intelligence-vbia-v63)
- [Neural Mesh Coordination](#neural-mesh-coordination)
- [Coding Council Self-Evolution](#coding-council-self-evolution)
- [Cross-Repository Integration](#cross-repository-integration)
- [Production Resilience](#production-resilience)
- [God Mode Surveillance](#god-mode-surveillance)
- [Configuration](#configuration)
- [API Reference](#api-reference)
- [Development](#development)
- [Troubleshooting](#troubleshooting)

---

## 🏗️ Architecture Overview

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         Ironcliw AI ECOSYSTEM v101.0                           │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│  ┌───────────────────┐      ┌──────────────────┐      ┌──────────────────┐ │
│  │   Ironcliw Core     │◄────►│  Ironcliw Prime    │◄────►│  Reactor Core    │ │
│  │   (Main Repo)     │      │  (Local LLM)     │      │  (Training)      │ │
│  └───────────────────┘      └──────────────────┘      └──────────────────┘ │
│           │                           │                         │            │
│           │                           │                         │            │
│  ┌────────▼───────────────────────────▼─────────────────────────▼─────────┐ │
│  │                    Trinity Integration Layer v101.0                     │ │
│  │  • Cross-Repo State Sync      • Neural Mesh Bus (10k msg/s)           │ │
│  │  • Coordinated Startup         • Cost Tracking (Redis pub/sub)         │ │
│  │  • Health Monitoring           • Event Streaming (~/.jarvis/cross_repo)│ │
│  └──────────────────────────────────────────────────────────────────────────┘ │
│                                                                               │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │                      Core Intelligence Systems                            │ │
│  ├─────────────────────────────────────────────────────────────────────────┤ │
│  │ • AGI Orchestrator v100.0    - Unified cognitive architecture           │ │
│  │ • UnifiedModelServing v100.2 - Adaptive LLM routing (J-Prime primary)   │ │
│  │ • Neural Mesh v9.4           - 60+ coordinated agents                   │ │
│  │ • Coding Council v78.0       - Self-evolution framework                 │ │
│  │ • VBIA v6.3                  - Multi-factor voice authentication        │ │
│  │ • Google Workspace v3.1      - Chief of Staff agent                     │ │
│  │ • GCP Hybrid Router v2.1     - Intelligent tier routing                 │ │
│  │ • God Mode Surveillance v61.2 - Universal window monitoring             │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
│                                                                               │
│  ┌─────────────────────────────────────────────────────────────────────────┐ │
│  │                    Production Resilience Layer                            │ │
│  ├─────────────────────────────────────────────────────────────────────────┤ │
│  │ • Circuit Breakers           • Graceful Degradation                      │ │
│  │ • Timeout Recovery           • Cost Optimization                         │ │
│  │ • Health Monitoring          • Adaptive Routing                          │ │
│  │ • Self-Healing               • Zero-Touch Updates                        │ │
│  └─────────────────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Technology Stack

| Layer | Technologies |
|-------|-------------|
| **LLM Models** | Claude Opus 4.5, Ironcliw-Prime (Llama 70B GGUF), Gemini, GPT-4 |
| **Voice** | ECAPA-TDNN, SpeechBrain STT, macOS TTS, ChromaDB semantic cache |
| **Vector DBs** | ChromaDB (6 collections), Pinecone, Weaviate |
| **Observability** | Langfuse (decision audit), Helicone (cost tracking), Prometheus |
| **State** | Redis (pub/sub), SQLite (local), Cloud SQL (voice profiles), PostgreSQL |
| **Cloud** | GCP (Spot VMs, Cloud Run, Artifact Registry), AWS (fallback) |
| **Frameworks** | FastAPI, LangChain, LangGraph, AutoGen, BabyAGI |
| **ML/DL** | PyTorch, Transformers, SpeechBrain, NumPy, Pandas |
| **Infrastructure** | Docker, Terraform, Yabai (window manager), BetterDisplay |

---

## 🌐 Trinity Systems (v100-101)

Trinity represents the **cross-repository orchestration layer** that unifies Ironcliw, Ironcliw-Prime, and Reactor-Core into a single cognitive system.

### Trinity Components

#### 1. **AGI Orchestrator v100.0**
Unified cognitive architecture coordinating all intelligence systems.

```python
from backend.intelligence.agi_orchestrator import AGIOrchestrator

orchestrator = await AGIOrchestrator.get_instance()
result = await orchestrator.process_request({
    "query": "Analyze the codebase and suggest improvements",
    "task_type": "reasoning",
    "require_vision": False
})
```

**Features:**
- Unified request processing across all agents
- Intelligent task routing based on complexity
- Cross-system awareness and coordination
- Goal inference and autonomous decision-making

#### 2. **Trinity Integrator v88.0**
Cross-repo initialization and health monitoring.

**Responsibilities:**
- Startup coordination with dependency ordering
- Health check aggregation across repos
- Orphan process cleanup
- Port allocation and IPC setup

**Configuration:**
```bash
TRINITY_BOOTSTRAP_VALIDATION=true
CROSS_REPO_NEURAL_MESH_ENABLED=true
CROSS_REPO_COST_SYNC_ENABLED=true
```

#### 3. **Cross-Repo State Initializer v6.3**
Real-time state synchronization and event streaming.

**File Structure:**
```
~/.jarvis/cross_repo/
├── vbia_events.json       # Ironcliw → All (voice auth events)
├── vbia_requests.json     # Prime/Reactor → Ironcliw
├── vbia_results.json      # Ironcliw → Prime/Reactor
├── vbia_state.json        # Ironcliw state broadcast
├── prime_state.json       # Ironcliw Prime status
├── reactor_state.json     # Reactor Core status
└── heartbeat.json         # Cross-repo health
```

**API:**
```python
from backend.core.cross_repo_state_initializer import (
    initialize_all_repos_coordinated,
    get_initialization_status
)

# Coordinated startup with graceful degradation
results = await initialize_all_repos_coordinated()
# Returns: {RepoType.Ironcliw: True, RepoType.Ironcliw_PRIME: True, ...}

# Check status
status = await get_initialization_status()
```

**Features:**
- Async parallel initialization
- Health probing with retry (3 attempts, 2s delay)
- Graceful degradation (optional repos can fail)
- HTTP + file-based health checks
- Timeout-based recovery (30s default)
- Event emission for cross-repo coordination

---

## 🧠 Intelligent LLM Routing

### UnifiedModelServing v100.2

Production-grade adaptive routing system that learns from performance and optimizes cost/latency/quality.

#### Architecture

```
Request → ModelRouter → [Provider Selection] → Execution → Performance Tracking
                              │
                              ├─ J-Prime Local (Primary)
                              ├─ J-Prime Cloud Run
                              ├─ Claude API (Fallback)
                              └─ Gemini (Emergency)
```

#### v100.2 Adaptive Routing (NEW)

**Dynamic Provider Scoring:**
```
Score = 0.6 × Success_Rate + 0.2 × Latency_Score + 0.2 × Recency_Score

Where:
- Success_Rate: Exponential moving average (α=0.1)
- Latency_Score: Normalized 0-5000ms → 1-0
- Recency_Score: Time decay over 1 hour
```

**Auto-Reordering:**
Providers with significantly better scores (>0.3 difference) are promoted within their tier.

**Example:**
```python
from backend.intelligence.unified_model_serving import get_model_server

server = await get_model_server()

# Automatic provider selection
result = await server.generate(
    prompt="Explain quantum computing",
    task_type="reasoning",  # Routes to J-Prime first (v100.2)
    max_tokens=2000
)

# Get performance stats
stats = server.get_router().get_provider_stats()
# Returns: {
#   "prime_local": {"success_rate": 0.98, "avg_latency_ms": 1200, "score": 0.95},
#   "claude": {"success_rate": 0.99, "avg_latency_ms": 800, "score": 0.92}
# }
```

#### Task Type Routing (v100.2)

| Task Type | Primary | Secondary | Tertiary | Notes |
|-----------|---------|-----------|----------|-------|
| **CHAT** | J-Prime Local | J-Prime Cloud Run | Claude | General conversation |
| **REASONING** | J-Prime Local | J-Prime Cloud Run | Claude | Complex analysis (NEW) |
| **VISION** | J-Prime Cloud Run | J-Prime Local | Claude | Image understanding (NEW) |
| **CODE** | J-Prime Local | J-Prime Cloud Run | Claude | Code generation |
| **TOOL_USE** | Claude | J-Prime Local | - | Function calling |
| **EMBEDDING** | J-Prime Local | J-Prime Cloud Run | - | Vector generation |

**Breaking Change (v100.2):** REASONING and VISION now route to J-Prime first (was Claude).

### GCP Hybrid Prime Router v2.1

Four-tier routing with cost optimization and graceful degradation.

#### Routing Decision Tree

```
Budget Check → Resource Check → Capability Match → Tier Selection

Tiers:
1. LOCAL_PRIME    - Free, 0ms latency, requires ≥8GB RAM
2. GCP_VM         - Spot pricing ~$0.029/hr, 30s timeout
3. GCP_CLOUD_RUN  - Serverless ~$0.00002400/vCPU-sec
4. CLOUD_CLAUDE   - API pricing, highest cost, ultimate fallback
5. DEGRADED_LOCAL - Budget exceeded, reduced capability
```

#### v2.1 Enhancements (NEW)

**1. Timeout-Based Degradation Recovery**
```bash
# Configure recovery timeout (default 5 minutes)
DEGRADATION_RECOVERY_TIMEOUT=300.0

# System automatically probes tiers and exits degradation mode
# when any tier becomes available
```

**2. Active Request Counter Validation**
```bash
# Prevents stuck counters from blocking VM termination
ACTIVE_REQUEST_VALIDATION_INTERVAL=60.0

# Every 60s, validates counters and resets if stuck
```

**3. Cost Sync Error Isolation**
```python
# Cost tracking failures no longer break execution
# Errors logged as warnings (non-fatal)
```

**4. Performance Optimizations**
- Latency tracking: O(n) list → O(1) deque
- Lock null checks before string operations
- Graceful degradation timestamp tracking

#### Configuration

```bash
# Cost limits
Ironcliw_UNIFIED_DAILY_BUDGET=5.00              # $5/day total
MAX_SINGLE_REQUEST_COST=0.50                   # $0.50/request max
PREFER_LOCAL_BELOW_COST=0.10                   # Use local if <$0.10

# Resource thresholds
LOCAL_PRIME_MIN_RAM_GB=8.0                     # Minimum RAM for local
GCP_TRIGGER_RAM_PERCENT=85.0                   # When to trigger GCP
CRITICAL_RAM_PERCENT=95.0                      # Critical threshold

# Timeouts
LOCAL_TIMEOUT_MS=5000                          # 5 seconds
GCP_TIMEOUT_MS=30000                           # 30 seconds
CLOUD_API_TIMEOUT_MS=60000                     # 60 seconds

# Resilience (v2.1)
DEGRADATION_RECOVERY_TIMEOUT=300.0             # 5 minutes
ACTIVE_REQUEST_VALIDATION_INTERVAL=60.0        # 60 seconds
```

#### Metrics & Monitoring

```python
from backend.core.gcp_hybrid_prime_router import get_gcp_hybrid_router

router = await get_gcp_hybrid_router()

# Get metrics
metrics = router.get_metrics()
print(f"Total requests: {metrics.total_requests}")
print(f"Local requests: {metrics.local_requests} ({metrics.local_requests/metrics.total_requests*100:.1f}%)")
print(f"Fallback requests: {metrics.fallback_requests}")
print(f"Budget blocks: {metrics.budget_blocks}")
print(f"Average latency: {metrics.avg_latency_ms:.1f}ms")

# Circuit breaker status
health = router.get_tier_health()
for tier, status in health.items():
    print(f"{tier}: {status.state} (success_rate: {status.success_rate:.2%})")
```

---

## 🎤 Voice Biometric Intelligence (VBIA v6.3)

Production-grade multi-factor voice authentication with anti-spoofing, visual security, and cross-repo coordination.

### Architecture

```
Voice Input → STT → VBIA Analysis → Authentication Decision → Action
                         │
                         ├─ Factor 1: ML (ECAPA-TDNN 192-dim embeddings)
                         ├─ Factor 2: Physics (vocal tract, reverberation, Doppler)
                         ├─ Factor 3: Behavioral (patterns, timing, context)
                         └─ Factor 4: Visual Security (screen threat detection)
                                      │
                                      └─ LangGraph 9-Node Reasoning Chain
```

### Components

#### 1. **ECAPA-TDNN Voice Embeddings**
State-of-the-art speaker verification using SpeechBrain.

**Specifications:**
- Model: `speechbrain/spkrec-ecapa-voxceleb` (192 dimensions)
- Storage: Cloud SQL (59 enrolled samples for primary user)
- Threshold: 85% confidence (Tier 2), 70% (Tier 1)
- Latency: ~200ms (Docker backend), ~1ms (L1 cache hit)

**Enrollment:**
```bash
# Enroll new voice profile
POST /api/voice/enroll
{
  "user_id": "derek",
  "audio_samples": [...],  # 3-5 samples recommended
  "tier": 2                # 1=low-auth, 2=strict-auth
}
```

#### 2. **Physics-Aware Anti-Spoofing**
Detects replay attacks and deepfakes using acoustic physics.

**Analysis Layers:**
1. **Vocal Tract Length** - Validates speaker's physical anatomy
2. **Reverberation Analysis** - Detects acoustic environment consistency
3. **Doppler Effect** - Detects pre-recorded audio (static frequency)
4. **Breathing Pattern** - Validates natural pauses and inhalation
5. **Bayesian Fusion** - Combines factors with adaptive priors

**Example Detection:**
```python
# Replay attack detected
{
  "ml_confidence": 0.89,  # High (voice matches)
  "physics_score": 0.12,  # Low (no breathing, flat reverberation)
  "final_decision": "REJECT",
  "reason": "Suspicious characteristics consistent with recording playback"
}
```

#### 3. **Behavioral Pattern Recognition (ChromaDB)**
Semantic voice pattern matching beyond raw embeddings.

**6 Collections:**
1. `voice_patterns` - Speech rhythm, cadence
2. `phrase_preferences` - Common phrases and variations
3. `emotional_baselines` - Stress levels, tone
4. `environmental_signatures` - Background noise profiles
5. `temporal_patterns` - Time-of-day voice variations
6. `authentication_history` - Past authentication contexts

**Features:**
- Detects "morning voice" vs "evening voice"
- Learns equipment signatures (AirPods vs Mac mic)
- Tracks voice evolution over time (seasonal changes)
- Context-aware thresholds (sick voice, loud environment)

#### 4. **Visual Security Integration (v6.2)**
Analyzes screen content during authentication to detect threats.

**Detection Cascade:**
```
Screen Capture → OmniParser → Claude Vision → OCR Fallback
                      │
                      ├─ Detect: Ransomware screens
                      ├─ Detect: Phishing dialogs
                      ├─ Detect: Suspicious prompts
                      └─ Verify: Normal lock screen
```

**Example:**
```json
{
  "visual_threat_detected": true,
  "threat_type": "ransomware_screen",
  "detected_text": "Your computer has been locked. Pay 0.5 BTC...",
  "action": "BLOCK_AUTHENTICATION",
  "defensive_actions": [
    "Screenshot saved for forensics",
    "Process killed (PID 49203)",
    "Security scan initiated",
    "Recent work backed up"
  ]
}
```

#### 5. **LangGraph Reasoning Chain**
9-node decision graph for complex authentication scenarios.

**Decision Nodes:**
1. Initial voice match
2. Confidence analysis (why low?)
3. Intelligent retry strategy
4. Multi-factor fusion
5. Context verification
6. Fallback selection
7. Challenge question (if needed)
8. Final decision
9. Learning & adaptation

**Example Flow:**
```
Voice Match: 72% (below threshold)
  ↓
Analyze: Background noise detected (SNR: 12 dB, normally 18 dB)
  ↓
Strategy: "Could you try again, speak louder and closer to mic?"
  ↓
Retry: 91% (success!)
  ↓
Decision: GRANT + Learn (store noisy environment profile)
```

### Cross-Repo Integration

VBIA events are broadcast to Ironcliw-Prime and Reactor-Core for analysis and training.

**Event Types:**
```python
# backend/core/cross_repo_state_initializer.py

class EventType(str, Enum):
    # Authentication events
    AUTHENTICATION_STARTED = "vbia_auth_started"
    AUTHENTICATION_SUCCESS = "vbia_auth_success"
    AUTHENTICATION_FAILED = "vbia_auth_failed"

    # Visual security events
    VISUAL_SECURITY_ANALYSIS = "vbia_visual_security"
    VISUAL_THREAT_DETECTED = "vbia_visual_threat"
    VISUAL_SAFE_CONFIRMED = "vbia_visual_safe"

    # Evidence collection
    EVIDENCE_COLLECTED = "vbia_evidence_collected"
    MULTI_FACTOR_FUSION = "vbia_multi_factor_fusion"

    # LangGraph reasoning
    REASONING_STARTED = "vbia_reasoning_started"
    REASONING_THOUGHT = "vbia_reasoning_thought"
    REASONING_COMPLETED = "vbia_reasoning_completed"
```

**Emit Event:**
```python
from backend.core.cross_repo_state_initializer import get_cross_repo_initializer

initializer = await get_cross_repo_initializer()
await initializer.emit_event(VBIAEvent(
    event_type=EventType.AUTHENTICATION_SUCCESS,
    source_repo=RepoType.Ironcliw,
    payload={
        "user_id": "derek",
        "confidence": 0.93,
        "factors": ["ml", "behavioral", "visual"],
        "latency_ms": 245
    }
))
```

### Observability

**Langfuse Decision Audit Trail:**
```python
# Every authentication logged with full decision trace
{
  "authentication_id": "auth_1234",
  "trace": [
    {"step": 1, "name": "audio_capture", "duration_ms": 147, "quality": 0.87},
    {"step": 2, "name": "embedding_extraction", "duration_ms": 203},
    {"step": 3, "name": "speaker_verification", "confidence": 0.934},
    {"step": 4, "name": "behavioral_analysis", "confidence": 0.96},
    {"step": 5, "name": "contextual_intelligence", "confidence": 0.98},
    {"step": 6, "name": "fusion_decision", "final_score": 0.949, "decision": "GRANT"}
  ],
  "total_time_ms": 2350,
  "cost": 0.0031,
  "risk_level": "minimal"
}
```

**Helicone Cost Tracking:**
```python
# Tracks ML inference costs across services
{
  "ecapa_tdnn_calls": 147,
  "claude_vision_calls": 12,
  "total_cost": 0.89,
  "cost_by_service": {
    "ecapa_docker": 0.0,      # Free (local)
    "claude_vision": 0.84,
    "chromadb_queries": 0.0,   # Free (local)
    "cloud_sql_queries": 0.05
  }
}
```

---

## 🕸️ Neural Mesh Coordination

60+ coordinated AI agents working in parallel with a unified communication bus.

### Architecture

```
Neural Mesh Network (10,000 messages/second)
    │
    ├─ Core Agents (12)
    │   ├─ MemoryAgent - ChromaDB, long-term storage
    │   ├─ CodeAgent - Repository intelligence, symbol search
    │   ├─ WebAgent - Real-time web scraping
    │   ├─ FileAgent - Filesystem operations
    │   ├─ TerminalAgent - Command execution
    │   ├─ CalendarAgent - Schedule management
    │   ├─ EmailAgent - Communication handling
    │   ├─ DocumentAgent - Content processing
    │   └─ ...
    │
    ├─ Google Workspace Agents (15)
    │   ├─ GmailAgent - Email operations
    │   ├─ CalendarAgent - Meeting scheduling
    │   ├─ DocsAgent - Document management
    │   ├─ SheetsAgent - Spreadsheet automation
    │   ├─ DriveAgent - File storage
    │   └─ ...
    │
    ├─ Visual Agents (8)
    │   ├─ ScreenCaptureAgent
    │   ├─ WindowManagementAgent
    │   ├─ OCRAgent
    │   └─ ...
    │
    └─ Specialized Agents (25+)
        ├─ SOPEnforcerAgent - Task governance
        ├─ RepositoryIntelligenceAgent - Code context
        ├─ CostOptimizationAgent - Budget management
        └─ ...
```

### Communication Bus

**Features:**
- **10,000 msg/s** - High-throughput message passing
- **Pub/Sub Model** - Async event-driven architecture
- **Topic-Based Routing** - Intelligent message filtering
- **Priority Queues** - Critical messages first
- **Message Persistence** - Redis-backed durability

**Example:**
```python
from backend.core.neural_mesh import get_neural_mesh

mesh = await get_neural_mesh()

# Register agent
await mesh.register_agent(
    agent_id="custom_agent",
    capabilities=["search", "analysis"],
    priority=5
)

# Publish message
await mesh.publish(
    topic="memory.query",
    payload={"query": "Recent conversations about AI", "limit": 10}
)

# Subscribe to topics
@mesh.subscribe(topic="memory.response")
async def handle_memory_response(message):
    print(f"Received: {message.payload}")
```

### Google Workspace Chief of Staff v3.1

Integrated AI assistant for Google Workspace with 12 admin capabilities.

**Capabilities:**
1. **Email Management** - Read, send, search, archive, label
2. **Calendar Operations** - Create events, find slots, manage availability
3. **Document Processing** - Create, edit, search Google Docs
4. **Spreadsheet Automation** - Data analysis, chart generation
5. **Drive Organization** - File management, sharing, search
6. **Meeting Coordination** - Schedule across participants, handle conflicts
7. **Task Management** - Create tasks from emails, track progress
8. **Contact Management** - Sync, update, search contacts
9. **Gmail Filters** - Smart categorization and routing
10. **Calendar Intelligence** - Suggest optimal meeting times
11. **Document Intelligence** - Extract insights from Docs
12. **Drive Intelligence** - Organize files by project/topic

**3-Tier Waterfall Fallback:**
```
User Request
  ↓
Tier 1: Natural Language Query (Claude)
  ├─ Success → Execute action
  └─ Fail ↓
Tier 2: Structured API Call (Google APIs)
  ├─ Success → Execute action
  └─ Fail ↓
Tier 3: Web Automation (Playwright)
  ├─ Success → Execute action
  └─ Fail → Error with context
```

**Example:**
```python
# Natural language request
await workspace_agent.execute(
    "Find the email from Derek about the Q4 budget and add it to my calendar"
)

# Executes:
# 1. Search Gmail for "from:derek Q4 budget"
# 2. Extract date/time from email body
# 3. Create calendar event with details
# 4. Reply to email confirming calendar entry
```

---

## 🔄 Coding Council Self-Evolution

Meta-level framework enabling Ironcliw to improve its own codebase autonomously.

### Architecture

```
User Request → Evolution Trigger → Safety Analysis → Plan Design → Code Generation
                                          │                │              │
                                          ├─ Risk Score    ├─ MetaGPT     ├─ Execution
                                          ├─ Complexity    ├─ Validation  ├─ Testing
                                          └─ Impact        └─ Review      └─ Rollback
```

### Components

#### 1. **SOP Enforcer v1.0**
Clinical-grade task governance preventing unconstrained evolution.

**Responsibilities:**
- Complexity analysis (simple/medium/complex)
- Design plan validation (architecture review)
- Risk assessment (impact scoring)
- MetaGPT-inspired discipline (structured thinking)
- Ironcliw Thinking Protocol enforcement

**Risk Scoring:**
```python
risk_score = (
    0.4 * complexity_score +      # How complex is this change?
    0.3 * impact_score +           # How many files affected?
    0.2 * reversibility_score +    # Can we rollback safely?
    0.1 * testing_coverage_score   # Are there tests?
)

# Thresholds
LOW_RISK = risk_score < 0.3        # Auto-approve
MEDIUM_RISK = 0.3 ≤ risk_score < 0.7   # Review required
HIGH_RISK = risk_score ≥ 0.7       # Manual approval + testing
```

#### 2. **Evolution Pipeline**
```
1. Intent Detection
   ├─ Is this a code modification request?
   └─ Extract: files, functions, goals

2. Safety Analysis (SOP Enforcer)
   ├─ Complexity: O(n), side effects, dependencies
   ├─ Risk: reversibility, test coverage
   └─ Decision: approve/review/reject

3. Plan Design (MetaGPT Approach)
   ├─ Architecture design
   ├─ Step-by-step implementation
   ├─ Testing strategy
   └─ Rollback plan

4. Code Generation
   ├─ Use LLM for code synthesis
   ├─ Apply coding standards
   └─ Generate unit tests

5. Execution & Testing
   ├─ Apply changes to codebase
   ├─ Run test suite
   ├─ Validate functionality
   └─ Rollback if tests fail

6. Observability
   ├─ Log all changes (Git)
   ├─ Track success/failure
   └─ Learn from outcomes
```

#### 3. **Intelligent Command Handler**
Routes evolution requests to appropriate execution strategy.

**Strategies:**
- **Direct Execution** - Simple, low-risk changes
- **Staged Execution** - Medium-risk, requires validation
- **Interactive Approval** - High-risk, needs human confirmation
- **Simulation Mode** - Test changes without applying

**Example:**
```python
# User: "Refactor the VBIA system to use async/await everywhere"

# Coding Council analysis:
{
  "complexity": "high",         # Touches 47 files
  "risk": 0.82,                 # High risk (core authentication)
  "requires_approval": true,
  "estimated_duration": "4 hours",
  "rollback_plan": "Git revert + schema rollback",
  "test_strategy": "Integration tests for all auth flows"
}

# Recommendation: MANUAL_APPROVAL_REQUIRED
```

---

## 🌍 Cross-Repository Integration

Unified ecosystem connecting Ironcliw, Ironcliw-Prime, and Reactor-Core.

### Startup Coordination (v6.3)

**Phase 1: Ironcliw Local** (Required)
```
Timeout: 30s
Success: Continue to Phase 2
Failure: Abort (critical dependency)
```

**Phase 2: External Repos** (Parallel)
```
┌─────────────────┐    ┌──────────────────┐
│ Ironcliw Prime    │    │ Reactor Core     │
│ Timeout: 30s    │    │ Timeout: 30s     │
│ Retry: 3x       │    │ Retry: 3x        │
│ Delay: 2s       │    │ Delay: 2s        │
│ Health: HTTP +  │    │ Health: HTTP +   │
│         File    │    │         File     │
└─────────────────┘    └──────────────────┘
         │                       │
         └───────┬───────────────┘
                 │
         Graceful Degradation
         (Optional repos can fail)
```

**Health Probing:**
```python
# 3 methods (prioritized)
1. Heartbeat file check (~/.jarvis/cross_repo/heartbeat.json)
   - Check timestamp < 30s old

2. State file check (prime_state.json, reactor_state.json)
   - Verify status = "ready" or "active"

3. HTTP health check (if configured)
   - GET {Ironcliw_PRIME_HEALTH_URL}
   - GET {REACTOR_CORE_HEALTH_URL}
```

**Configuration:**
```bash
# Coordinated startup
Ironcliw_COORDINATED_STARTUP_ENABLED=true
Ironcliw_GRACEFUL_DEGRADATION_ENABLED=true

# Timeouts
Ironcliw_REPO_STARTUP_TIMEOUT=30.0           # Per-repo startup timeout
Ironcliw_REPO_HEALTH_PROBE_TIMEOUT=5.0       # Health check timeout

# Retry policy
Ironcliw_REPO_HEALTH_RETRY_COUNT=3           # Number of retries
Ironcliw_REPO_HEALTH_RETRY_DELAY=2.0         # Delay between retries (seconds)

# Health endpoints (optional)
Ironcliw_PRIME_HEALTH_URL=http://localhost:8002/health
REACTOR_CORE_HEALTH_URL=http://localhost:8090/health
```

**Example Output:**
```
[CrossRepoState] ═══════════════════════════════════════════════
[CrossRepoState] v6.3: Starting coordinated multi-repo initialization
[CrossRepoState] ═══════════════════════════════════════════════
[CrossRepoState] Phase 1: Initializing Ironcliw local...
[CrossRepoState] ✅ Ironcliw local initialized
[CrossRepoState] Phase 2a: Initializing Ironcliw Prime...
[CrossRepoState] Phase 2b: Initializing Reactor Core...
[CrossRepoState] ✅ Ironcliw Prime initialized
[CrossRepoState] ⚠️ Reactor Core unavailable - degraded mode
[CrossRepoState] ═══════════════════════════════════════════════
[CrossRepoState] v6.3: Coordinated startup complete (12.34s)
[CrossRepoState]   • Success: 2/3 repos
[CrossRepoState]   • jarvis: ✅ Ready
[CrossRepoState]   • jarvis_prime: ✅ Ready
[CrossRepoState]   • reactor_core: ⚠️ Degraded
[CrossRepoState] ═══════════════════════════════════════════════
```

### Cost Synchronization

**Redis Pub/Sub Architecture:**
```
Ironcliw → Redis Channel "jarvis:cost:cross_repo" ← Ironcliw Prime
                            ↓                            ↓
                      Reactor Core                  [Others]

Messages:
{
  "repo": "jarvis",
  "cost": 0.0043,
  "tokens_in": 1000,
  "tokens_out": 500,
  "provider": "claude",
  "timestamp": "2026-01-14T10:30:45Z"
}
```

**File-Based Fallback:**
```
~/.jarvis/cost_tracking/
├── daily_cost.json          # Atomic operations
├── weekly_cost.json
└── monthly_cost.json
```

**Features:**
- Real-time cost aggregation across repos
- Per-repo cost attribution
- Budget enforcement (unified $5/day default)
- Cost anomaly detection
- Fallback to file-based when Redis unavailable

### Experience Forwarding

**Reactor-Core Integration:**
```
Ironcliw → Experience Events → Reactor-Core Training Pipeline

Experience Types:
- Task completion (success/failure)
- User corrections
- Error patterns
- Optimization opportunities
```

**WebSocket Communication:**
```python
# Primary: WebSocket (low latency)
ws://localhost:8090/training/experience

# Fallback: REST API
POST http://localhost:8090/api/training/experience
```

**Continuous Learning:**
```
User: "Ironcliw, unlock my screen"
Ironcliw: [Tries voice auth, fails]
Ironcliw: "Voice authentication failed - background noise"
User: [Manually unlocks with password]

Experience Recorded:
{
  "task": "voice_authentication",
  "outcome": "failed",
  "reason": "background_noise_threshold_exceeded",
  "context": {
    "snr": 12.3,  # Should be >18
    "environment": "coffee_shop",
    "time_of_day": "14:30"
  }
}

Reactor-Core Action:
- Adjusts noise threshold for coffee shop environment
- Creates training sample for adaptive thresholds
- Updates ChromaDB with environmental pattern
```

---

## 🛡️ Production Resilience

Production-grade reliability features ensuring zero-downtime operation.

### Circuit Breakers

**CrossRepoCircuitBreaker v2.0:**
```
States:
CLOSED  → Normal operation (all requests allowed)
OPEN    → Failure threshold exceeded (reject requests immediately)
HALF_OPEN → Testing recovery (limited requests allowed)

Transitions:
CLOSED → OPEN: After N failures in window
OPEN → HALF_OPEN: After timeout expires
HALF_OPEN → CLOSED: After M successful requests
HALF_OPEN → OPEN: If any request fails
```

**Configuration:**
```python
from backend.core.resilience.cross_repo_circuit_breaker import (
    CrossRepoCircuitBreaker,
    CircuitBreakerConfig
)

breaker = CrossRepoCircuitBreaker(
    name="my_circuit_breaker",
    config=CircuitBreakerConfig(
        failure_threshold=3,        # Open after 3 failures
        success_threshold=2,        # Close after 2 successes in half-open
        timeout_seconds=30.0,       # Try recovery after 30s
        half_open_max_calls=5       # Limit requests during recovery
    )
)

# Use circuit breaker
result = await breaker.execute(
    tier="jarvis_prime",
    func=lambda: call_jarvis_prime(),
    timeout=5.0
)
```

**Metrics:**
```python
health = breaker.get_tier_health("jarvis_prime")
{
  "state": "closed",
  "success_rate": 0.98,
  "failure_count": 2,
  "last_failure": "2026-01-14T10:25:13Z",
  "consecutive_successes": 47,
  "dominant_failure_type": "timeout"
}
```

### Graceful Degradation

**Fallback Chains:**
```
Primary Tier Fails
  ↓
Try Tier 2
  ↓ (fails)
Try Tier 3
  ↓ (fails)
Try Tier 4
  ↓ (all fail)
Enter Degradation Mode
  ↓
Timeout-Based Recovery (v2.1)
  ├─ Probe tiers every 5 minutes
  ├─ Exit degradation when any tier responds
  └─ Continue serving degraded responses until recovery
```

**Example:**
```python
# Local Prime fails (out of memory)
decision = route_request(task="reasoning")
# → Falls back to GCP Cloud Run

# Cloud Run fails (quota exceeded)
# → Falls back to Claude API

# Claude fails (network error)
# → Returns degraded response:
{
  "response": "[System operating in degraded mode - please try again later]",
  "degraded": true,
  "all_tiers_failed": true,
  "error": "All tiers unavailable",
  "degradation_entered_at": "2026-01-14T10:30:00Z",
  "recovery_timeout": 300.0  # Will retry in 5 minutes
}
```

### Timeout Recovery (v2.1)

**Degradation Mode Recovery:**
```python
# Automatic recovery probing
while in_degradation_mode:
    if elapsed_time > recovery_timeout:
        for tier in [LOCAL_PRIME, GCP_CLOUD_RUN, CLOUD_CLAUDE]:
            if probe_tier_health(tier):
                exit_degradation_mode()
                log(f"Recovered via {tier}")
                return

        # No tier recovered, reset timeout
        degradation_entered_at = now()
```

**Configuration:**
```bash
DEGRADATION_RECOVERY_TIMEOUT=300.0  # 5 minutes (default)
```

### Self-Healing

**Active Request Counter Validation (v2.1):**
```python
# Prevents stuck counters from blocking VM termination
async def validate_active_requests():
    if no_requests_in_last_60_seconds:
        for tier, count in active_requests.items():
            if count > 0:
                log(f"Stuck counter detected: {tier}={count}")
                active_requests[tier] = 0  # Reset
```

**Configuration:**
```bash
ACTIVE_REQUEST_VALIDATION_INTERVAL=60.0  # Check every 60 seconds
```

---

## 👁️ God Mode Surveillance

Universal window monitoring across physical and virtual displays.

### Overview

Watch **any application** for **any visual event** across **all desktop spaces** including virtual displays (BetterDisplay Ghost Monitor).

### Capabilities

```bash
# Example commands
"Watch all Chrome windows for bouncing ball"
"Monitor every Terminal for BUILD SUCCESS"
"Track all Slack windows for Derek mentioned"
"Watch Gmail for urgent email"
"Monitor Figma for comment added"
```

### Protocol Suite (v53-v63)

| Version | Protocol | Purpose |
|---------|----------|---------|
| **v53** | NAVIGATOR | Space-aware SIP-compliant teleportation |
| **v55** | PHOENIX | Dynamic window ID resurrection |
| **v56** | REAPER | Stale window purging |
| **v60** | PANOPTICON | Ghost Display visibility (0% → 100%) |
| **v60** | VALIDATION BYPASS | Auto-validate Ghost Display (2.8s → 0.001s) |
| **v61** | RETINA | Display-aware capture routing |
| **v63** | BOOMERANG | Intelligent auto-summon via OS signals |
| **v65** | ASYNC-AWARENESS | Zero timeouts with background setup |
| **v66** | COMMAND & CONTROL | Guaranteed voice command execution |

### Technical Metrics

| Metric | Before v53 | After v61.2 | Improvement |
|--------|------------|-------------|-------------|
| Virtual Display Support | 0% | 100% | ∞ |
| Stale Window Detection | 10% | 98% | 880% |
| Validation Speed (Ghost) | 2.8s fail | 0.001s pass | 2800x |
| Success Rate | 40% | 94% | 135% |
| CPU Usage (5 windows) | 15% | 3% | 5x reduction |

### Capture Modes

**Mosaic Mode (O(1) - Virtual Displays):**
```python
# Single AVFoundation stream captures entire virtual display
# All windows visible simultaneously
# 0.001s validation (instant)
# 3% CPU usage
```

**Ferrari Engine (O(N) - Physical Displays):**
```python
# ScreenCaptureKit per-window capture
# Required for SIP-protected physical displays
# 15% CPU usage (optimized)
```

### Visual Detection Cascade

```
OmniParser → Claude Vision → OCR Fallback

Confidence Thresholds:
- OmniParser: 95% fuzzy match
- Claude Vision: 90% confidence
- OCR: 85% similarity
```

---

## ⚙️ Configuration

### Environment Variables

#### Core System
```bash
# Startup
Ironcliw_FAST_STARTUP=false                  # Skip health checks for dev
Ironcliw_GLOBAL_STARTUP_TIMEOUT=600.0        # Max startup time (10 minutes)

# Logging
Ironcliw_LOG_LEVEL=INFO                      # DEBUG, INFO, WARNING, ERROR
Ironcliw_LOG_FILE=/var/log/jarvis/jarvis.log

# Database
Ironcliw_DB_PATH=~/.jarvis/jarvis.db         # SQLite database
Ironcliw_CLOUD_SQL_ENABLED=true              # Use Cloud SQL for voice profiles
```

#### LLM Routing
```bash
# Model preferences (v100.2)
Ironcliw_PRIMARY_MODEL=prime_local           # prime_local, claude, gemini
Ironcliw_FALLBACK_MODEL=claude              # Fallback when primary unavailable

# Cost management
Ironcliw_UNIFIED_DAILY_BUDGET=5.00          # $5/day across all repos
MAX_SINGLE_REQUEST_COST=0.50               # Max $0.50 per request

# Timeouts
LOCAL_TIMEOUT_MS=5000
GCP_TIMEOUT_MS=30000
CLOUD_API_TIMEOUT_MS=60000

# Resilience (v2.1)
DEGRADATION_RECOVERY_TIMEOUT=300.0
ACTIVE_REQUEST_VALIDATION_INTERVAL=60.0
```

#### Cross-Repo Integration
```bash
# Trinity coordination
Ironcliw_COORDINATED_STARTUP_ENABLED=true
Ironcliw_GRACEFUL_DEGRADATION_ENABLED=true
CROSS_REPO_NEURAL_MESH_ENABLED=true
CROSS_REPO_COST_SYNC_ENABLED=true

# Repo paths
Ironcliw_REPO_PATH=~/Documents/repos/Ironcliw-AI-Agent
Ironcliw_PRIME_REPO_PATH=~/Documents/repos/jarvis-prime
REACTOR_CORE_REPO_PATH=~/Documents/repos/reactor-core

# Health endpoints
Ironcliw_PRIME_HEALTH_URL=http://localhost:8002/health
REACTOR_CORE_HEALTH_URL=http://localhost:8090/health

# Startup timeouts
Ironcliw_REPO_STARTUP_TIMEOUT=30.0
Ironcliw_REPO_HEALTH_PROBE_TIMEOUT=5.0
Ironcliw_REPO_HEALTH_RETRY_COUNT=3
Ironcliw_REPO_HEALTH_RETRY_DELAY=2.0
```

#### Voice Biometric Intelligence
```bash
# Authentication thresholds
Ironcliw_TIER1_VBIA_THRESHOLD=0.70           # Low-auth tier
Ironcliw_TIER2_VBIA_THRESHOLD=0.85           # Strict-auth tier

# Features
Ironcliw_VOICE_AUTH_PRE_EXECUTION=true       # Verify before executing
Ironcliw_VOICE_CONTINUOUS_VERIFY=false       # Continuous background verification
Ironcliw_VOICE_ENV_ADAPT=true                # Adapt to environment noise
Ironcliw_ANTI_SPOOFING_ENABLED=true          # Physics-aware anti-spoofing

# Visual security
Ironcliw_VISUAL_SECURITY_ENABLED=true
Ironcliw_VISUAL_SECURITY_MODE=omniparser     # omniparser, claude_vision, ocr

# Caching
Ironcliw_VOICE_CACHE_TTL=30.0                # Semantic cache TTL (seconds)

# Observability
Ironcliw_VOICE_WATCHDOG_INTEGRATION=true
```

#### Google Workspace
```bash
# Enable Chief of Staff
Ironcliw_GOOGLE_WORKSPACE_ENABLED=true

# Credentials
GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json
GOOGLE_WORKSPACE_DOMAIN=yourcompany.com
GOOGLE_WORKSPACE_USER_EMAIL=you@yourcompany.com

# Features
Ironcliw_GMAIL_ENABLED=true
Ironcliw_CALENDAR_ENABLED=true
Ironcliw_DOCS_ENABLED=true
Ironcliw_DRIVE_ENABLED=true
```

#### Neural Mesh
```bash
# Message bus
NEURAL_MESH_ENABLED=true
NEURAL_MESH_MESSAGE_RATE=10000             # 10k messages/second
NEURAL_MESH_REDIS_URL=redis://localhost:6379

# Agent registration
NEURAL_MESH_AUTO_REGISTER=true
NEURAL_MESH_HEALTH_CHECK_INTERVAL=30.0
```

#### God Mode Surveillance
```bash
# Ghost Display
Ironcliw_SHADOW_DISPLAY=BetterDisplay        # Virtual display name
GHOST_DISPLAY_ID=2                         # Display ID

# Capture
Ironcliw_CAPTURE_MODE=auto                   # auto, mosaic, ferrari
Ironcliw_OCR_CONFIDENCE_THRESHOLD=0.85

# Detection
Ironcliw_OMNIPARSER_ENABLED=true
Ironcliw_CLAUDE_VISION_ENABLED=true
Ironcliw_OCR_FALLBACK_ENABLED=true
```

---

## 📚 API Reference

### UnifiedModelServing

```python
from backend.intelligence.unified_model_serving import get_model_server

server = await get_model_server()

# Generate text
result = await server.generate(
    prompt="Explain quantum computing",
    task_type="reasoning",     # chat, reasoning, code, vision, tool_use
    max_tokens=2000,
    temperature=0.7,
    preferred_provider="prime_local"  # Optional override
)

# Get provider statistics (v100.2)
stats = server.get_router().get_provider_stats()
# Returns: {"prime_local": {"success_rate": 0.98, "avg_latency_ms": 1200, ...}}

# Record provider result (for adaptive routing)
server.get_router().record_provider_result(
    provider=ModelProvider.PRIME_LOCAL,
    success=True,
    latency_ms=1245.0
)
```

### Cross-Repo State

```python
from backend.core.cross_repo_state_initializer import (
    initialize_all_repos_coordinated,
    get_initialization_status,
    get_cross_repo_initializer
)

# Coordinated startup
results = await initialize_all_repos_coordinated()
# Returns: {RepoType.Ironcliw: True, RepoType.Ironcliw_PRIME: True, ...}

# Check status
status = await get_initialization_status()
# Returns: {
#   "coordinated_startup_enabled": True,
#   "graceful_degradation_enabled": True,
#   "repos": {
#     "jarvis": {"status": "ready", "last_update": "...", "capabilities": {...}},
#     ...
#   }
# }

# Emit event
initializer = await get_cross_repo_initializer()
await initializer.emit_event(VBIAEvent(
    event_type=EventType.AUTHENTICATION_SUCCESS,
    source_repo=RepoType.Ironcliw,
    payload={"user_id": "derek", "confidence": 0.93}
))

# Get recent events
events = await initializer.get_recent_events(limit=100)
```

### GCP Hybrid Router

```python
from backend.core.gcp_hybrid_prime_router import get_gcp_hybrid_router

router = await get_gcp_hybrid_router()

# Route request
result = await router.route_request(
    payload={"prompt": "Hello", "max_tokens": 1000}
)

# Get metrics
metrics = router.get_metrics()
print(f"Total requests: {metrics.total_requests}")
print(f"Budget blocks: {metrics.budget_blocks}")
print(f"Avg latency: {metrics.avg_latency_ms:.1f}ms")

# Get tier health
health = router.get_tier_health()
for tier, status in health.items():
    print(f"{tier}: {status.state} (success_rate: {status.success_rate:.2%})")

# Check degradation status
if router.is_degraded():
    reason = router.get_degradation_reason()
    print(f"Degraded: {reason}")
```

### Neural Mesh

```python
from backend.core.neural_mesh import get_neural_mesh

mesh = await get_neural_mesh()

# Register agent
await mesh.register_agent(
    agent_id="my_agent",
    capabilities=["search", "analysis"],
    priority=5
)

# Publish message
await mesh.publish(
    topic="task.execute",
    payload={"task": "search", "query": "AI research papers"}
)

# Subscribe to messages
@mesh.subscribe(topic="task.result")
async def handle_result(message):
    print(f"Result: {message.payload}")

# Health check
health = await mesh.get_health()
print(f"Registered agents: {health['agent_count']}")
print(f"Messages/sec: {health['message_rate']}")
```

---

## 🛠️ Development

### Running Tests

```bash
# All tests
pytest

# Specific test suite
pytest tests/unit/test_unified_model_serving.py
pytest tests/integration/test_cross_repo_startup.py

# With coverage
pytest --cov=backend --cov-report=html

# Parallel execution
pytest -n auto
```

### Debugging

```bash
# Enable debug logging
export Ironcliw_LOG_LEVEL=DEBUG

# Run with verbose output
python3 run_supervisor.py --verbose

# Interactive Python shell with Ironcliw context
python3 -i -c "from backend.core import *"
```

### Code Quality

```bash
# Linting
ruff check backend/

# Formatting
black backend/

# Type checking
mypy backend/

# Security scan
bandit -r backend/
```

---

## 🐛 Troubleshooting

### Common Issues

#### 1. "Ironcliw-Prime failed to initialize"

**Cause:** Ironcliw-Prime repo not found or not running.

**Solution:**
```bash
# Check Ironcliw-Prime is running
curl http://localhost:8002/health

# Check repo path
echo $Ironcliw_PRIME_REPO_PATH

# Disable if not needed
export Ironcliw_COORDINATED_STARTUP_ENABLED=false
```

#### 2. "Degradation mode - all tiers failed"

**Cause:** All LLM providers unavailable (local, GCP, Claude).

**Solution:**
```bash
# Check local Prime
ps aux | grep prime

# Check GCP quota
gcloud compute project-info describe --project=your-project

# Check API keys
echo $ANTHROPIC_API_KEY

# Check recovery timeout
export DEGRADATION_RECOVERY_TIMEOUT=60.0  # Reduce to 1 minute
```

#### 3. "Voice authentication failed - background noise"

**Cause:** Environmental noise exceeding threshold.

**Solution:**
```bash
# Enable adaptive thresholds
export Ironcliw_VOICE_ENV_ADAPT=true

# Lower threshold temporarily
export Ironcliw_TIER2_VBIA_THRESHOLD=0.75

# Check microphone
# Speak louder and closer to mic
```

#### 4. "Stuck active request counter"

**Cause:** Exception between increment/decrement left counter in invalid state.

**Solution:**
```bash
# Enable automatic validation (v2.1)
export ACTIVE_REQUEST_VALIDATION_INTERVAL=60.0

# Counter will be reset within 60 seconds
```

### Logs

```bash
# Main log
tail -f ~/.jarvis/logs/jarvis.log

# Supervisor log
tail -f ~/.jarvis/logs/supervisor.log

# Voice authentication log
tail -f ~/.jarvis/logs/vbia.log

# Cross-repo events
cat ~/.jarvis/cross_repo/vbia_events.json | jq '.[-10:]'
```

---

## 📊 Metrics & Monitoring

### Langfuse Dashboard

Access: `https://cloud.langfuse.com`

**Metrics:**
- Authentication decision traces
- LLM routing performance
- Cost per request
- Latency percentiles (p50, p95, p99)
- Error rates by provider

### Helicone Dashboard

Access: `https://www.helicone.ai`

**Metrics:**
- Total API costs
- Cost breakdown by service (Claude, Gemini, etc.)
- Token usage (input/output)
- Request volume over time
- Cost optimization suggestions

### Local Metrics

```bash
# Get router stats
curl http://localhost:8010/api/metrics/router

# Get neural mesh stats
curl http://localhost:8010/api/metrics/neural_mesh

# Get voice auth stats
curl http://localhost:8010/api/metrics/vbia

# Prometheus endpoint
curl http://localhost:8010/metrics
```

---

## 🙏 Acknowledgments

Built with:
- **Claude Opus 4.5** (Anthropic) - Primary reasoning model
- **Ironcliw-Prime** (Llama 70B) - Local LLM brain
- **SpeechBrain** - ECAPA-TDNN voice embeddings
- **ChromaDB** - Vector database for semantic memory
- **LangChain/LangGraph** - Agent orchestration
- **BabyAGI** - Task decomposition inspiration
- **MetaGPT** - Multi-agent collaboration patterns

Special thanks to the open-source community for the amazing tools and libraries.

---

## 📜 License

MIT License - See [LICENSE](LICENSE) file for details.

---

## 🔗 Links

- **Documentation**: [https://jarvis-docs.example.com](https://jarvis-docs.example.com)
- **Issue Tracker**: [GitHub Issues](https://github.com/yourusername/Ironcliw-AI-Agent/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/Ironcliw-AI-Agent/discussions)
- **Blog**: [Ironcliw Development Blog](https://blog.example.com)

---

**Made with ❤️ by the Ironcliw Team**

*"Just Another Rather Very Intelligent System"*
