name: Deploy Ironcliw to GCP

on:
  push:
    branches:
      - main
      - multi-monitor-support
    paths:
      - 'backend/**'
      - 'start_system.py'  # Root startup script with hybrid routing
      - '.github/workflows/deploy-to-gcp.yml'

  workflow_dispatch:
    inputs:
      skip_tests:
        description: 'Skip pre-deployment tests'
        required: false
        default: 'false'

jobs:
  pre-deployment-checks:
    name: Pre-Deployment Validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.10'

      - name: Validate Configuration
        run: |
          pip install pyyaml
          python -c "
          import yaml
          print('🔍 Validating hybrid configuration...')
          with open('backend/core/hybrid_config.yaml', 'r') as f:
              config = yaml.safe_load(f)
          assert 'hybrid' in config
          assert config['hybrid']['intelligence']['uae']['enabled']
          print('✅ Configuration valid')
          "

      - name: Check Critical Files
        run: |
          echo "📋 Checking critical files..."
          test -f backend/core/hybrid_orchestrator.py && echo "✅ hybrid_orchestrator.py"
          test -f backend/core/hybrid_router.py && echo "✅ hybrid_router.py"
          test -f backend/core/hybrid_config.yaml && echo "✅ hybrid_config.yaml"
          test -f backend/main.py && echo "✅ main.py"
          echo "✅ All critical files present"

  deploy:
    name: Deploy to GCP (Spot VM Architecture)
    runs-on: ubuntu-latest
    needs: pre-deployment-checks

    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Cleanup Orphaned VMs
        run: |
          echo "🧹 Cleaning up orphaned VMs..."
          bash scripts/cleanup_orphaned_vms.sh || echo "⚠️  Cleanup script failed, continuing..."

      - name: Deploy Code to Cloud Storage
        run: |
          BRANCH="${{ github.ref_name }}"
          COMMIT="${{ github.sha }}"
          DEPLOYMENT_BUCKET="gs://jarvis-473803-deployments"

          echo "📦 Creating deployment package..."

          # Create deployment archive
          tar -czf jarvis-${COMMIT}.tar.gz \
            --exclude='backend/__pycache__' \
            --exclude='backend/*.pyc' \
            --exclude='backend/logs/*' \
            --exclude='backend/.env' \
            backend/ \
            start_system.py \
            scripts/

          # Upload to Cloud Storage
          echo "☁️  Uploading to Cloud Storage..."

          # Create bucket if it doesn't exist
          if ! gcloud storage buckets describe ${DEPLOYMENT_BUCKET} > /dev/null 2>&1; then
            echo "Creating bucket ${DEPLOYMENT_BUCKET}..."
            gcloud storage buckets create ${DEPLOYMENT_BUCKET} \
              --location=us-central1 \
              --project=${{ secrets.GCP_PROJECT_ID }} || {
                echo "⚠️  Bucket creation failed, but continuing (it may already exist)"
              }
          else
            echo "✅ Bucket ${DEPLOYMENT_BUCKET} already exists"
          fi

          # Cost guardrail: ensure old deployment artifacts expire automatically
          # (prevents unbounded Cloud Storage growth from frequent deploys).
          TTL_DAYS="${DEPLOYMENT_ARTIFACT_TTL_DAYS:-30}"
          echo "🧹 Ensuring bucket lifecycle policy (TTL=${TTL_DAYS} days) ..."
          cat > lifecycle.json << EOF
          {
            "rule": [
              {
                "action": { "type": "Delete" },
                "condition": {
                  "age": ${TTL_DAYS},
                  "matchesPrefix": ["jarvis-", "metadata-"]
                }
              }
            ]
          }
          EOF
          # gsutil is available with setup-gcloud; lifecycle set is idempotent.
          gsutil lifecycle set lifecycle.json ${DEPLOYMENT_BUCKET} || echo "⚠️  Could not set lifecycle policy (continuing)"

          # Upload deployment package
          echo "📤 Uploading deployment package..."
          gcloud storage cp jarvis-${COMMIT}.tar.gz ${DEPLOYMENT_BUCKET}/ || {
            echo "❌ Failed to upload deployment package"
            exit 1
          }

          # Create latest pointer
          echo "$COMMIT" > latest-${BRANCH}.txt
          gcloud storage cp latest-${BRANCH}.txt ${DEPLOYMENT_BUCKET}/

          # Create deployment metadata
          cat > deployment-metadata.json << METADATA
          {
            "branch": "${BRANCH}",
            "commit": "${COMMIT}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "deployer": "${{ github.actor }}",
            "artifact": "jarvis-${COMMIT}.tar.gz"
          }
          METADATA

          gcloud storage cp deployment-metadata.json ${DEPLOYMENT_BUCKET}/metadata-${COMMIT}.json

          echo "✅ Deployment package uploaded"
          echo "📍 Location: ${DEPLOYMENT_BUCKET}/jarvis-${COMMIT}.tar.gz"
          echo "🔗 Latest ${BRANCH}: ${DEPLOYMENT_BUCKET}/latest-${BRANCH}.txt"

      - name: Verify Deployment Accessibility
        run: |
          DEPLOYMENT_BUCKET="gs://jarvis-473803-deployments"
          BRANCH="${{ github.ref_name }}"
          COMMIT="${{ github.sha }}"

          echo "✅ Deployment package is now available at:"
          echo "   ${DEPLOYMENT_BUCKET}/jarvis-${COMMIT}.tar.gz"
          echo ""
          echo "📝 Spot VMs will automatically pull this code on creation"
          echo "   via the startup script embedded in start_system.py"
          echo ""
          echo "ℹ️  To deploy:"
          echo "   1. Start Ironcliw locally: python start_system.py"
          echo "   2. When RAM > 85%, Spot VM auto-creates"
          echo "   3. Spot VM pulls latest code from Cloud Storage"
          echo "   4. Ironcliw runs with latest changes"

      - name: Deployment Summary
        if: always()
        run: |
          echo "## 🚀 Deployment Report (Spot VM Architecture)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Status:** ${{ job.status == 'success' && '✅ Success' || '❌ Failed' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Artifact:** gs://jarvis-473803-deployments/jarvis-${{ github.sha }}.tar.gz" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Deployment Model" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **On-Demand Spot VMs** (created when RAM > 85%)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **Cloud Storage Deployment** (VMs pull latest code automatically)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **Auto-Cleanup** (VMs deleted on shutdown)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **Cost Optimized** (~$11-15/month vs $180/month)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Features Available" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Hybrid Architecture (Local + GCP)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Intelligence Systems (UAE/SAI/CAI)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Learning Database (Cloud SQL)" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Intelligent Routing" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### How to Deploy" >> $GITHUB_STEP_SUMMARY
          echo "1. Run Ironcliw locally: \`python start_system.py\`" >> $GITHUB_STEP_SUMMARY
          echo "2. System auto-scales to GCP when RAM > 85%" >> $GITHUB_STEP_SUMMARY
          echo "3. Spot VMs auto-pull latest code from Cloud Storage" >> $GITHUB_STEP_SUMMARY
          echo "4. VMs auto-delete when Ironcliw stops (Ctrl+C)" >> $GITHUB_STEP_SUMMARY

  verify-deployment-package:
    name: Verify Deployment Package
    runs-on: ubuntu-latest
    needs: deploy
    if: success()

    steps:
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Verify Package Exists
        run: |
          DEPLOYMENT_BUCKET="gs://jarvis-473803-deployments"
          COMMIT="${{ github.sha }}"
          BRANCH="${{ github.ref_name }}"

          echo "🔍 Verifying deployment package..."

          # Check if artifact exists
          if gcloud storage ls ${DEPLOYMENT_BUCKET}/jarvis-${COMMIT}.tar.gz > /dev/null 2>&1; then
            echo "✅ Deployment artifact found"
          else
            echo "❌ Deployment artifact not found"
            exit 1
          fi

          # Check if metadata exists
          if gcloud storage ls ${DEPLOYMENT_BUCKET}/metadata-${COMMIT}.json > /dev/null 2>&1; then
            echo "✅ Deployment metadata found"
            gcloud storage cat ${DEPLOYMENT_BUCKET}/metadata-${COMMIT}.json
          else
            echo "⚠️  Deployment metadata not found"
          fi

          # Check latest pointer
          if gcloud storage ls ${DEPLOYMENT_BUCKET}/latest-${BRANCH}.txt > /dev/null 2>&1; then
            LATEST_COMMIT=$(gcloud storage cat ${DEPLOYMENT_BUCKET}/latest-${BRANCH}.txt)
            echo "✅ Latest ${BRANCH} commit: ${LATEST_COMMIT}"
          else
            echo "⚠️  Latest ${BRANCH} pointer not found"
          fi

      - name: Summary
        run: |
          echo "## ✅ Deployment Package Verified" >> $GITHUB_STEP_SUMMARY
          echo "Spot VMs will pull this code on creation!" >> $GITHUB_STEP_SUMMARY
