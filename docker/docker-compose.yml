# =============================================================================
# Ironcliw AI Agent - Unified Docker Compose Configuration v9.4
# =============================================================================
#
# Multi-Repo Integration Stack connecting:
# - Ironcliw-AI-Agent: Main FastAPI server with Neural Mesh
# - Ironcliw-Prime: Local LLM inference (from jarvis-prime repo)
# - Reactor-Core: Training pipeline (from reactor-core repo)
#
# Services:
# - jarvis-backend: Main API with 60+ agent Neural Mesh
# - jarvis-frontend: React frontend via nginx
# - jarvis-training: Continuous learning + Safe Scout
# - jarvis-prime: Custom GGUF model inference (optional)
# - jarvis-prime-cloud: Cloud Run inference proxy (optional)
# - reactor-core: Training pipeline orchestrator (optional)
# - redis: Distributed caching and session storage
# - chromadb: Vector database for embeddings
#
# Profiles:
#   default       - Backend, Frontend, Training, Redis, ChromaDB
#   local-llm     - Add local Ironcliw-Prime inference
#   cloud-llm     - Add Cloud Run inference proxy
#   full-training - Add Reactor-Core training pipeline
#   all           - Everything enabled
#
# Usage:
#   docker compose up -d                           # Default stack
#   docker compose --profile local-llm up -d       # With local inference
#   docker compose --profile all up -d             # Everything
#   docker compose logs -f jarvis-backend          # View logs
#   docker compose down -v                         # Stop and remove volumes
#
# Version: 9.4.0
# =============================================================================

# =============================================================================
# Networks
# =============================================================================
networks:
  jarvis-network:
    name: jarvis-unified-network
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16
          gateway: 172.28.0.1

# =============================================================================
# Volumes - Shared across all repos
# =============================================================================
volumes:
  # Core data
  jarvis-data:
    name: jarvis-unified-data
    driver: local

  # Shared models (accessible by all services)
  jarvis-models:
    name: jarvis-unified-models
    driver: local

  # Logs
  jarvis-logs:
    name: jarvis-unified-logs
    driver: local

  # Training database
  jarvis-training-db:
    name: jarvis-training-db
    driver: local

  # ChromaDB persistence
  chromadb-data:
    name: jarvis-chromadb-data
    driver: local

  # Redis persistence
  redis-data:
    name: jarvis-redis-data
    driver: local

  # Reactor-Core work directory
  reactor-work:
    name: jarvis-reactor-work
    driver: local

# =============================================================================
# Services
# =============================================================================
services:
  # ---------------------------------------------------------------------------
  # Ironcliw Backend - Main API Server
  # ---------------------------------------------------------------------------
  jarvis-backend:
    build:
      context: ..
      dockerfile: docker/Dockerfile.backend
    image: jarvis-backend:${Ironcliw_VERSION:-9.4.0}
    container_name: jarvis-backend
    hostname: jarvis-backend
    restart: unless-stopped

    # Entrypoint
    entrypoint: ["/app/entrypoint.sh"]
    command: ["supervisor"]

    # Ports
    ports:
      - "${Ironcliw_API_PORT:-8010}:8010"
      - "${Ironcliw_LOADING_PORT:-8011}:8011"

    # Environment
    environment:
      # Core
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app:/app/backend
      - Ironcliw_DOCKER=true
      - Ironcliw_ENV=${Ironcliw_ENV:-production}

      # Paths
      - Ironcliw_DATA_DIR=/app/data
      - Ironcliw_MODELS_DIR=/app/models
      - Ironcliw_LOGS_DIR=/app/data/logs
      - Ironcliw_TRAINING_DB=/app/data/training_db/jarvis_training.db

      # API Keys (from .env)
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}

      # Ironcliw Prime
      - Ironcliw_PRIME_URL=http://jarvis-prime:8012
      - Ironcliw_PRIME_CLOUD_RUN_URL=${Ironcliw_PRIME_CLOUD_RUN_URL:-}

      # Redis
      - REDIS_URL=redis://redis:6379/0

      # Neural Mesh
      - NEURAL_MESH_ENABLED=${NEURAL_MESH_ENABLED:-true}
      - NEURAL_MESH_PRODUCTION=${NEURAL_MESH_PRODUCTION:-true}
      - NEURAL_MESH_MAX_AGENTS=${NEURAL_MESH_MAX_AGENTS:-60}

      # Data Flywheel
      - DATA_FLYWHEEL_ENABLED=${DATA_FLYWHEEL_ENABLED:-true}
      - TRAINING_SCHEDULE=${TRAINING_SCHEDULE:-03:00}

      # GCS (for model uploads)
      - GCS_BUCKET=${GCS_BUCKET:-}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/credentials/gcp-key.json

    # Volumes
    volumes:
      - jarvis-data:/app/data
      - jarvis-models:/app/models
      - jarvis-logs:/app/data/logs
      - ${GCP_CREDENTIALS_PATH:-./credentials}:/app/credentials:ro

    # Dependencies
    depends_on:
      redis:
        condition: service_healthy

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8010/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    # Network
    networks:
      jarvis-network:
        ipv4_address: 172.28.0.10

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: "${BACKEND_CPU_LIMIT:-4}"
          memory: ${BACKEND_MEMORY_LIMIT:-8G}
        reservations:
          cpus: "1"
          memory: 2G

  # ---------------------------------------------------------------------------
  # Ironcliw Frontend - React Web Interface
  # ---------------------------------------------------------------------------
  jarvis-frontend:
    build:
      context: ..
      dockerfile: docker/Dockerfile.frontend
    image: jarvis-frontend:${Ironcliw_VERSION:-9.4.0}
    container_name: jarvis-frontend
    hostname: jarvis-frontend
    restart: unless-stopped

    # Ports
    ports:
      - "${Ironcliw_FRONTEND_PORT:-3000}:80"

    # Dependencies
    depends_on:
      jarvis-backend:
        condition: service_healthy

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

    # Network
    networks:
      jarvis-network:
        ipv4_address: 172.28.0.11

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 512M

  # ---------------------------------------------------------------------------
  # Ironcliw Training Engine - Continuous Learning
  # ---------------------------------------------------------------------------
  jarvis-training:
    build:
      context: ..
      dockerfile: docker/Dockerfile.training
    image: jarvis-training:${Ironcliw_VERSION:-9.4.0}
    container_name: jarvis-training
    hostname: jarvis-training
    restart: unless-stopped

    # Entrypoint
    entrypoint: ["python3", "docker/training_entrypoint.py"]
    command: ["--mode", "continuous"]

    # Environment
    environment:
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app:/app/backend
      - Ironcliw_DOCKER=true

      # Database
      - Ironcliw_TRAINING_DB=/app/data/training_db/jarvis_training.db

      # Training
      - Ironcliw_TRAINING_ENABLED=${TRAINING_ENABLED:-true}
      - Ironcliw_TRAINING_SCHEDULE=${TRAINING_SCHEDULE:-03:00}
      - Ironcliw_TRAINING_MIN_EXPERIENCES=${TRAINING_MIN_EXPERIENCES:-100}
      - Ironcliw_TRAINING_COOLDOWN_HOURS=${TRAINING_COOLDOWN_HOURS:-24}

      # Scraping
      - CONTINUOUS_SCRAPING_ENABLED=${CONTINUOUS_SCRAPING_ENABLED:-true}
      - CONTINUOUS_SCRAPING_INTERVAL_HOURS=${SCRAPING_INTERVAL_HOURS:-4}
      - CONTINUOUS_SCRAPING_MAX_PAGES=${SCRAPING_MAX_PAGES:-50}

      # Models
      - Ironcliw_MODELS_DIR=/app/models
      - GGUF_EXPORT_ENABLED=${GGUF_EXPORT_ENABLED:-true}
      - GGUF_QUANTIZATION=${GGUF_QUANTIZATION:-q4_k_m}

      # GCS
      - GCS_UPLOAD_ENABLED=${GCS_UPLOAD_ENABLED:-false}
      - GCS_MODELS_BUCKET=${GCS_BUCKET:-}

    # Volumes
    volumes:
      - jarvis-data:/app/data
      - jarvis-models:/app/models
      - jarvis-logs:/app/data/logs

    # Dependencies
    depends_on:
      jarvis-backend:
        condition: service_healthy

    # Network
    networks:
      jarvis-network:
        ipv4_address: 172.28.0.12

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: "${TRAINING_CPU_LIMIT:-2}"
          memory: ${TRAINING_MEMORY_LIMIT:-4G}

  # ---------------------------------------------------------------------------
  # Ironcliw Prime - Local LLM Inference (from jarvis-prime repo)
  # ---------------------------------------------------------------------------
  jarvis-prime:
    build:
      context: ${Ironcliw_PRIME_PATH:-../../jarvis-prime}
      dockerfile: Dockerfile
    image: jarvis-prime:${Ironcliw_VERSION:-9.4.0}
    container_name: jarvis-prime
    hostname: jarvis-prime
    restart: unless-stopped
    profiles:
      - local-llm
      - all

    # Ports
    ports:
      - "${Ironcliw_PRIME_PORT:-8012}:8000"

    # Environment
    environment:
      - PYTHONUNBUFFERED=1
      - Ironcliw_PRIME_HOST=0.0.0.0
      - Ironcliw_PRIME_PORT=8000
      - MODEL_PATH=/models/current/jarvis-prime-latest.gguf
      - CONTEXT_SIZE=${PRIME_CONTEXT_SIZE:-4096}
      - N_GPU_LAYERS=${PRIME_GPU_LAYERS:-0}
      - N_THREADS=${PRIME_THREADS:-4}
      - ENVIRONMENT=${Ironcliw_ENV:-production}

      # Redis for caching
      - REDIS_URL=redis://redis:6379/1

      # ChromaDB for embeddings
      - CHROMADB_HOST=chromadb
      - CHROMADB_PORT=8000

    # Volumes
    volumes:
      - jarvis-models:/models:ro
      - jarvis-data:/app/data

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

    # Dependencies
    depends_on:
      redis:
        condition: service_healthy

    # Network
    networks:
      jarvis-network:
        ipv4_address: 172.28.0.13

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: "${PRIME_CPU_LIMIT:-4}"
          memory: ${PRIME_MEMORY_LIMIT:-16G}
        reservations:
          cpus: "2"
          memory: 4G

  # ---------------------------------------------------------------------------
  # Ironcliw Prime Cloud Proxy - Cloud Run Inference (optional)
  # ---------------------------------------------------------------------------
  jarvis-prime-cloud:
    image: nginx:alpine
    container_name: jarvis-prime-cloud
    hostname: jarvis-prime-cloud
    restart: unless-stopped
    profiles:
      - cloud-llm
      - all

    # Ports
    ports:
      - "${Ironcliw_PRIME_CLOUD_PORT:-8013}:80"

    # Config mounted from custom nginx conf
    volumes:
      - ./nginx-cloud-proxy.conf:/etc/nginx/conf.d/default.conf:ro

    # Environment (for envsubst)
    environment:
      - CLOUD_RUN_URL=${Ironcliw_PRIME_CLOUD_RUN_URL:-https://jarvis-prime-dev.run.app}

    # Network
    networks:
      jarvis-network:
        ipv4_address: 172.28.0.14

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 128M

  # ---------------------------------------------------------------------------
  # Reactor-Core - Training Pipeline Orchestrator
  # ---------------------------------------------------------------------------
  reactor-core:
    build:
      context: ${REACTOR_CORE_PATH:-../../reactor-core}
      dockerfile: docker/Dockerfile
    image: reactor-core:${Ironcliw_VERSION:-9.4.0}
    container_name: reactor-core
    hostname: reactor-core
    restart: unless-stopped
    profiles:
      - full-training
      - all

    # Ports
    ports:
      - "${REACTOR_CORE_PORT:-8020}:8020"

    # Environment
    environment:
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      - REACTOR_HOST=0.0.0.0
      - REACTOR_PORT=8020
      - ENVIRONMENT=${Ironcliw_ENV:-production}

      # Training config
      - BASE_MODEL=${BASE_MODEL:-meta-llama/Llama-3.2-3B}
      - OUTPUT_NAME=jarvis-prime
      - QUANTIZATION=${GGUF_QUANTIZATION:-q4_k_m}

      # Database
      - TRAINING_DB_PATH=/data/training_db/jarvis_training.db

      # Integration with Ironcliw
      - Ironcliw_API_URL=http://jarvis-backend:8010
      - Ironcliw_MODELS_DIR=/models

      # GCS
      - GCS_BUCKET=${GCS_BUCKET:-}
      - GCS_UPLOAD_ENABLED=${GCS_UPLOAD_ENABLED:-false}
      - GOOGLE_APPLICATION_CREDENTIALS=/credentials/gcp-key.json

    # Volumes
    volumes:
      - jarvis-models:/models
      - jarvis-training-db:/data/training_db
      - reactor-work:/app/work
      - ${GCP_CREDENTIALS_PATH:-./credentials}:/credentials:ro

    # Dependencies
    depends_on:
      jarvis-backend:
        condition: service_healthy
      redis:
        condition: service_healthy

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8020/health"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s

    # Network
    networks:
      jarvis-network:
        ipv4_address: 172.28.0.15

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: "${REACTOR_CPU_LIMIT:-4}"
          memory: ${REACTOR_MEMORY_LIMIT:-16G}
        reservations:
          cpus: "2"
          memory: 8G

  # ---------------------------------------------------------------------------
  # ChromaDB - Vector Database for Embeddings
  # ---------------------------------------------------------------------------
  chromadb:
    image: chromadb/chroma:latest
    container_name: jarvis-chromadb
    hostname: chromadb
    restart: unless-stopped

    # Ports
    ports:
      - "${CHROMADB_PORT:-8001}:8000"

    # Environment
    environment:
      - IS_PERSISTENT=TRUE
      - ANONYMIZED_TELEMETRY=FALSE
      - ALLOW_RESET=TRUE
      - CHROMA_SERVER_AUTH_PROVIDER=${CHROMADB_AUTH_PROVIDER:-}
      - CHROMA_SERVER_AUTH_CREDENTIALS=${CHROMADB_AUTH_CREDENTIALS:-}

    # Volumes
    volumes:
      - chromadb-data:/chroma/chroma

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

    # Network
    networks:
      jarvis-network:
        ipv4_address: 172.28.0.21

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G

  # ---------------------------------------------------------------------------
  # Redis - Distributed Caching and Session Storage
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    container_name: jarvis-redis
    hostname: redis
    restart: unless-stopped

    # Ports
    ports:
      - "${REDIS_PORT:-6379}:6379"

    # Command with persistence and memory limit
    command: >
      redis-server
      --save 60 1
      --loglevel warning
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --appendonly yes

    # Volumes
    volumes:
      - redis-data:/data

    # Health check
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s

    # Network
    networks:
      jarvis-network:
        ipv4_address: 172.28.0.20

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M

# =============================================================================
# x-common-labels - Shared labels for all services
# =============================================================================
x-common-labels: &common-labels
  app.jarvis.version: "${Ironcliw_VERSION:-9.4.0}"
  app.jarvis.component: "jarvis-stack"
  app.jarvis.managed-by: "docker-compose"

# =============================================================================
# Profile Reference
# =============================================================================
#
# Profiles allow selective service activation:
#
# | Profile        | Services Included                                    |
# |----------------|------------------------------------------------------|
# | (default)      | backend, frontend, training, redis, chromadb         |
# | local-llm      | + jarvis-prime (local GGUF inference)                |
# | cloud-llm      | + jarvis-prime-cloud (Cloud Run proxy)               |
# | full-training  | + reactor-core (full training pipeline)              |
# | all            | Everything enabled                                   |
#
# Examples:
#   docker compose up -d                         # Default services
#   docker compose --profile local-llm up -d    # + Local LLM
#   docker compose --profile all up -d          # Everything
#   docker compose --profile local-llm --profile full-training up -d
#
# =============================================================================
