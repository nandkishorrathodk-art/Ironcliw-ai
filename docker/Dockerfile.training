# =============================================================================
# Ironcliw Training Engine Dockerfile v1.0.0
# =============================================================================
#
# Unified training container that integrates:
# - Ironcliw-AI-Agent (experience collection, observability)
# - reactor-core (training pipeline, GGUF export)
# - Ironcliw-Prime (model deployment)
#
# Features:
# - SQLite training database for experience storage
# - Continuous background web scraping via Safe Scout
# - Automatic model training on schedule
# - GGUF model export for Ironcliw-Prime
# - GCS upload for cloud deployment
#
# Build:
#   docker build -f docker/Dockerfile.training -t jarvis-training .
#
# Run:
#   docker run -v $(pwd)/data:/app/data \
#              -v $(pwd)/models:/app/models \
#              -e ANTHROPIC_API_KEY=sk-xxx \
#              jarvis-training
#
# =============================================================================

# -----------------------------------------------------------------------------
# Stage 1: Builder - Install dependencies and compile code
# -----------------------------------------------------------------------------
FROM python:3.11-slim-bookworm AS builder

LABEL maintainer="Ironcliw AI Agent Team"
LABEL description="Ironcliw Training Engine - Autonomous Self-Improving Learning Pipeline"
LABEL version="1.0.0"

# Build arguments
ARG REACTOR_CORE_VERSION=main
ARG Ironcliw_PRIME_VERSION=main

# Environment
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    cmake \
    git \
    curl \
    sqlite3 \
    libsqlite3-dev \
    && rm -rf /var/lib/apt/lists/*

# Create virtual environment
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Upgrade pip
RUN pip install --upgrade pip wheel setuptools

# Create working directory
WORKDIR /build

# Copy Ironcliw-AI-Agent requirements
COPY requirements.txt /build/jarvis-requirements.txt

# Install Ironcliw-AI-Agent dependencies
RUN pip install -r /build/jarvis-requirements.txt || true

# Install additional training dependencies
RUN pip install \
    # Training & ML
    torch>=2.0.0 \
    transformers>=4.30.0 \
    datasets>=2.14.0 \
    accelerate>=0.20.0 \
    bitsandbytes>=0.40.0 \
    peft>=0.5.0 \
    trl>=0.7.0 \
    # Database
    aiosqlite>=0.19.0 \
    sqlalchemy>=2.0.0 \
    alembic>=1.12.0 \
    # Web scraping
    playwright>=1.40.0 \
    beautifulsoup4>=4.12.0 \
    html2text>=2020.1.16 \
    # GGUF export
    llama-cpp-python>=0.2.0 \
    # Utilities
    httpx>=0.25.0 \
    aiohttp>=3.9.0 \
    python-dotenv>=1.0.0 \
    pyyaml>=6.0.0 \
    rich>=13.0.0 \
    typer>=0.9.0 \
    # GCS upload
    google-cloud-storage>=2.10.0 \
    || echo "Some packages may have failed - continuing..."

# Install Playwright browsers
RUN playwright install chromium


# -----------------------------------------------------------------------------
# Stage 2: Production - Minimal runtime image
# -----------------------------------------------------------------------------
FROM python:3.11-slim-bookworm AS production

# Labels
LABEL maintainer="Ironcliw AI Agent Team"
LABEL description="Ironcliw Training Engine"
LABEL version="1.0.0"

# Install runtime dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    sqlite3 \
    libsqlite3-0 \
    curl \
    ffmpeg \
    libsndfile1 \
    # Playwright dependencies
    libnss3 \
    libnspr4 \
    libdbus-1-3 \
    libatk1.0-0 \
    libatk-bridge2.0-0 \
    libdrm2 \
    libxkbcommon0 \
    libatspi2.0-0 \
    libxcomposite1 \
    libxdamage1 \
    libxfixes3 \
    libxrandr2 \
    libgbm1 \
    libasound2 \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Copy virtual environment from builder
COPY --from=builder /opt/venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Copy Playwright browsers
COPY --from=builder /root/.cache/ms-playwright /root/.cache/ms-playwright

# Create non-root user for security
RUN groupadd -r jarvis && useradd -r -g jarvis -m -d /home/jarvis jarvis

# Create application directories
WORKDIR /app
RUN mkdir -p \
    /app/backend \
    /app/data/training_db \
    /app/data/experiences \
    /app/data/scraped_content \
    /app/models/current \
    /app/models/archive \
    /app/logs \
    && chown -R jarvis:jarvis /app

# Copy Ironcliw-AI-Agent backend
COPY --chown=jarvis:jarvis backend/ /app/backend/

# Copy training-specific files
COPY --chown=jarvis:jarvis docker/training_entrypoint.py /app/training_entrypoint.py
COPY --chown=jarvis:jarvis docker/training_db_schema.sql /app/training_db_schema.sql

# Set ownership
RUN chown -R jarvis:jarvis /app

# Switch to non-root user
USER jarvis

# =============================================================================
# Environment Configuration
# =============================================================================

# Paths
ENV Ironcliw_ROOT=/app \
    Ironcliw_DATA_DIR=/app/data \
    Ironcliw_MODELS_DIR=/app/models \
    Ironcliw_LOGS_DIR=/app/logs \
    PYTHONPATH=/app:/app/backend

# Training Database (SQLite)
ENV Ironcliw_TRAINING_DB=/app/data/training_db/jarvis_training.db \
    Ironcliw_TRAINING_DB_TYPE=sqlite

# Training Configuration
ENV Ironcliw_TRAINING_ENABLED=true \
    Ironcliw_TRAINING_SCHEDULE="03:00" \
    Ironcliw_TRAINING_MIN_EXPERIENCES=100 \
    Ironcliw_TRAINING_COOLDOWN_HOURS=24

# Continuous Scraping
ENV CONTINUOUS_SCRAPING_ENABLED=true \
    CONTINUOUS_SCRAPING_INTERVAL_HOURS=4 \
    CONTINUOUS_SCRAPING_MAX_PAGES=50

# Intelligence Systems
ENV UAE_ENABLED=true \
    SAI_ENABLED=true \
    NEURAL_MESH_ENABLED=true \
    MAS_ENABLED=true \
    CAI_ENABLED=true

# GGUF Export
ENV GGUF_EXPORT_ENABLED=true \
    GGUF_QUANTIZATION=q4_k_m

# GCS Upload (optional - configure via environment)
ENV GCS_UPLOAD_ENABLED=false \
    GCS_MODELS_BUCKET=""

# Playwright
ENV PLAYWRIGHT_BROWSERS_PATH=/root/.cache/ms-playwright

# Expose port for monitoring
EXPOSE 8090

# Health check
HEALTHCHECK --interval=60s --timeout=30s --start-period=60s --retries=3 \
    CMD python3 -c "import sqlite3; conn = sqlite3.connect('$Ironcliw_TRAINING_DB'); print('ok')" || exit 1

# Default entrypoint
ENTRYPOINT ["python3", "/app/training_entrypoint.py"]
CMD ["--mode", "continuous"]
